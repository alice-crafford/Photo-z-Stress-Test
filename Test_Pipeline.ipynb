{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential Imports: \n",
    "import os\n",
    "import numpy as np\n",
    "import qp\n",
    "import tables_io\n",
    "from pathlib import Path \n",
    "from pzflow.examples import get_galaxy_data\n",
    "import ceci\n",
    "\n",
    "## RAIL-Specific Imports: \n",
    "import rail\n",
    "\n",
    "# old : from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness\n",
    "\n",
    "\n",
    "from rail.creation.degradation.lsst_error_model import LSSTErrorModel\n",
    "from rail.creation.degradation.spectroscopic_degraders import InvRedshiftIncompleteness\n",
    "\n",
    "import rail.creation \n",
    "import rail.creation.engines\n",
    "from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "# old : from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "\n",
    "from rail.estimation.algos.train_z import TrainZEstimator, TrainZInformer\n",
    "from rail.estimation.algos.cmnn import Inform_CMNNPDF, CMNNPDF\n",
    "from rail.estimation.algos.gpz import GPzInformer, GPzEstimator \n",
    "from rail.estimation.algos.pzflow_nf import PZFlowInformer, PZFlowEstimator \n",
    "from rail.estimation.algos.flexzboost import FlexZBoostInformer, FlexZBoostEstimator  \n",
    "\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "\n",
    "## Data Storage: \n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True\n",
    "\n",
    "\n",
    "### CMNN, PZFlow, FlexZBoost, GPZ, trainz for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package rail.estimation.algos in rail.estimation:\n",
      "\n",
      "NAME\n",
      "    rail.estimation.algos\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _gpz_util\n",
      "    bpz_lite\n",
      "    cmnn\n",
      "    delightPZ\n",
      "    delight_version (package)\n",
      "    equal_count\n",
      "    flexzboost\n",
      "    gpz\n",
      "    naive_stack\n",
      "    point_est_hist\n",
      "    pzflow_nf\n",
      "    random_gauss\n",
      "    train_z\n",
      "    uniform_binning\n",
      "    var_inf\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rail.estimation.algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(rail.creation.engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from rail.stages import *\n",
    "#rail.stages.import_and_attach_all()\n",
    "#for val in RailStage.pipeline_stages.values():\n",
    "#    print(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    #path to access the data \n",
    "    DATA_DIR = Path().resolve() / \"data\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    catalog_file = DATA_DIR / \"base_catalog.pq\"\n",
    "\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    \n",
    "    #array of galaxies w/ 7 attributes for each: redshift & ugrizy\n",
    "    catalog = get_galaxy_data().rename(band_dict, axis=1) \n",
    "\n",
    "    #turns array into a table \n",
    "    tables_io.write(catalog, str(catalog_file.with_suffix(\"\")), catalog_file.suffix[1:])\n",
    "\n",
    "    catalog_file = str(catalog_file)\n",
    "    flow_file = str(DATA_DIR / \"trained_flow.pkl\")\n",
    "\n",
    "    print(flow_file)\n",
    "\n",
    "    #we set up the stage \n",
    "    flow_modeler_params = {\n",
    "        \"name\": \"flow_modeler\",\n",
    "        \"input\": catalog_file,\n",
    "        \"model\": flow_file,\n",
    "        \"seed\": 0,\n",
    "        \"phys_cols\": {\"redshift\": [0, 3]},\n",
    "        \"phot_cols\": {\n",
    "            \"mag_u_lsst\": [17, 35],\n",
    "            \"mag_g_lsst\": [16, 32],\n",
    "            \"mag_r_lsst\": [15, 30],\n",
    "            \"mag_i_lsst\": [15, 30],\n",
    "            \"mag_z_lsst\": [14, 29],\n",
    "            \"mag_y_lsst\": [14, 28],\n",
    "        },\n",
    "        \"calc_colors\": {\"ref_column_name\": \"mag_i_lsst\"},\n",
    "    }\n",
    "    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)\n",
    "    # flow_modeler.fit_model()\n",
    "    return flow_modeler, flow_file ##.get_handle(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl\n"
     ]
    }
   ],
   "source": [
    "modelData, flow_file = makeModel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make Training Set and Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSet(ntrain, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'train_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntrain,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSet(ntest, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'test_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntest,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data #.sample(ntest, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Degraders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inverse Redshift Incompleteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invRedshift(pivot = 1.0):\n",
    "    assert type(pivot) == float \n",
    "    degr = InvRedshiftIncompleteness.make_stage(\n",
    "        name = 'inv_redshift',\n",
    "        pivot_redshift = pivot\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "pivot_ls = [1.0, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Choose pivot z's for inverse redshift incompleteness \n",
    "\n",
    "# ## seed1 and ndata should be the same as  seed1 and ntrain used to call bigF!! \n",
    "# ## Otherwise this might not be representative of the real data \n",
    "\n",
    "# def choosePivots(seed1, ndata):\n",
    "#     nums = trainSet(ndata, seed1)\n",
    "#     data = nums.sample(ndata, seed1)\n",
    "#     data_pq = col_remap(data)\n",
    "#     data_table = table_conv(data_pq)\n",
    "#     table = tables_io.convertObj(data_table.data, tables_io.types.PD_DATAFRAME)\n",
    "#     return np.asarray(table['redshift'])\n",
    "\n",
    "# percentiles = np.arange(10, 100, 10)\n",
    "# pivots = [] \n",
    "\n",
    "# for i in percentiles:\n",
    "#     pivot = np.percentile(choosePivots(17, 100000), i) \n",
    "#     pivots.append(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pivots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSST Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "\n",
    "def lsstError(dict, seed): #tvis = 1, nYrObs = 1, airmass = 1, extendedSource = 1, sigmaSys = 1, magLim = 1, ndFlag = 1, A_min = 1, A_max = 1):\n",
    "    deg = LSSTErrorModel.make_stage(\n",
    "        name='lsst_error',\n",
    "        renameDict= dict, \n",
    "        ndFlag=np.nan,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return deg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Quantity Cuts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a dictionary with the different bands and magnitudes you want\n",
    "\n",
    "def quantCuts(band, mag):\n",
    "    quantity_cut = QuantityCut.make_stage(\n",
    "        name='quantity_cut',    \n",
    "        cuts={'mag_i_lsst': 25.0},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcuts_dict = {'mag_u_lsst': [...], \n",
    "              'mag_g_lsst': [...], \n",
    "              'mag_r_lsst': [...], \n",
    "              'mag_i_lsst': [...], \n",
    "              'mag_z_lsst': [...], \n",
    "              'mag_y_lsst': [...] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Survey-Based Degraders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.creation.degradation.spectroscopic_selections import *\n",
    "\n",
    "def specSelectBOSS(ntrain):\n",
    "    degr = SpecSelection_BOSS.make_stage(\n",
    "        name = 'specselection_boss',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectDEEP2(ntrain):\n",
    "    degr = SpecSelection_DEEP2.make_stage(\n",
    "        name = 'specselection_deep2',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectGAMA(ntrain):\n",
    "    degr = SpecSelection_GAMA.make_stage(\n",
    "        name = 'specselection_gama',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectHSC(ntrain):\n",
    "    degr = SpecSelection_HSC.make_stage(\n",
    "        name = 'specselection_HSC',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectVVDSf02(ntrain):\n",
    "    degr = SpecSelection_VVDSf02.make_stage(\n",
    "        name = 'specselection_VVDSf02',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectzCOSMOS(ntrain):\n",
    "    degr = SpecSelection_zCOSMOS.make_stage(\n",
    "        name = 'specselection_zCOSMOS',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(data, model, grid):\n",
    "    posts = FlowPosterior.make_stage(\n",
    "        name='get_posts'+str(data), \n",
    "        column='redshift',\n",
    "        grid = grid,\n",
    "        model = model,\n",
    "        data = data\n",
    "    )\n",
    "    return posts #posts.get_posterior(data, column = 'redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(zmin, zmax, nbins):\n",
    "    import numpy as np\n",
    "    grid = np.linspace(zmin, zmax, nbins + 1)\n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = makeGrid(0, 2.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_train_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_train = FlowPosterior.make_stage(name='orig_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_train)\n",
    "\n",
    "# orig_train_pdfs = flow_post_orig_train.get_posterior(orig_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_train_posts ** rerun this cell!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_train = FlowPosterior.make_stage(name='deg_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              err_samples = 0,\n",
    "#                                              data = deg_train)\n",
    "\n",
    "\n",
    "\n",
    "# deg_train_pdfs = flow_post_deg_train.get_posterior(deg_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_test = FlowPosterior.make_stage(name='orig_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_test)\n",
    "\n",
    "# orig_test_pdfs = flow_post_orig_test.get_posterior(orig_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_test = FlowPosterior.make_stage(name='deg_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = deg_test)\n",
    "\n",
    "# deg_test_pdfs = flow_post_deg_test.get_posterior(deg_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "def colRemapper(dict):\n",
    "    col_remap = ColumnMapper.make_stage(\n",
    "    name='col_remapper', \n",
    "    columns=dict,\n",
    "    )\n",
    "    return col_remap\n",
    "\n",
    "def tableConverter():\n",
    "    table_conv = TableConverter.make_stage(\n",
    "    name='table_conv', \n",
    "    output_format='numpyDict',\n",
    "    )\n",
    "    return table_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_remap = colRemapper(band_dict_err)\n",
    "table_conv = tableConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inform & Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informTrainZ():\n",
    "    inf = TrainZInformer.make_stage(\n",
    "    name = 'inform_TrainZ',\n",
    "    model = 'trainz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateTrainZ(info):\n",
    "    est = TrainZEstimator.make_stage(\n",
    "    name = 'estimate_TrainZ',\n",
    "    model = 'trainz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informCMNN():\n",
    "    inf = Inform_CMNNPDF.make_stage(\n",
    "    name = 'inform_CMNN',\n",
    "    model = 'cmnn.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateCMNN(info):\n",
    "    est = CMNNPDF.make_stage(\n",
    "    name = 'estimate_CMNN',\n",
    "    model = 'cmnn.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informGPz():\n",
    "    inf = GPzInformer.make_stage(\n",
    "    name = 'inform_GPz',\n",
    "    model = 'gpz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateGPz(info):\n",
    "    est = GPzEstimator.make_stage(\n",
    "    name = 'estimate_GPz',\n",
    "    model = 'gpz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informPZFlow():\n",
    "    inf = PZFlowInformer.make_stage(\n",
    "    name = 'inform_PZFlow',\n",
    "    model = 'pzflow.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimatePZFlow(info):\n",
    "    est = PZFlowEstimator.make_stage(\n",
    "    name = 'estimate_PZFlow',\n",
    "    model = 'pzflow.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informFZBoost():\n",
    "    info = FlexZBoostInformer.make_stage(\n",
    "    name ='inform_FZBoost', \n",
    "    model ='fzboost.pkl', \n",
    "    hdf5_groupname='',\n",
    "    )\n",
    "    return info\n",
    "\n",
    "def estimateFZBoost(info):\n",
    "    est = FlexZBoostEstimator.make_stage(\n",
    "    name='est_FZBoost', \n",
    "    nondetect_val=np.nan,\n",
    "    model= info,\n",
    "    hdf5_groupname='',\n",
    "    aliases=dict(input='test_data', output='fzboost_estim'),\n",
    "    nzbins = 100 \n",
    "    )\n",
    "    return est "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'invz': invRedshift,\n",
    "\n",
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } \n",
    "\n",
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ceci \n",
    "\n",
    "# pr = ceci.Pipeline.read(path_lst_1[0])#parent_dir+directory+\"/invz=0.33672517538070684_lsstErr_pzflow.yml\")\n",
    "# pr.run()\n",
    "\n",
    "# ## 1) terminal: go to path up to invz_lsstErr_pzflow, then run these 2 lines \n",
    "# ## 2)  make list/txt file with list of paths to files made by big F\n",
    "\n",
    "# ## do 1) \n",
    "# ## open virtual env\n",
    "# ## python \n",
    "# ## import ceci \n",
    "# ## run the 2 lines of code above \n",
    "\n",
    "\n",
    "# ### at the end we can put this into a .py file that we can run at the command line \n",
    "\n",
    "# ## %cd ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## more config parameters/better config parameters\n",
    "## have to give path above to estimator model instead of get_handle('model')\n",
    "## fix truncated parameter printing in help(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Big F's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl, test_set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_test_set: inprogress_output_test_set.pq, test_set\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:792\u001b[0m, in \u001b[0;36mreadPqToDataFrames\u001b[0;34m(basepath, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 792\u001b[0m     dataframes[key] \u001b[39m=\u001b[39m readPqToDataFrame(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mbasepath\u001b[39m}\u001b[39;49;00m\u001b[39m{\u001b[39;49;00mkey\u001b[39m}\u001b[39;49;00m\u001b[39m.pq\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    793\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m msg:  \u001b[39m#pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:747\u001b[0m, in \u001b[0;36mreadPqToDataFrame\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \u001b[39mReads a `pandas.DataFrame` object from an parquet file.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[39m    The data frame\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_parquet(filepath, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpyarrow\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39;49mread(\n\u001b[1;32m    504\u001b[0m     path,\n\u001b[1;32m    505\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    506\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    507\u001b[0m     use_nullable_dtypes\u001b[39m=\u001b[39;49muse_nullable_dtypes,\n\u001b[1;32m    508\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    509\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/pandas/io/parquet.py:244\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m     to_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39msplit_blocks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mfilesystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/pandas/io/parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     94\u001b[0m     \u001b[39mnot\u001b[39;00m fs\n\u001b[1;32m     95\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     handles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m    103\u001b[0m         path_or_handle, mode, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m     fs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m handles\u001b[39m.\u001b[39mappend(handle)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_test_set.pq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 51\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m testData \u001b[39m=\u001b[39m testSet(\u001b[39m100\u001b[39m, \u001b[39m39\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m testData\u001b[39m.\u001b[39mrun()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y101sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m test_data \u001b[39m=\u001b[39m DS\u001b[39m.\u001b[39;49mread_file(\u001b[39m\"\u001b[39;49m\u001b[39mtest_Data\u001b[39;49m\u001b[39m\"\u001b[39;49m, TableHandle, \u001b[39m\"\u001b[39;49m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_test_set.pq\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:437\u001b[0m, in \u001b[0;36mDataStore.read_file\u001b[0;34m(self, key, handle_class, path, creator, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Create a handle, use it to read a file, and insert it into the DataStore \"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m handle \u001b[39m=\u001b[39m handle_class(key, path\u001b[39m=\u001b[39mpath, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, creator\u001b[39m=\u001b[39mcreator)\n\u001b[0;32m--> 437\u001b[0m handle\u001b[39m.\u001b[39;49mread(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m handle\n\u001b[1;32m    439\u001b[0m \u001b[39mreturn\u001b[39;00m handle\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:62\u001b[0m, in \u001b[0;36mDataHandle.read\u001b[0;34m(self, force, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force:\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpandvars(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:205\u001b[0m, in \u001b[0;36mTableHandle._read\u001b[0;34m(cls, path, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read\u001b[39m(\u001b[39mcls\u001b[39m, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read and return the data from the associated file \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m tables_io\u001b[39m.\u001b[39;49mread(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:960\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filepath, tType, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(filepath, tType\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_missing_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    939\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \n\u001b[1;32m    941\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     odict \u001b[39m=\u001b[39m readNative(filepath, fmt, keys, allow_missing_keys)\n\u001b[1;32m    961\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(odict) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m defName \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39m__astropy_table__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:934\u001b[0m, in \u001b[0;36mreadNative\u001b[0;34m(filepath, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m fType \u001b[39m==\u001b[39m PANDAS_PARQUET:\n\u001b[1;32m    933\u001b[0m     basepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(filepath)[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 934\u001b[0m     \u001b[39mreturn\u001b[39;00m readPqToDataFrames(basepath, keys, allow_missing_keys)\n\u001b[1;32m    935\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported FileType \u001b[39m\u001b[39m{\u001b[39;00mfType\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:796\u001b[0m, in \u001b[0;36mreadPqToDataFrames\u001b[0;34m(basepath, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[39mif\u001b[39;00m allow_missing_keys:\n\u001b[1;32m    795\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mmsg\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[39mreturn\u001b[39;00m dataframes\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make sure to change the first argument of testSet\n",
    "# testData = testSet(ntest, seed2)\n",
    "\n",
    "testData = testSet(100, 39)\n",
    "testData.run()\n",
    "\n",
    "test_data = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_test_set.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, lsst_error\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unknown file format , supported types are{list(FILE_FORMAT_SUFFIXS.keys())}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/types.py:206\u001b[0m, in \u001b[0;36mfileType\u001b[0;34m(filepath, fmt)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m FILE_FORMAT_SUFFIXS[fmt]\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m msg:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 52\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m band_dict_err \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmag_\u001b[39m\u001b[39m{\u001b[39;00mband\u001b[39m}\u001b[39;00m\u001b[39m_lsst_err\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmag_err_\u001b[39m\u001b[39m{\u001b[39;00mband\u001b[39m}\u001b[39;00m\u001b[39m_lsst\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m band \u001b[39min\u001b[39;00m bands}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lsstErr \u001b[39m=\u001b[39m lsstError(band_dict, \u001b[39m172\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lsstErr\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lsst_Err \u001b[39m=\u001b[39m DS\u001b[39m.\u001b[39mread_file(\u001b[39m\"\u001b[39m\u001b[39mtest_Data\u001b[39m\u001b[39m\"\u001b[39m, TableHandle, \u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_lsst_error.pq\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/creation/degradation/lsst_error_model.py:55\u001b[0m, in \u001b[0;36mLSSTErrorModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return pandas DataFrame with photometric errors.\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Load the input catalog\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data(\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Add photometric errors\u001b[39;00m\n\u001b[1;32m     58\u001b[0m obsData \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_model(data, random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mseed)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/stage.py:248\u001b[0m, in \u001b[0;36mRailStage.get_data\u001b[0;34m(self, tag, allow_missing)\u001b[0m\n\u001b[1;32m    246\u001b[0m handle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_handle(tag, allow_missing\u001b[39m=\u001b[39mallow_missing)\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handle\u001b[39m.\u001b[39mhas_data:\n\u001b[0;32m--> 248\u001b[0m     handle\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m handle()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:62\u001b[0m, in \u001b[0;36mDataHandle.read\u001b[0;34m(self, force, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force:\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpandvars(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:205\u001b[0m, in \u001b[0;36mTableHandle._read\u001b[0;34m(cls, path, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read\u001b[39m(\u001b[39mcls\u001b[39m, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read and return the data from the associated file \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m tables_io\u001b[39m.\u001b[39;49mread(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:960\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filepath, tType, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(filepath, tType\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_missing_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    939\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \n\u001b[1;32m    941\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     odict \u001b[39m=\u001b[39m readNative(filepath, fmt, keys, allow_missing_keys)\n\u001b[1;32m    961\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(odict) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m defName \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39m__astropy_table__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:921\u001b[0m, in \u001b[0;36mreadNative\u001b[0;34m(filepath, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadNative\u001b[39m(filepath, fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_missing_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    902\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m \n\u001b[1;32m    920\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     fType \u001b[39m=\u001b[39m fileType(filepath, fmt)\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m fType \u001b[39m==\u001b[39m ASTROPY_FITS:\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m readFitsToApTables(filepath)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/types.py:208\u001b[0m, in \u001b[0;36mfileType\u001b[0;34m(filepath, fmt)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mreturn\u001b[39;00m FILE_FORMAT_SUFFIXS[fmt]\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m msg:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown file format \u001b[39m\u001b[39m{\u001b[39;00mfmt\u001b[39m}\u001b[39;00m\u001b[39m, supported types are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m{\u001b[39m\u001b[39mlist(FILE_FORMAT_SUFFIXS.keys())}\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mmsg\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unknown file format , supported types are{list(FILE_FORMAT_SUFFIXS.keys())}'"
     ]
    }
   ],
   "source": [
    "#lsstErr = lsstError(band_dict, seed3)\n",
    "\n",
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "lsstErr = lsstError(band_dict, 172)\n",
    "lsstErr.connect_input(test_data) ## might be wrong; passing in a file not a stage \n",
    "lsstErr.run()\n",
    "\n",
    "lsst_Err = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_lsst_error.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for inverse redshift incompleteness:\n",
    "\n",
    "pivot_ls = [1.0, 1.4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF0(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infTrainZ = informTrainZ()\n",
    "    estTrainZ = estimateTrainZ(infTrainZ)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infTrainZ, \n",
    "        estTrainZ]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infTrainZ.connect_input(deg) \n",
    "    estTrainZ.connect_input(infTrainZ, inputTag = 'model')\n",
    "    estTrainZ.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_pzflow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_0 = []\n",
    "directory = \"specSelection_lsstErr_TrainZ\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_0, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_0.append(bigF0(spec_dict[key], key, path_0, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_0_invz = []\n",
    "directory = \"invz_lsstErr_TrainZ\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_0_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_0_invz.append(bigF0(invRedshift(i), 'invz='+str(i), path_0_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infCMNN = informCMNN()\n",
    "    estCMNN = estimateCMNN(infCMNN)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infCMNN, \n",
    "        estCMNN]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infCMNN.connect_input(deg) \n",
    "    estCMNN.connect_input(infCMNN, inputTag = 'model')\n",
    "    estCMNN.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_CMNN.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1 = []\n",
    "directory = \"specSelection_lsstErr_CMNN\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_1.append(bigF1(spec_dict[key], key, path_1, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1_invz = []\n",
    "directory = \"invz_lsstErr_CMNN\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_1_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_1_invz.append(bigF1(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infGPz = informGPz()\n",
    "    estGPz = estimateGPz(infGPz)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infGPz, \n",
    "        estGPz]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infGPz.connect_input(deg) \n",
    "    estGPz.connect_input(infGPz, inputTag = 'model')\n",
    "    estGPz.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_GPz.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2 = []\n",
    "directory = \"specSelection_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_1.append(bigF2(spec_dict[key], key, path_2, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2_invz = []\n",
    "directory = \"invz_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_2_invz.append(bigF2(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PZFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigF3(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    # lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    # estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_PZFlow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(rail.creation.degradation.spectroscopic_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_3 = []\n",
    "directory = \"specSelection_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage lsst_error is missing input(s): output_test_set\nStage estimate_PZFlow is missing input(s): output_lsst_error\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 66\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m spec_dict:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     path_lst_2\u001b[39m.\u001b[39mappend(bigF2(spec_dict[key], key, \u001b[39m1000\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m39\u001b[39;49m, \u001b[39m172\u001b[39;49m, \u001b[39m10\u001b[39;49m))\n",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 66\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m estPZFlow\u001b[39m.\u001b[39mconnect_input(lsstErr, inputTag \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m## trucated out of docs :(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# informFZB.connect_input(invRed)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# estFZB.connect_input(informFZB, lsstErr) \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m pipe\u001b[39m.\u001b[39;49minitialize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdict\u001b[39;49m(model\u001b[39m=\u001b[39;49mflow_file), \u001b[39mdict\u001b[39;49m(output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, log_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, resume\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), \u001b[39mNone\u001b[39;49;00m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m outpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_2, \u001b[39m\"\u001b[39m\u001b[39m% s\u001b[39;00m\u001b[39m_lsstErr_pzflow.yml\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m pipe\u001b[39m.\u001b[39msave(outpath)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:798\u001b[0m, in \u001b[0;36mPipeline.initialize\u001b[0;34m(self, overall_inputs, run_config, stages_config)\u001b[0m\n\u001b[1;32m    795\u001b[0m     v\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_config)\n\u001b[1;32m    797\u001b[0m \u001b[39m# Get the stages in the order we need.\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mordered_stages(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverall_inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstages_config)\n\u001b[1;32m    800\u001b[0m \u001b[39m# Initiate the run.\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# This is an implementation detail for the different subclasses to store\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# necessary information about the run if necessary.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# Usually, the arguments are ignored, but they are provided in case a class needs to\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# do something special with any of them.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitiate_run(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:753\u001b[0m, in \u001b[0;36mPipeline.ordered_stages\u001b[0;34m(self, overall_inputs, stages_config)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 msg1\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStage \u001b[39m\u001b[39m{\u001b[39;00mstage_name\u001b[39m}\u001b[39;00m\u001b[39m is missing input(s): \u001b[39m\u001b[39m{\u001b[39;00mmissing_inputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    752\u001b[0m             msg1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(msg1)\n\u001b[0;32m--> 753\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    755\u001b[0m \u001b[39mSome required inputs to the pipeline could not be found,\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39m(or possibly your pipeline is cyclic):\u001b[39m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39m{\u001b[39;00mmsg1\u001b[39m}\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    760\u001b[0m             )\n\u001b[1;32m    762\u001b[0m         \u001b[39mreturn\u001b[39;00m ordered_stages\n",
      "\u001b[0;31mValueError\u001b[0m: \nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage lsst_error is missing input(s): output_test_set\nStage estimate_PZFlow is missing input(s): output_lsst_error\n"
     ]
    }
   ],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_3.append(bigF3(spec_dict[key], key, path_3, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_3_invz = []\n",
    "directory = \"invz_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_3_invz.append(bigF3(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlexZBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF4(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infFZBoost = informFZBoost()\n",
    "    estFZBoost = estimateFZBoost(infFZBoost)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infFZBoost, \n",
    "        estFZBoost]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infFZBoost.connect_input(deg) \n",
    "    estFZBoost.connect_input(infFZBoost, inputTag = 'model')\n",
    "    estFZBoost.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_FZBoost.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4 = []\n",
    "directory = \"specSelection_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_4.append(bigF4(spec_dict[key], key, path_4, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4_invz = []\n",
    "directory = \"invz_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_4_invz.append(bigF4(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n",
      "Job inform_PZFlow has completed successfully!\n",
      "\n",
      "Executing estimate_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.PZFlowEstimator   --model=./pzflow.pkl   --input=./output_lsst_error.pq   --name=estimate_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_estimate_PZFlow.hdf5 \n",
      "Output writing to ./estimate_PZFlow.out\n",
      "\n",
      "Job estimate_PZFlow has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = ceci.Pipeline.read(path_2+\"/BOSS_lsstErr_pzflow.yml\")\n",
    "pr.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function makedirs in module os:\n",
      "\n",
      "makedirs(name, mode=511, exist_ok=False)\n",
      "    makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "    \n",
      "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "    will be created if it does not exist. If the target directory already\n",
      "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "    raised.  This is recursive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.makedirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]  \n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    #estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST1.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_specselection_deep2: inprogress_output_specselection_deep2.pq, specselection_deep2\n",
      "Inserting handle into data store.  output_specselection_gama: inprogress_output_specselection_gama.pq, specselection_gama\n",
      "Inserting handle into data store.  output_specselection_HSC: inprogress_output_specselection_HSC.pq, specselection_HSC\n",
      "Inserting handle into data store.  output_specselection_VVDSf02: inprogress_output_specselection_VVDSf02.pq, specselection_VVDSf02\n",
      "Inserting handle into data store.  output_specselection_zCOSMOS: inprogress_output_specselection_zCOSMOS.pq, specselection_zCOSMOS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_lst_TEST1 = []\n",
    "directory = \"specSelection_TEST1\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST1 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST1, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST1.append(bigF_TEST1(spec_dict[key], key, path_TEST1, 1000, 1000, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]\n",
    "\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    #estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST2.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_lst_TEST2 = []\n",
    "directory = \"specSelection_TEST2\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST2, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST2.append(bigF_TEST2(spec_dict[key], key, path_TEST2, 10000, 10000, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir1 = \"outputs\"\n",
    "out_parent_dir1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1\"\n",
    "path_outs1 = os.path.join(out_parent_dir1, out_dir1)\n",
    "os.makedirs(path_outs1, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n",
      "Job inform_PZFlow has completed successfully!\n",
      "\n",
      "Executing estimate_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.PZFlowEstimator   --model=./pzflow.pkl   --input=./output_lsst_error.pq   --name=estimate_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_estimate_PZFlow.hdf5 \n",
      "Output writing to ./estimate_PZFlow.out\n",
      "\n",
      "Job estimate_PZFlow has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST1+\"/BOSS_TEST1.yml\")\n",
    "pr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.933041</td>\n",
       "      <td>27.515276</td>\n",
       "      <td>27.286690</td>\n",
       "      <td>26.769602</td>\n",
       "      <td>26.087349</td>\n",
       "      <td>25.628199</td>\n",
       "      <td>25.478405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.595904</td>\n",
       "      <td>27.316408</td>\n",
       "      <td>26.487122</td>\n",
       "      <td>25.609987</td>\n",
       "      <td>25.022789</td>\n",
       "      <td>24.816481</td>\n",
       "      <td>24.619503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503885</td>\n",
       "      <td>26.787773</td>\n",
       "      <td>26.411472</td>\n",
       "      <td>25.777828</td>\n",
       "      <td>25.382620</td>\n",
       "      <td>25.257975</td>\n",
       "      <td>25.065731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.149223</td>\n",
       "      <td>29.424986</td>\n",
       "      <td>28.336277</td>\n",
       "      <td>27.484585</td>\n",
       "      <td>27.122864</td>\n",
       "      <td>26.690264</td>\n",
       "      <td>26.177797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.330744</td>\n",
       "      <td>26.478308</td>\n",
       "      <td>26.149168</td>\n",
       "      <td>25.454374</td>\n",
       "      <td>24.850704</td>\n",
       "      <td>24.430229</td>\n",
       "      <td>23.861637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.016123</td>\n",
       "      <td>26.238529</td>\n",
       "      <td>26.198832</td>\n",
       "      <td>26.058969</td>\n",
       "      <td>26.133110</td>\n",
       "      <td>26.050972</td>\n",
       "      <td>25.689487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.520875</td>\n",
       "      <td>27.604046</td>\n",
       "      <td>26.637758</td>\n",
       "      <td>25.569271</td>\n",
       "      <td>25.078390</td>\n",
       "      <td>24.902649</td>\n",
       "      <td>24.692707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.172287</td>\n",
       "      <td>29.186840</td>\n",
       "      <td>28.469145</td>\n",
       "      <td>27.898277</td>\n",
       "      <td>27.719030</td>\n",
       "      <td>27.374804</td>\n",
       "      <td>26.885008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.234789</td>\n",
       "      <td>29.393019</td>\n",
       "      <td>28.316401</td>\n",
       "      <td>26.837587</td>\n",
       "      <td>25.619205</td>\n",
       "      <td>24.774239</td>\n",
       "      <td>24.047237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.800591</td>\n",
       "      <td>26.958065</td>\n",
       "      <td>26.128017</td>\n",
       "      <td>25.514343</td>\n",
       "      <td>24.974525</td>\n",
       "      <td>24.458202</td>\n",
       "      <td>24.266705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "0    0.933041   27.515276   27.286690   26.769602   26.087349   25.628199   \n",
       "1    0.595904   27.316408   26.487122   25.609987   25.022789   24.816481   \n",
       "2    0.503885   26.787773   26.411472   25.777828   25.382620   25.257975   \n",
       "3    2.149223   29.424986   28.336277   27.484585   27.122864   26.690264   \n",
       "4    1.330744   26.478308   26.149168   25.454374   24.850704   24.430229   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "995  2.016123   26.238529   26.198832   26.058969   26.133110   26.050972   \n",
       "996  0.520875   27.604046   26.637758   25.569271   25.078390   24.902649   \n",
       "997  2.172287   29.186840   28.469145   27.898277   27.719030   27.374804   \n",
       "998  1.234789   29.393019   28.316401   26.837587   25.619205   24.774239   \n",
       "999  1.800591   26.958065   26.128017   25.514343   24.974525   24.458202   \n",
       "\n",
       "     mag_y_lsst  \n",
       "0     25.478405  \n",
       "1     24.619503  \n",
       "2     25.065731  \n",
       "3     26.177797  \n",
       "4     23.861637  \n",
       "..          ...  \n",
       "995   25.689487  \n",
       "996   24.692707  \n",
       "997   26.885008  \n",
       "998   24.047237  \n",
       "999   24.266705  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1train = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs/output_train_set.pq\")\n",
    "\n",
    "df1train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.678802</td>\n",
       "      <td>22.524094</td>\n",
       "      <td>22.298061</td>\n",
       "      <td>21.065384</td>\n",
       "      <td>20.072044</td>\n",
       "      <td>19.666212</td>\n",
       "      <td>19.417404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.496280</td>\n",
       "      <td>22.490469</td>\n",
       "      <td>21.483559</td>\n",
       "      <td>20.207443</td>\n",
       "      <td>19.443588</td>\n",
       "      <td>19.127865</td>\n",
       "      <td>18.890064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "470  0.678802   22.524094   22.298061   21.065384   20.072044   19.666212   \n",
       "557  0.496280   22.490469   21.483559   20.207443   19.443588   19.127865   \n",
       "\n",
       "     mag_y_lsst  \n",
       "470   19.417404  \n",
       "557   18.890064  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.342823</td>\n",
       "      <td>25.937267</td>\n",
       "      <td>25.592773</td>\n",
       "      <td>25.302280</td>\n",
       "      <td>24.184923</td>\n",
       "      <td>23.383533</td>\n",
       "      <td>22.579002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191652</td>\n",
       "      <td>28.780466</td>\n",
       "      <td>28.075939</td>\n",
       "      <td>27.267124</td>\n",
       "      <td>26.668451</td>\n",
       "      <td>25.890570</td>\n",
       "      <td>25.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.751760</td>\n",
       "      <td>26.832052</td>\n",
       "      <td>26.458172</td>\n",
       "      <td>26.087759</td>\n",
       "      <td>25.595860</td>\n",
       "      <td>24.988527</td>\n",
       "      <td>24.666149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620976</td>\n",
       "      <td>22.530554</td>\n",
       "      <td>22.241764</td>\n",
       "      <td>21.103287</td>\n",
       "      <td>20.136244</td>\n",
       "      <td>19.746765</td>\n",
       "      <td>19.453854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.793243</td>\n",
       "      <td>27.564707</td>\n",
       "      <td>26.932222</td>\n",
       "      <td>26.285490</td>\n",
       "      <td>25.502998</td>\n",
       "      <td>25.277523</td>\n",
       "      <td>25.163303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.981384</td>\n",
       "      <td>27.963957</td>\n",
       "      <td>27.702507</td>\n",
       "      <td>27.336897</td>\n",
       "      <td>27.156370</td>\n",
       "      <td>26.714178</td>\n",
       "      <td>26.362583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744960</td>\n",
       "      <td>27.017117</td>\n",
       "      <td>26.490191</td>\n",
       "      <td>25.695547</td>\n",
       "      <td>24.839457</td>\n",
       "      <td>24.637497</td>\n",
       "      <td>24.520649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.101568</td>\n",
       "      <td>27.205582</td>\n",
       "      <td>26.924608</td>\n",
       "      <td>26.450403</td>\n",
       "      <td>26.079315</td>\n",
       "      <td>25.530327</td>\n",
       "      <td>25.305614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.928054</td>\n",
       "      <td>28.203192</td>\n",
       "      <td>27.457575</td>\n",
       "      <td>26.576130</td>\n",
       "      <td>25.856819</td>\n",
       "      <td>25.445122</td>\n",
       "      <td>25.309990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.202691</td>\n",
       "      <td>28.391132</td>\n",
       "      <td>27.409241</td>\n",
       "      <td>26.832666</td>\n",
       "      <td>26.587118</td>\n",
       "      <td>26.461618</td>\n",
       "      <td>26.408859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "0     1.342823   25.937267   25.592773   25.302280   24.184923   23.383533   \n",
       "1     1.191652   28.780466   28.075939   27.267124   26.668451   25.890570   \n",
       "2     1.751760   26.832052   26.458172   26.087759   25.595860   24.988527   \n",
       "3     0.620976   22.530554   22.241764   21.103287   20.136244   19.746765   \n",
       "4     0.793243   27.564707   26.932222   26.285490   25.502998   25.277523   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "9995  1.981384   27.963957   27.702507   27.336897   27.156370   26.714178   \n",
       "9996  0.744960   27.017117   26.490191   25.695547   24.839457   24.637497   \n",
       "9997  1.101568   27.205582   26.924608   26.450403   26.079315   25.530327   \n",
       "9998  0.928054   28.203192   27.457575   26.576130   25.856819   25.445122   \n",
       "9999  0.202691   28.391132   27.409241   26.832666   26.587118   26.461618   \n",
       "\n",
       "      mag_y_lsst  \n",
       "0      22.579002  \n",
       "1      25.420044  \n",
       "2      24.666149  \n",
       "3      19.453854  \n",
       "4      25.163303  \n",
       "...          ...  \n",
       "9995   26.362583  \n",
       "9996   24.520649  \n",
       "9997   25.305614  \n",
       "9998   25.309990  \n",
       "9999   26.408859  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2train = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_train_set.pq\")\n",
    "\n",
    "df2train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n",
      "Job inform_PZFlow has completed successfully!\n",
      "\n",
      "Executing estimate_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.PZFlowEstimator   --model=./pzflow.pkl   --input=./output_lsst_error.pq   --name=estimate_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_estimate_PZFlow.hdf5 \n",
      "Output writing to ./estimate_PZFlow.out\n",
      "\n",
      "Job estimate_PZFlow has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.298815</td>\n",
       "      <td>22.866861</td>\n",
       "      <td>21.576294</td>\n",
       "      <td>20.371439</td>\n",
       "      <td>19.647549</td>\n",
       "      <td>19.384043</td>\n",
       "      <td>19.054184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.506937</td>\n",
       "      <td>23.405199</td>\n",
       "      <td>20.913086</td>\n",
       "      <td>19.358709</td>\n",
       "      <td>18.569523</td>\n",
       "      <td>18.225611</td>\n",
       "      <td>17.970161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>0.649493</td>\n",
       "      <td>22.256865</td>\n",
       "      <td>21.764664</td>\n",
       "      <td>20.519007</td>\n",
       "      <td>19.611025</td>\n",
       "      <td>19.282930</td>\n",
       "      <td>19.013233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>0.423514</td>\n",
       "      <td>23.458931</td>\n",
       "      <td>20.948090</td>\n",
       "      <td>19.118870</td>\n",
       "      <td>18.525711</td>\n",
       "      <td>18.173027</td>\n",
       "      <td>17.956638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>0.648363</td>\n",
       "      <td>22.301899</td>\n",
       "      <td>21.645138</td>\n",
       "      <td>20.663469</td>\n",
       "      <td>19.834093</td>\n",
       "      <td>19.535355</td>\n",
       "      <td>19.293495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0.648992</td>\n",
       "      <td>25.440855</td>\n",
       "      <td>22.707363</td>\n",
       "      <td>20.903374</td>\n",
       "      <td>19.688295</td>\n",
       "      <td>19.192822</td>\n",
       "      <td>18.862762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>0.426807</td>\n",
       "      <td>23.751444</td>\n",
       "      <td>20.760584</td>\n",
       "      <td>19.133968</td>\n",
       "      <td>18.386021</td>\n",
       "      <td>18.017616</td>\n",
       "      <td>17.826719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8306</th>\n",
       "      <td>0.619865</td>\n",
       "      <td>23.423046</td>\n",
       "      <td>22.094854</td>\n",
       "      <td>20.491508</td>\n",
       "      <td>19.485312</td>\n",
       "      <td>18.963287</td>\n",
       "      <td>18.576736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "525   0.298815   22.866861   21.576294   20.371439   19.647549   19.384043   \n",
       "3830  0.506937   23.405199   20.913086   19.358709   18.569523   18.225611   \n",
       "4847  0.649493   22.256865   21.764664   20.519007   19.611025   19.282930   \n",
       "5592  0.423514   23.458931   20.948090   19.118870   18.525711   18.173027   \n",
       "5605  0.648363   22.301899   21.645138   20.663469   19.834093   19.535355   \n",
       "5835  0.648992   25.440855   22.707363   20.903374   19.688295   19.192822   \n",
       "7164  0.426807   23.751444   20.760584   19.133968   18.386021   18.017616   \n",
       "8306  0.619865   23.423046   22.094854   20.491508   19.485312   18.963287   \n",
       "\n",
       "      mag_y_lsst  \n",
       "525    19.054184  \n",
       "3830   17.970161  \n",
       "4847   19.013233  \n",
       "5592   17.956638  \n",
       "5605   19.293495  \n",
       "5835   18.862762  \n",
       "7164   17.826719  \n",
       "8306   18.576736  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir2 = \"outputs\"\n",
    "out_parent_dir2 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2\"\n",
    "path_outs2 = os.path.join(out_parent_dir2, out_dir2)\n",
    "os.makedirs(path_outs2, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST2+\"/BOSS_TEST2.yml\")\n",
    "pr.run()\n",
    "\n",
    "import pandas as pd\n",
    "df2 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail--new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
