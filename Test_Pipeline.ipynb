{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential Imports: \n",
    "import os\n",
    "import numpy as np\n",
    "import qp\n",
    "import tables_io\n",
    "from pathlib import Path \n",
    "from pzflow.examples import get_galaxy_data\n",
    "import ceci\n",
    "\n",
    "## RAIL-Specific Imports: \n",
    "import rail\n",
    "\n",
    "# old : from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness\n",
    "\n",
    "\n",
    "from rail.creation.degradation.lsst_error_model import LSSTErrorModel\n",
    "from rail.creation.degradation.spectroscopic_degraders import InvRedshiftIncompleteness\n",
    "\n",
    "import rail.creation \n",
    "import rail.creation.engines\n",
    "from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "# old : from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "\n",
    "from rail.estimation.algos.train_z import TrainZEstimator, TrainZInformer\n",
    "from rail.estimation.algos.cmnn import Inform_CMNNPDF, CMNNPDF\n",
    "from rail.estimation.algos.gpz import GPzInformer, GPzEstimator \n",
    "from rail.estimation.algos.pzflow_nf import PZFlowInformer, PZFlowEstimator \n",
    "from rail.estimation.algos.flexzboost import FlexZBoostInformer, FlexZBoostEstimator  \n",
    "\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "\n",
    "## Data Storage: \n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True\n",
    "\n",
    "\n",
    "### CMNN, PZFlow, FlexZBoost, GPZ, trainz for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package rail.estimation.algos in rail.estimation:\n",
      "\n",
      "NAME\n",
      "    rail.estimation.algos\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _gpz_util\n",
      "    bpz_lite\n",
      "    cmnn\n",
      "    delightPZ\n",
      "    delight_version (package)\n",
      "    equal_count\n",
      "    flexzboost\n",
      "    gpz\n",
      "    naive_stack\n",
      "    point_est_hist\n",
      "    pzflow_nf\n",
      "    random_gauss\n",
      "    train_z\n",
      "    uniform_binning\n",
      "    var_inf\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rail.estimation.algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(rail.creation.engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from rail.stages import *\n",
    "#rail.stages.import_and_attach_all()\n",
    "#for val in RailStage.pipeline_stages.values():\n",
    "#    print(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    #path to access the data \n",
    "    DATA_DIR = Path().resolve() / \"data\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    catalog_file = DATA_DIR / \"base_catalog.pq\"\n",
    "\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    \n",
    "    #array of galaxies w/ 7 attributes for each: redshift & ugrizy\n",
    "    catalog = get_galaxy_data().rename(band_dict, axis=1) \n",
    "\n",
    "    #turns array into a table \n",
    "    tables_io.write(catalog, str(catalog_file.with_suffix(\"\")), catalog_file.suffix[1:])\n",
    "\n",
    "    catalog_file = str(catalog_file)\n",
    "    flow_file = str(DATA_DIR / \"trained_flow.pkl\")\n",
    "\n",
    "    print(flow_file)\n",
    "\n",
    "    #we set up the stage \n",
    "    flow_modeler_params = {\n",
    "        \"name\": \"flow_modeler\",\n",
    "        \"input\": catalog_file,\n",
    "        \"model\": flow_file,\n",
    "        \"seed\": 0,\n",
    "        \"phys_cols\": {\"redshift\": [0, 3]},\n",
    "        \"phot_cols\": {\n",
    "            \"mag_u_lsst\": [17, 35],\n",
    "            \"mag_g_lsst\": [16, 32],\n",
    "            \"mag_r_lsst\": [15, 30],\n",
    "            \"mag_i_lsst\": [15, 30],\n",
    "            \"mag_z_lsst\": [14, 29],\n",
    "            \"mag_y_lsst\": [14, 28],\n",
    "        },\n",
    "        \"calc_colors\": {\"ref_column_name\": \"mag_i_lsst\"},\n",
    "    }\n",
    "    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)\n",
    "    # flow_modeler.fit_model()\n",
    "    return flow_modeler, flow_file ##.get_handle(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl\n"
     ]
    }
   ],
   "source": [
    "modelData, flow_file = makeModel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make Training Set and Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSet(ntrain, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'train_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntrain,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSet(ntest, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'test_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntest,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data #.sample(ntest, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Degraders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inverse Redshift Incompleteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invRedshift(pivot = 1.0):\n",
    "    assert type(pivot) == float \n",
    "    degr = InvRedshiftIncompleteness.make_stage(\n",
    "        name = 'inv_redshift',\n",
    "        pivot_redshift = pivot\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "pivot_ls = [1.0, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Choose pivot z's for inverse redshift incompleteness \n",
    "\n",
    "# ## seed1 and ndata should be the same as  seed1 and ntrain used to call bigF!! \n",
    "# ## Otherwise this might not be representative of the real data \n",
    "\n",
    "# def choosePivots(seed1, ndata):\n",
    "#     nums = trainSet(ndata, seed1)\n",
    "#     data = nums.sample(ndata, seed1)\n",
    "#     data_pq = col_remap(data)\n",
    "#     data_table = table_conv(data_pq)\n",
    "#     table = tables_io.convertObj(data_table.data, tables_io.types.PD_DATAFRAME)\n",
    "#     return np.asarray(table['redshift'])\n",
    "\n",
    "# percentiles = np.arange(10, 100, 10)\n",
    "# pivots = [] \n",
    "\n",
    "# for i in percentiles:\n",
    "#     pivot = np.percentile(choosePivots(17, 100000), i) \n",
    "#     pivots.append(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pivots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSST Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "\n",
    "def lsstError(dict, seed): #tvis = 1, nYrObs = 1, airmass = 1, extendedSource = 1, sigmaSys = 1, magLim = 1, ndFlag = 1, A_min = 1, A_max = 1):\n",
    "    deg = LSSTErrorModel.make_stage(\n",
    "        name='lsst_error',\n",
    "        renameDict= dict, \n",
    "        ndFlag=np.nan,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return deg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Quantity Cuts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a dictionary with the different bands and magnitudes you want\n",
    "\n",
    "def quantCuts(band, mag):\n",
    "    quantity_cut = QuantityCut.make_stage(\n",
    "        name='quantity_cut',    \n",
    "        cuts={'mag_i_lsst': 25.0},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcuts_dict = {'mag_u_lsst': [...], \n",
    "              'mag_g_lsst': [...], \n",
    "              'mag_r_lsst': [...], \n",
    "              'mag_i_lsst': [...], \n",
    "              'mag_z_lsst': [...], \n",
    "              'mag_y_lsst': [...] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Survey-Based Degraders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.creation.degradation.spectroscopic_selections import *\n",
    "\n",
    "def specSelectBOSS(ntrain):\n",
    "    degr = SpecSelection_BOSS.make_stage(\n",
    "        name = 'specselection_boss',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectDEEP2(ntrain):\n",
    "    degr = SpecSelection_DEEP2.make_stage(\n",
    "        name = 'specselection_deep2',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectGAMA(ntrain):\n",
    "    degr = SpecSelection_GAMA.make_stage(\n",
    "        name = 'specselection_gama',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectHSC(ntrain):\n",
    "    degr = SpecSelection_HSC.make_stage(\n",
    "        name = 'specselection_HSC',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectVVDSf02(ntrain):\n",
    "    degr = SpecSelection_VVDSf02.make_stage(\n",
    "        name = 'specselection_VVDSf02',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectzCOSMOS(ntrain):\n",
    "    degr = SpecSelection_zCOSMOS.make_stage(\n",
    "        name = 'specselection_zCOSMOS',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(data, model, grid):\n",
    "    posts = FlowPosterior.make_stage(\n",
    "        name='get_posts'+str(data), \n",
    "        column='redshift',\n",
    "        grid = grid,\n",
    "        model = model,\n",
    "        data = data\n",
    "    )\n",
    "    return posts #posts.get_posterior(data, column = 'redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(zmin, zmax, nbins):\n",
    "    import numpy as np\n",
    "    grid = np.linspace(zmin, zmax, nbins + 1)\n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = makeGrid(0, 2.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_train_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_train = FlowPosterior.make_stage(name='orig_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_train)\n",
    "\n",
    "# orig_train_pdfs = flow_post_orig_train.get_posterior(orig_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_train_posts ** rerun this cell!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_train = FlowPosterior.make_stage(name='deg_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              err_samples = 0,\n",
    "#                                              data = deg_train)\n",
    "\n",
    "\n",
    "\n",
    "# deg_train_pdfs = flow_post_deg_train.get_posterior(deg_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_test = FlowPosterior.make_stage(name='orig_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_test)\n",
    "\n",
    "# orig_test_pdfs = flow_post_orig_test.get_posterior(orig_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_test = FlowPosterior.make_stage(name='deg_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = deg_test)\n",
    "\n",
    "# deg_test_pdfs = flow_post_deg_test.get_posterior(deg_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "def colRemapper(dict):\n",
    "    col_remap = ColumnMapper.make_stage(\n",
    "    name='col_remapper', \n",
    "    columns=dict,\n",
    "    )\n",
    "    return col_remap\n",
    "\n",
    "def tableConverter():\n",
    "    table_conv = TableConverter.make_stage(\n",
    "    name='table_conv', \n",
    "    output_format='numpyDict',\n",
    "    )\n",
    "    return table_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_remap = colRemapper(band_dict_err)\n",
    "table_conv = tableConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inform & Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informTrainZ():\n",
    "    inf = TrainZInformer.make_stage(\n",
    "    name = 'inform_TrainZ',\n",
    "    model = 'trainz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateTrainZ(info):\n",
    "    est = TrainZEstimator.make_stage(\n",
    "    name = 'estimate_TrainZ',\n",
    "    model = 'trainz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informCMNN():\n",
    "    inf = Inform_CMNNPDF.make_stage(\n",
    "    name = 'inform_CMNN',\n",
    "    model = 'cmnn.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateCMNN(info):\n",
    "    est = CMNNPDF.make_stage(\n",
    "    name = 'estimate_CMNN',\n",
    "    model = 'cmnn.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informGPz():\n",
    "    inf = GPzInformer.make_stage(\n",
    "    name = 'inform_GPz',\n",
    "    model = 'gpz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateGPz(info):\n",
    "    est = GPzEstimator.make_stage(\n",
    "    name = 'estimate_GPz',\n",
    "    model = 'gpz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informPZFlow():\n",
    "    inf = PZFlowInformer.make_stage(\n",
    "    name = 'inform_PZFlow',\n",
    "    model = 'pzflow.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimatePZFlow(info):\n",
    "    est = PZFlowEstimator.make_stage(\n",
    "    name = 'estimate_PZFlow',\n",
    "    model = 'pzflow.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informFZBoost():\n",
    "    info = FlexZBoostInformer.make_stage(\n",
    "    name ='inform_FZBoost', \n",
    "    model ='fzboost.pkl', \n",
    "    hdf5_groupname='',\n",
    "    )\n",
    "    return info\n",
    "\n",
    "def estimateFZBoost(info):\n",
    "    est = FlexZBoostEstimator.make_stage(\n",
    "    name='est_FZBoost', \n",
    "    nondetect_val=np.nan,\n",
    "    model= info,\n",
    "    hdf5_groupname='',\n",
    "    aliases=dict(input='test_data', output='fzboost_estim'),\n",
    "    nzbins = 100 \n",
    "    )\n",
    "    return est "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'invz': invRedshift,\n",
    "\n",
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } \n",
    "\n",
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ceci \n",
    "\n",
    "# pr = ceci.Pipeline.read(path_lst_1[0])#parent_dir+directory+\"/invz=0.33672517538070684_lsstErr_pzflow.yml\")\n",
    "# pr.run()\n",
    "\n",
    "# ## 1) terminal: go to path up to invz_lsstErr_pzflow, then run these 2 lines \n",
    "# ## 2)  make list/txt file with list of paths to files made by big F\n",
    "\n",
    "# ## do 1) \n",
    "# ## open virtual env\n",
    "# ## python \n",
    "# ## import ceci \n",
    "# ## run the 2 lines of code above \n",
    "\n",
    "\n",
    "# ### at the end we can put this into a .py file that we can run at the command line \n",
    "\n",
    "# ## %cd ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## more config parameters/better config parameters\n",
    "## have to give path above to estimator model instead of get_handle('model')\n",
    "## fix truncated parameter printing in help(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Big F's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl, test_set\n",
      "Inserting handle into data store.  output_test_set: inprogress_output_test_set.pq, test_set\n"
     ]
    }
   ],
   "source": [
    "# Make sure to change the first argument of testSet\n",
    "# testData = testSet(ntest, seed2)\n",
    "\n",
    "testData = testSet(100, 39)\n",
    "testData.run()\n",
    "\n",
    "test_data = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_test_set.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: None, lsst_error\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Unknown file format , supported types are{list(FILE_FORMAT_SUFFIXS.keys())}'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/types.py:206\u001b[0m, in \u001b[0;36mfileType\u001b[0;34m(filepath, fmt)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m FILE_FORMAT_SUFFIXS[fmt]\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m msg:\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 52\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m band_dict_err \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmag_\u001b[39m\u001b[39m{\u001b[39;00mband\u001b[39m}\u001b[39;00m\u001b[39m_lsst_err\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmag_err_\u001b[39m\u001b[39m{\u001b[39;00mband\u001b[39m}\u001b[39;00m\u001b[39m_lsst\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m band \u001b[39min\u001b[39;00m bands}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lsstErr \u001b[39m=\u001b[39m lsstError(band_dict, \u001b[39m172\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lsstErr\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y236sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m lsst_Err \u001b[39m=\u001b[39m DS\u001b[39m.\u001b[39mread_file(\u001b[39m\"\u001b[39m\u001b[39mtest_Data\u001b[39m\u001b[39m\"\u001b[39m, TableHandle, \u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_lsst_error.pq\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/creation/degradation/lsst_error_model.py:55\u001b[0m, in \u001b[0;36mLSSTErrorModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return pandas DataFrame with photometric errors.\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m# Load the input catalog\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_data(\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     57\u001b[0m \u001b[39m# Add photometric errors\u001b[39;00m\n\u001b[1;32m     58\u001b[0m obsData \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_model(data, random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mseed)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/stage.py:248\u001b[0m, in \u001b[0;36mRailStage.get_data\u001b[0;34m(self, tag, allow_missing)\u001b[0m\n\u001b[1;32m    246\u001b[0m handle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_handle(tag, allow_missing\u001b[39m=\u001b[39mallow_missing)\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handle\u001b[39m.\u001b[39mhas_data:\n\u001b[0;32m--> 248\u001b[0m     handle\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m handle()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:62\u001b[0m, in \u001b[0;36mDataHandle.read\u001b[0;34m(self, force, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force:\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n\u001b[0;32m---> 62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mexpandvars(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/core/data.py:205\u001b[0m, in \u001b[0;36mTableHandle._read\u001b[0;34m(cls, path, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read\u001b[39m(\u001b[39mcls\u001b[39m, path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read and return the data from the associated file \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m tables_io\u001b[39m.\u001b[39;49mread(path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:960\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filepath, tType, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(filepath, tType\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_missing_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    939\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \n\u001b[1;32m    941\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m     odict \u001b[39m=\u001b[39m readNative(filepath, fmt, keys, allow_missing_keys)\n\u001b[1;32m    961\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(odict) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m defName \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39m__astropy_table__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/ioUtils.py:921\u001b[0m, in \u001b[0;36mreadNative\u001b[0;34m(filepath, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadNative\u001b[39m(filepath, fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keys\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allow_missing_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    902\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m \n\u001b[1;32m    920\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     fType \u001b[39m=\u001b[39m fileType(filepath, fmt)\n\u001b[1;32m    922\u001b[0m     \u001b[39mif\u001b[39;00m fType \u001b[39m==\u001b[39m ASTROPY_FITS:\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m readFitsToApTables(filepath)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/tables_io/types.py:208\u001b[0m, in \u001b[0;36mfileType\u001b[0;34m(filepath, fmt)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mreturn\u001b[39;00m FILE_FORMAT_SUFFIXS[fmt]\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m msg:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown file format \u001b[39m\u001b[39m{\u001b[39;00mfmt\u001b[39m}\u001b[39;00m\u001b[39m, supported types are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m{\u001b[39m\u001b[39mlist(FILE_FORMAT_SUFFIXS.keys())}\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mmsg\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Unknown file format , supported types are{list(FILE_FORMAT_SUFFIXS.keys())}'"
     ]
    }
   ],
   "source": [
    "#lsstErr = lsstError(band_dict, seed3)\n",
    "\n",
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "lsstErr = lsstError(band_dict, 172)\n",
    "lsstErr.connect_input(test_data) ## might be wrong; passing in a file not a stage \n",
    "lsstErr.run()\n",
    "\n",
    "lsst_Err = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_lsst_error.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for inverse redshift incompleteness:\n",
    "\n",
    "pivot_ls = [1.0, 1.4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF0(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infTrainZ = informTrainZ()\n",
    "    estTrainZ = estimateTrainZ(infTrainZ)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infTrainZ, \n",
    "        estTrainZ]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infTrainZ.connect_input(deg) \n",
    "    estTrainZ.connect_input(infTrainZ, inputTag = 'model')\n",
    "    estTrainZ.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_pzflow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_0 = []\n",
    "directory = \"specSelection_lsstErr_TrainZ\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_0, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_0.append(bigF0(spec_dict[key], key, path_0, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_0_invz = []\n",
    "directory = \"invz_lsstErr_TrainZ\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_0_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_0_invz.append(bigF0(invRedshift(i), 'invz='+str(i), path_0_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infCMNN = informCMNN()\n",
    "    estCMNN = estimateCMNN(infCMNN)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infCMNN, \n",
    "        estCMNN]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infCMNN.connect_input(deg) \n",
    "    estCMNN.connect_input(infCMNN, inputTag = 'model')\n",
    "    estCMNN.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_CMNN.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1 = []\n",
    "directory = \"specSelection_lsstErr_CMNN\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_1.append(bigF1(spec_dict[key], key, path_1, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1_invz = []\n",
    "directory = \"invz_lsstErr_CMNN\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_1_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_1_invz.append(bigF1(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infGPz = informGPz()\n",
    "    estGPz = estimateGPz(infGPz)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infGPz, \n",
    "        estGPz]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infGPz.connect_input(deg) \n",
    "    estGPz.connect_input(infGPz, inputTag = 'model')\n",
    "    estGPz.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_GPz.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2 = []\n",
    "directory = \"specSelection_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_1.append(bigF2(spec_dict[key], key, path_2, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2_invz = []\n",
    "directory = \"invz_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_2_invz.append(bigF2(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PZFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigF3(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    # lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    # estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_PZFlow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(rail.creation.degradation.spectroscopic_selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_3 = []\n",
    "directory = \"specSelection_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage lsst_error is missing input(s): output_test_set\nStage estimate_PZFlow is missing input(s): output_lsst_error\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 66\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m spec_dict:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     path_lst_2\u001b[39m.\u001b[39mappend(bigF2(spec_dict[key], key, \u001b[39m1000\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m39\u001b[39;49m, \u001b[39m172\u001b[39;49m, \u001b[39m10\u001b[39;49m))\n",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 66\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m estPZFlow\u001b[39m.\u001b[39mconnect_input(lsstErr, inputTag \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m## trucated out of docs :(\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# informFZB.connect_input(invRed)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# estFZB.connect_input(informFZB, lsstErr) \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m pipe\u001b[39m.\u001b[39;49minitialize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdict\u001b[39;49m(model\u001b[39m=\u001b[39;49mflow_file), \u001b[39mdict\u001b[39;49m(output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, log_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, resume\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), \u001b[39mNone\u001b[39;49;00m) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m outpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_2, \u001b[39m\"\u001b[39m\u001b[39m% s\u001b[39;00m\u001b[39m_lsstErr_pzflow.yml\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m pipe\u001b[39m.\u001b[39msave(outpath)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:798\u001b[0m, in \u001b[0;36mPipeline.initialize\u001b[0;34m(self, overall_inputs, run_config, stages_config)\u001b[0m\n\u001b[1;32m    795\u001b[0m     v\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_config)\n\u001b[1;32m    797\u001b[0m \u001b[39m# Get the stages in the order we need.\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mordered_stages(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverall_inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstages_config)\n\u001b[1;32m    800\u001b[0m \u001b[39m# Initiate the run.\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# This is an implementation detail for the different subclasses to store\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# necessary information about the run if necessary.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# Usually, the arguments are ignored, but they are provided in case a class needs to\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# do something special with any of them.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitiate_run(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:753\u001b[0m, in \u001b[0;36mPipeline.ordered_stages\u001b[0;34m(self, overall_inputs, stages_config)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 msg1\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStage \u001b[39m\u001b[39m{\u001b[39;00mstage_name\u001b[39m}\u001b[39;00m\u001b[39m is missing input(s): \u001b[39m\u001b[39m{\u001b[39;00mmissing_inputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    752\u001b[0m             msg1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(msg1)\n\u001b[0;32m--> 753\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    755\u001b[0m \u001b[39mSome required inputs to the pipeline could not be found,\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39m(or possibly your pipeline is cyclic):\u001b[39m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39m{\u001b[39;00mmsg1\u001b[39m}\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    760\u001b[0m             )\n\u001b[1;32m    762\u001b[0m         \u001b[39mreturn\u001b[39;00m ordered_stages\n",
      "\u001b[0;31mValueError\u001b[0m: \nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage lsst_error is missing input(s): output_test_set\nStage estimate_PZFlow is missing input(s): output_lsst_error\n"
     ]
    }
   ],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_3.append(bigF3(spec_dict[key], key, path_3, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_3_invz = []\n",
    "directory = \"invz_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_3_invz.append(bigF3(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlexZBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF4(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    # testData = testSet(ntest, seed2)\n",
    "\n",
    "    #lsstErr = lsstError(band_dict, seed3)\n",
    "    infFZBoost = informFZBoost()\n",
    "    estFZBoost = estimateFZBoost(infFZBoost)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        #testData, \n",
    "        #lsstErr,  \n",
    "        infFZBoost, \n",
    "        estFZBoost]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infFZBoost.connect_input(deg) \n",
    "    estFZBoost.connect_input(infFZBoost, inputTag = 'model')\n",
    "    estFZBoost.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_FZBoost.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4 = []\n",
    "directory = \"specSelection_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_4.append(bigF4(spec_dict[key], key, path_4, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4_invz = []\n",
    "directory = \"invz_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_4_invz.append(bigF4(invRedshift(i), 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n",
      "Job inform_PZFlow has completed successfully!\n",
      "\n",
      "Executing estimate_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.PZFlowEstimator   --model=./pzflow.pkl   --input=./output_lsst_error.pq   --name=estimate_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_pzflow/BOSS_lsstErr_pzflow_config.yml   --output=./output_estimate_PZFlow.hdf5 \n",
      "Output writing to ./estimate_PZFlow.out\n",
      "\n",
      "Job estimate_PZFlow has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = ceci.Pipeline.read(path_2+\"/BOSS_lsstErr_pzflow.yml\")\n",
    "pr.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function makedirs in module os:\n",
      "\n",
      "makedirs(name, mode=511, exist_ok=False)\n",
      "    makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "    \n",
      "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "    will be created if it does not exist. If the target directory already\n",
      "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "    raised.  This is recursive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.makedirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        # infPZFlow, \n",
    "        # estPZFlow]\n",
    "    ]    \n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    # infPZFlow.connect_input(deg) \n",
    "    # estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    # estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    # estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST1.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_lst_TEST1 = []\n",
    "directory = \"specSelection_TEST1\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST1 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST1, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST1.append(bigF_TEST1(spec_dict[key], key, path_TEST1, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    #infPZFlow = informPZFlow()\n",
    "    #estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        #infPZFlow, \n",
    "        #estPZFlow]\n",
    "    ]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    # infPZFlow.connect_input(deg) \n",
    "    # estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    # estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    # estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST2.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_lst_TEST2 = []\n",
    "directory = \"specSelection_TEST2\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST2, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST2.append(bigF_TEST2(spec_dict[key], key, path_TEST2, 1000, 100, 17, 39, 172, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir1 = \"outputs\"\n",
    "out_parent_dir1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1\"\n",
    "path_outs1 = os.path.join(out_parent_dir1, out_dir1)\n",
    "os.makedirs(path_outs1, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST1+\"/BOSS_TEST1.yml\")\n",
    "pr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.678802</td>\n",
       "      <td>22.524094</td>\n",
       "      <td>22.298061</td>\n",
       "      <td>21.065384</td>\n",
       "      <td>20.072044</td>\n",
       "      <td>19.666212</td>\n",
       "      <td>19.417404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.496280</td>\n",
       "      <td>22.490469</td>\n",
       "      <td>21.483559</td>\n",
       "      <td>20.207443</td>\n",
       "      <td>19.443588</td>\n",
       "      <td>19.127865</td>\n",
       "      <td>18.890064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "470  0.678802   22.524094   22.298061   21.065384   20.072044   19.666212   \n",
       "557  0.496280   22.490469   21.483559   20.207443   19.443588   19.127865   \n",
       "\n",
       "     mag_y_lsst  \n",
       "470   19.417404  \n",
       "557   18.890064  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.678802</td>\n",
       "      <td>22.524094</td>\n",
       "      <td>22.298061</td>\n",
       "      <td>21.065384</td>\n",
       "      <td>20.072044</td>\n",
       "      <td>19.666212</td>\n",
       "      <td>19.417404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.496280</td>\n",
       "      <td>22.490469</td>\n",
       "      <td>21.483559</td>\n",
       "      <td>20.207443</td>\n",
       "      <td>19.443588</td>\n",
       "      <td>19.127865</td>\n",
       "      <td>18.890064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "470  0.678802   22.524094   22.298061   21.065384   20.072044   19.666212   \n",
       "557  0.496280   22.490469   21.483559   20.207443   19.443588   19.127865   \n",
       "\n",
       "     mag_y_lsst  \n",
       "470   19.417404  \n",
       "557   18.890064  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir2 = \"outputs\"\n",
    "out_parent_dir2 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2\"\n",
    "path_outs2 = os.path.join(out_parent_dir2, out_dir2)\n",
    "os.makedirs(path_outs2, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST2+\"/BOSS_TEST2.yml\")\n",
    "pr.run()\n",
    "\n",
    "import pandas as pd\n",
    "df2 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "470      True        True        True        True        True        True   \n",
       "557      True        True        True        True        True        True   \n",
       "\n",
       "     mag_y_lsst  \n",
       "470        True  \n",
       "557        True  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 == df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "470       0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "557       0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     mag_y_lsst  \n",
       "470         0.0  \n",
       "557         0.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 - df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail--new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
