{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential Imports: \n",
    "import os\n",
    "import numpy as np\n",
    "import qp\n",
    "import tables_io\n",
    "from pathlib import Path \n",
    "from pzflow.examples import get_galaxy_data\n",
    "import ceci\n",
    "\n",
    "## RAIL-Specific Imports: \n",
    "import rail\n",
    "\n",
    "# old : from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness\n",
    "\n",
    "\n",
    "from rail.creation.degradation.lsst_error_model import LSSTErrorModel\n",
    "from rail.creation.degradation.spectroscopic_degraders import InvRedshiftIncompleteness\n",
    "\n",
    "import rail.creation \n",
    "import rail.creation.engines\n",
    "from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "# old : from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "\n",
    "from rail.estimation.algos.train_z import TrainZEstimator, TrainZInformer\n",
    "from rail.estimation.algos.cmnn import Inform_CMNNPDF, CMNNPDF\n",
    "from rail.estimation.algos.gpz import GPzInformer, GPzEstimator \n",
    "from rail.estimation.algos.pzflow_nf import PZFlowInformer, PZFlowEstimator \n",
    "from rail.estimation.algos.flexzboost import FlexZBoostInformer, FlexZBoostEstimator  \n",
    "\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "\n",
    "## Data Storage: \n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True\n",
    "\n",
    "\n",
    "### CMNN, PZFlow, FlexZBoost, GPZ, trainz for control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package rail.estimation.algos in rail.estimation:\n",
      "\n",
      "NAME\n",
      "    rail.estimation.algos\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _gpz_util\n",
      "    bpz_lite\n",
      "    cmnn\n",
      "    delightPZ\n",
      "    delight_version (package)\n",
      "    equal_count\n",
      "    flexzboost\n",
      "    gpz\n",
      "    naive_stack\n",
      "    point_est_hist\n",
      "    pzflow_nf\n",
      "    random_gauss\n",
      "    train_z\n",
      "    uniform_binning\n",
      "    var_inf\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rail.estimation.algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from rail.stages import *\n",
    "#rail.stages.import_and_attach_all()\n",
    "#for val in RailStage.pipeline_stages.values():\n",
    "#    print(val[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    #path to access the data \n",
    "    DATA_DIR =  Path().resolve() / \"data\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    catalog_file = DATA_DIR / \"base_catalog.pq\"\n",
    "\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    # band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "    # band_dict_err = {f'mag_err_{band}_lsst' for band in bands}\n",
    "    \n",
    "    #array of galaxies w/ 7 attributes for each: redshift & ugrizy\n",
    "    catalog = get_galaxy_data().rename(band_dict, axis=1) \n",
    "\n",
    "    #turns array into a table \n",
    "    tables_io.write(catalog, str(catalog_file.with_suffix(\"\")), catalog_file.suffix[1:])\n",
    "\n",
    "    catalog_file = str(catalog_file)\n",
    "    flow_file = str(DATA_DIR / \"trained_flow.pkl\")\n",
    "\n",
    "    print(flow_file)\n",
    "\n",
    "    #we set up the stage \n",
    "    flow_modeler_params = {\n",
    "        \"name\": \"flow_modeler\",\n",
    "        \"input\": catalog_file,\n",
    "        \"model\": flow_file,\n",
    "        \"seed\": 0,\n",
    "        \"phys_cols\": {\"redshift\": [0, 3]},\n",
    "        \"phot_cols\": {\n",
    "            \"mag_u_lsst\": [17, 35],\n",
    "            \"mag_g_lsst\": [16, 32],\n",
    "            \"mag_r_lsst\": [15, 30],\n",
    "            \"mag_i_lsst\": [15, 30],\n",
    "            \"mag_z_lsst\": [14, 29],\n",
    "            \"mag_y_lsst\": [14, 28],\n",
    "        },\n",
    "        \"calc_colors\": {\"ref_column_name\": \"mag_i_lsst\"},\n",
    "    }\n",
    "    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)\n",
    "    # flow_modeler.fit_model()\n",
    "    return flow_modeler, flow_file ##.get_handle(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl\n"
     ]
    }
   ],
   "source": [
    "modelData, flow_file = makeModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                    \u001b[34mqp\u001b[m\u001b[m\n",
      "Test_Pipeline.ipynb          \u001b[34mspecSelection_TEST1\u001b[m\u001b[m\n",
      "\u001b[34mdata\u001b[m\u001b[m                         \u001b[34mspecSelection_TEST2\u001b[m\u001b[m\n",
      "output_flow_creator_test.pq  trained_flow.pkl\n",
      "output_flow_creator_train.pq \u001b[34muntitled folder\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make Training Set and Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSet(ntrain, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'train_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntrain,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSet(ntest, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'test_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntest,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data #.sample(ntest, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Degraders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inverse Redshift Incompleteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invRedshift(pivot = 1.0):\n",
    "    assert type(pivot) == float \n",
    "    degr = InvRedshiftIncompleteness.make_stage(\n",
    "        name = 'inv_redshift',\n",
    "        pivot_redshift = pivot\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "pivot_ls = [1.0, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Choose pivot z's for inverse redshift incompleteness \n",
    "\n",
    "# ## seed1 and ndata should be the same as  seed1 and ntrain used to call bigF!! \n",
    "# ## Otherwise this might not be representative of the real data \n",
    "\n",
    "# def choosePivots(seed1, ndata):\n",
    "#     nums = trainSet(ndata, seed1)\n",
    "#     data = nums.sample(ndata, seed1)\n",
    "#     data_pq = col_remap(data)\n",
    "#     data_table = table_conv(data_pq)\n",
    "#     table = tables_io.convertObj(data_table.data, tables_io.types.PD_DATAFRAME)\n",
    "#     return np.asarray(table['redshift'])\n",
    "\n",
    "# percentiles = np.arange(10, 100, 10)\n",
    "# pivots = [] \n",
    "\n",
    "# for i in percentiles:\n",
    "#     pivot = np.percentile(choosePivots(17, 100000), i) \n",
    "#     pivots.append(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pivots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSST Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "\n",
    "def lsstError(dict, seed): \n",
    "    deg = LSSTErrorModel.make_stage(\n",
    "        name='lsst_error',\n",
    "        renameDict= dict, \n",
    "        ndFlag=np.nan,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return deg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module rail.creation.degradation.lsst_error_model in rail.creation.degradation:\n",
      "\n",
      "NAME\n",
      "    rail.creation.degradation.lsst_error_model - The LSST Model for photometric errors.\n",
      "\n",
      "CLASSES\n",
      "    rail.creation.degrader.Degrader(rail.core.stage.RailStage)\n",
      "        LSSTErrorModel\n",
      "    \n",
      "    class LSSTErrorModel(rail.creation.degrader.Degrader)\n",
      "     |  LSSTErrorModel(args, comm=None)\n",
      "     |  \n",
      "     |  The LSST Model for photometric errors.\n",
      "     |  \n",
      "     |  This is a wrapper around the error model from PhotErr. The parameter\n",
      "     |  docstring below is dynamically added by the installed version of PhotErr:\n",
      "     |  \n",
      "     |  Parameters for the LSST photometric error model.\n",
      "     |  \n",
      "     |  Default values taken from pages 11, 12, 26 of Ivezic 2019.\n",
      "     |  \n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  nYrObs : float\n",
      "     |      Number of years of observations\n",
      "     |  nVisYr : dict\n",
      "     |      Mean number of visits per year in each band\n",
      "     |  gamma : dict\n",
      "     |      A band dependent parameter defined in Ivezic 2019\n",
      "     |  m5 : dict\n",
      "     |      A dictionary of single visit 5-sigma limiting magnitudes. For any\n",
      "     |      bands for which you pass a value in m5, this will be the 5-sigma\n",
      "     |      limiting magnitude used, and any values for that band in Cm, msky,\n",
      "     |      theta, and km will be ignored.\n",
      "     |  tvis : float\n",
      "     |      Exposure time in seconds for a single visit\n",
      "     |  airmass : float\n",
      "     |      The fiducial airmass\n",
      "     |  Cm : dict\n",
      "     |      A band dependent parameter defined in Ivezic 2019\n",
      "     |  msky : dict\n",
      "     |      Median zenith sky brightness in each band, in AB mag / arcsec^2.\n",
      "     |  theta : dict\n",
      "     |      Median zenith seeing FWHM in arcseconds for each band\n",
      "     |  km : dict\n",
      "     |      Atmospheric extinction in each band\n",
      "     |  sigmaSys : float; default=0.005\n",
      "     |      The irreducible error of the system in AB magnitudes. Sets the minimum\n",
      "     |      photometric error.\n",
      "     |  sigLim : float; default=0\n",
      "     |      The n-sigma detection limit. Magnitudes beyond this limit are treated as\n",
      "     |      non-detections. For example, if sigLim=1, then all magnitudes beyond the\n",
      "     |      1-sigma limit in each band are treated as non-detections. sigLim=0\n",
      "     |      corresponds to only treating negative fluxes as non-detections.\n",
      "     |  ndMode : str; default=\"flag\"\n",
      "     |      The non-detection mode. I.e. how should the model handle non-detections?\n",
      "     |      Non-detections are defined as magnitudes beyond sigLim (see above).\n",
      "     |      There are two options:\n",
      "     |          - \"flag\" - non-detections are flagged using the ndFlag (see below)\n",
      "     |          - \"sigLim\" - magnitudes are clipped at the n-sigma limits. I.e. if\n",
      "     |              sigLim=1 above, then all magnitudes greater than the 1-sigma limit\n",
      "     |              in each band are replaced with the 1-sigma limiting magnitude.\n",
      "     |  ndFlag : float; default=np.inf\n",
      "     |      Flag for non-detections when ndMode == \"flag\".\n",
      "     |  absFlux : bool; default=False\n",
      "     |      Whether to take the absolute value of \"observed\" fluxes, before converting\n",
      "     |      back to magnitudes. This removes the possibility of negative fluxes.\n",
      "     |      absFlux=True together with sigLim=0 ensures that every galaxy is assigned\n",
      "     |      an observed magnitude in every band, which is useful if you do not want to\n",
      "     |      worry about non-detections.\n",
      "     |  extendedType: str; default=\"point\"\n",
      "     |      Whether to use the error model for point sources or extended sources.\n",
      "     |      For point sources, use \"point\". For extended sources, you can use \"auto\"\n",
      "     |      or \"gaap\". See Notes below for more details on these models.\n",
      "     |  aMin : float; default=2.0\n",
      "     |      The minimum GAaP aperture diameter in arcseconds.\n",
      "     |  aMax : float; default=0.7\n",
      "     |      The maximum GAaP aperture diameter in arcseconds.\n",
      "     |  majorCol : str; default=\"major\"\n",
      "     |      The name of the column containing the semi-major axes of the galaxies (in\n",
      "     |      arcseconds). The length scales corresponds to the half-light radius.\n",
      "     |  minorCol : str; default=\"minor\"\n",
      "     |      The name of the column containing the semi-minor axes of the galaxies (in\n",
      "     |      arcseconds). The length scales corresponds to the half-light radius.\n",
      "     |  decorrelate : bool; default=True\n",
      "     |      Whether or not to decorrelate the photometric errors. If True, after calculating\n",
      "     |      observed magnitudes, the errors are re-calculated using the observed magnitudes.\n",
      "     |      If False, the original photometric errors are returned. Be warned, however,\n",
      "     |      that in this case, the returned photometric errors are calculated from the true\n",
      "     |      magnitudes, and thus provide a deterministic link back to the true magnitudes!\n",
      "     |  highSNR : bool; default=False\n",
      "     |      Whether to use the high SNR approximations given in Ivezic 2019. If False,\n",
      "     |      then Eq. 5 from that paper is used to calculate (N/S)^2 in flux, and errors\n",
      "     |      are Gaussian in flux space. If True, Eq. 5 is used to calculate the Gaussian\n",
      "     |      variance in magnitude space.\n",
      "     |  scale : dict; default=dict()\n",
      "     |      A dictionary that rescales the error for the given bands. For example, if\n",
      "     |      scale = {\"u\": 2}, then all the errors for the u band are doubled. This allows\n",
      "     |      you to answer questions like \"what happens to my science if the u band errors\n",
      "     |      are doubled.\"\n",
      "     |  errLoc: str; default=\"after\"\n",
      "     |      Where to place the error columns in the output table. If \"after\", then the\n",
      "     |      error columns will be placed immediately after the corresponding magnitude\n",
      "     |      columns. If \"end\", then all of the error columns will be placed at the end\n",
      "     |      of the table. If \"alone\", then the errors will be returned by themselves.\n",
      "     |  renameDict : dict; optional\n",
      "     |      A dictionary used to rename the bands in the parameters above that are\n",
      "     |      dictionaries. This is useful if you want to use some of the default parameters\n",
      "     |      but have given your bands different names. For example, if your bands are named\n",
      "     |      \"lsst_u\", \"lsst_g\", etc., then you can provide\n",
      "     |      renameDict={\"u\": \"lsst_u\", \"g\": \"lsst_g\", ...}, and all of the default\n",
      "     |      parameters will be renamed. Additionally, if you are overriding any of the\n",
      "     |      default dictionary parameters, you can provide those overrides using *either*\n",
      "     |      the old or the new naming scheme.\n",
      "     |  validate : bool; True\n",
      "     |      Whether or not to validate all the parameters.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Parameters for the error model from Ivezic 2019. We also implement a more general\n",
      "     |  model that is also accurate in the low-SNR regime, and include errors for extended\n",
      "     |  sources using the elliptical models from van den Busch 2020 (the \"auto\" model) and\n",
      "     |  Kuijken 2019 (the \"gaap\" model). The \"gaap\" model identical to the \"auto\" model,\n",
      "     |  except that it has minimum and maximum aperture sizes.\n",
      "     |  \n",
      "     |  When using the model for extended sources, you must provide the semi-major and\n",
      "     |  semi-minor axes of the galaxies in arcseconds. These must be in columns whose\n",
      "     |  names are given by majorCol and minorCol. In addition, you must provide the PSF\n",
      "     |  size for each band in the theta dictionary (see above).\n",
      "     |  \n",
      "     |  Whether you are using the point source or extended source models, you must provide\n",
      "     |  nVisYr and gamma for every band you wish to calculate errors for. In addition,\n",
      "     |  you must provide either:\n",
      "     |  - the single-visit 5-sigma limiting magnitude in the m5 dictionary\n",
      "     |  - tvis and airmass, plus per-band parameters in the Cm, msky, theta, and km\n",
      "     |      dictionaries, which are used to calculate the limiting magnitudes using\n",
      "     |      Eq. 6 from Ivezic 2019.\n",
      "     |  \n",
      "     |  Note if for any bands you pass a value in the m5 dictionary, the model will use\n",
      "     |  that value for that band, regardless of the values in Cm, msky, theta, and km.\n",
      "     |  \n",
      "     |  When instantiating the ErrorParams object, it will determine which bands it has\n",
      "     |  enough information to calculate errors for, and throw away all of the extraneous\n",
      "     |  parameters. If you expect errors in a certain band, but the error model is not\n",
      "     |  calculating errors for that band, check that you have provided all of the required\n",
      "     |  parameters for that band.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Ivezic 2019 - https://arxiv.org/abs/0805.2366\n",
      "     |  van den Busch 2020 - http://arxiv.org/abs/2007.01846\n",
      "     |  Kuijken 2019 - https://arxiv.org/abs/1902.11265\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LSSTErrorModel\n",
      "     |      rail.creation.degrader.Degrader\n",
      "     |      rail.core.stage.RailStage\n",
      "     |      ceci.stage.PipelineStage\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, args, comm=None)\n",
      "     |      Constructor\n",
      "     |      \n",
      "     |      Does standard Degrader initialization and sets up the error model.\n",
      "     |  \n",
      "     |  run(self)\n",
      "     |      Return pandas DataFrame with photometric errors.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  config_options = {'Cm': <ceci.config.StageParameter object>, 'aMax': <...\n",
      "     |  \n",
      "     |  default = True\n",
      "     |  \n",
      "     |  key = 'validate'\n",
      "     |  \n",
      "     |  name = 'LSSTErrorModel'\n",
      "     |  \n",
      "     |  val = Field(name='validate',type='InitVar[bool]',defau...oxy({}),kw_on...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.creation.degrader.Degrader:\n",
      "     |  \n",
      "     |  __call__(self, sample, seed: int = None)\n",
      "     |      The main interface method for `Degrader`\n",
      "     |      \n",
      "     |      Applies degradation.\n",
      "     |      \n",
      "     |      This will attach the sample to this `Degrader`\n",
      "     |      (for introspection and provenance tracking).\n",
      "     |      \n",
      "     |      Then it will call the run() and finalize() methods, which need to\n",
      "     |      be implemented by the sub-classes.\n",
      "     |      \n",
      "     |      The run() method will need to register the data that it creates to this Estimator\n",
      "     |      by using `self.add_data('output', output_data)`.\n",
      "     |      \n",
      "     |      Finally, this will return a PqHandle providing access to that output data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample : table-like\n",
      "     |          The sample to be degraded\n",
      "     |      seed : int, default=None\n",
      "     |          An integer to set the numpy random seed\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      output_data : `PqHandle`\n",
      "     |          A handle giving access to a table with degraded sample\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.creation.degrader.Degrader:\n",
      "     |  \n",
      "     |  inputs = [('input', <class 'rail.core.data.PqHandle'>)]\n",
      "     |  \n",
      "     |  outputs = [('output', <class 'rail.core.data.PqHandle'>)]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  add_data(self, tag, data=None)\n",
      "     |      Adds a handle to the DataStore associated to a particular tag and\n",
      "     |      attaches data to it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  add_handle(self, tag, data=None, path=None)\n",
      "     |      Adds a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any or None\n",
      "     |          If not None these data will be associated to the handle\n",
      "     |      path : str or None\n",
      "     |          If not None, this will be the path used to read the data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that gives access to the associated data\n",
      "     |  \n",
      "     |  connect_input(self, other, inputTag=None, outputTag=None)\n",
      "     |      Connect another stage to this stage as an input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : RailStage\n",
      "     |           The stage whose output is being connected\n",
      "     |      inputTag : str\n",
      "     |           Which input tag of this stage to connect to.  None -> self.inputs[0]\n",
      "     |      outputTag : str\n",
      "     |           Which output tag of the other stage to connect to.  None -> other.outputs[0]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : The input handle for this stage\n",
      "     |  \n",
      "     |  get_data(self, tag, allow_missing=True)\n",
      "     |      Gets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. This gets the data via the DataHandle, and can and will read the data\n",
      "     |      from disk if needed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  get_handle(self, tag, path=None, allow_missing=False)\n",
      "     |      Gets a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      path : str or None\n",
      "     |          The path to the data, only needed if we might need to read the data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that give access to the associated data\n",
      "     |  \n",
      "     |  input_iterator(self, tag, **kwargs)\n",
      "     |      Iterate the input assocated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      \n",
      "     |      kwargs : dict[str, Any]\n",
      "     |          These will be passed to the Handle's iterator method\n",
      "     |  \n",
      "     |  set_data(self, tag, data, path=None, do_read=True)\n",
      "     |      Sets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. If data is a DataHandle and tag is one of the input tags,\n",
      "     |      then this will add an alias between the two, i.e., it will\n",
      "     |      set `self.config.alias[tag] = data.tag`.  This allows the user to\n",
      "     |      make connections between stages simply by passing DataHandles between\n",
      "     |      them.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |          The data being set,\n",
      "     |      path : str or None\n",
      "     |          Can be used to set the path for the data\n",
      "     |      do_read : bool\n",
      "     |          If True, will read the data if it is not set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  build(**kwargs) from builtins.type\n",
      "     |      Return an object that can be used to build a stage\n",
      "     |  \n",
      "     |  make_and_connect(**kwargs) from builtins.type\n",
      "     |      Make a stage and connects it to other stages\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      kwargs are used to set stage configuration,\n",
      "     |      the should be key, value pairs, where the key\n",
      "     |      is the parameter name and the value is value we want to assign\n",
      "     |      \n",
      "     |      The 'connections' keyword is special, it is a dict[str, DataHandle]\n",
      "     |      and should define the Input connections for this stage\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A stage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  data_store = DataStore\n",
      "     |  {  model:<class 'rail.tools.flow_handl...e.data...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  already_finished(self)\n",
      "     |      Print a warning that a stage is being skipped\n",
      "     |  \n",
      "     |  check_io(self, args=None)\n",
      "     |      Check the inputs and outputs.\n",
      "     |      This function is seperate so that when Stages are configured interactively after\n",
      "     |      construction then can invove this\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  data_ranges_by_rank(self, n_rows, chunk_rows, parallel=True)\n",
      "     |      Split a number of rows by process.\n",
      "     |      \n",
      "     |      Given a total number of rows to read and a chunk size, yield\n",
      "     |      the ranges within them that this process should handle.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_rows: int\n",
      "     |          Total number of rows to split up\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Size of each chunk to be read.\n",
      "     |      \n",
      "     |      Parallel: bool\n",
      "     |          Whether to split data by rank or just give all procs all data.\n",
      "     |          Default=True\n",
      "     |  \n",
      "     |  finalize(self)\n",
      "     |      Finalize the stage, moving all its outputs to their final locations.\n",
      "     |  \n",
      "     |  find_inputs(self, pipeline_files)\n",
      "     |      Find and retrun all the inputs associated to this stage in the FileManager\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  find_outputs(self, outdir)\n",
      "     |      Find and retrun all the outputs associated to this stage\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  get_aliased_tag(self, tag)\n",
      "     |      Returns the possibly remapped value for an input or output tag\n",
      "     |      \n",
      "     |      Parameter\n",
      "     |      ---------\n",
      "     |      tag : `str`\n",
      "     |          The input or output tag we are checking\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aliased_tag : `str`\n",
      "     |          The aliases version of the tag\n",
      "     |  \n",
      "     |  get_aliases(self)\n",
      "     |      Returns the dictionary of aliases used to remap inputs and outputs\n",
      "     |      in the case that we want to have multiple instance of this class in the pipeline\n",
      "     |  \n",
      "     |  get_config_dict(self, ignore=None, reduce_config=False)\n",
      "     |      Write the current configuration to a dict\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ignore : dict or None\n",
      "     |          Global parameters not to write\n",
      "     |      reduce_config : bool\n",
      "     |          If true, reduce the configuration by parsing out the inputs, outputs and global params\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out_dict : dict\n",
      "     |          The configuration\n",
      "     |  \n",
      "     |  get_input(self, tag)\n",
      "     |      Return the path of an input file with the given tag,\n",
      "     |      which can be aliased.\n",
      "     |  \n",
      "     |  get_input_type(self, tag)\n",
      "     |      Return the file type class of an input file with the given tag.\n",
      "     |  \n",
      "     |  get_output(self, tag, final_name=False)\n",
      "     |      Return the path of an output file with the given tag,\n",
      "     |      which can be aliased already.\n",
      "     |      \n",
      "     |      If final_name is False then use a temporary name - file will\n",
      "     |      be moved to its final name at the end\n",
      "     |  \n",
      "     |  get_output_type(self, tag)\n",
      "     |      Return the file type class of an output file with the given tag.\n",
      "     |  \n",
      "     |  is_dask(self)\n",
      "     |      Returns True if the stage is being run in parallel with Dask.\n",
      "     |  \n",
      "     |  is_mpi(self)\n",
      "     |      Returns True if the stage is being run under MPI.\n",
      "     |  \n",
      "     |  is_parallel(self)\n",
      "     |      Returns True if the code is being run in parallel.\n",
      "     |      Right now is_parallel() will return the same value as is_mpi(),\n",
      "     |      but that may change in future if we implement other forms of\n",
      "     |      parallelization.\n",
      "     |  \n",
      "     |  iterate_fits(self, tag, hdunum, cols, chunk_rows, parallel=True)\n",
      "     |      Loop through chunks of the input data from a FITS file with the given tag\n",
      "     |      \n",
      "     |      TODO: add ceci tests of this functions\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      hdunum: int\n",
      "     |          The extension number to read\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, array) tuples of (start, end, data)\n",
      "     |          data is a structured array.\n",
      "     |  \n",
      "     |  iterate_hdf(self, tag, group_name, cols, chunk_rows, parallel=True, longest=False)\n",
      "     |      Loop through chunks of the input data from an HDF5 file with the given tag.\n",
      "     |      \n",
      "     |      All the selected columns must have the same length.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      group: str\n",
      "     |          The group within the HDF5 file to use, looked up as\n",
      "     |          file[group]\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      longest: bool\n",
      "     |          Whether to allow mixed length arrays and keep going until the longest\n",
      "     |          array is completed, returning empty arrays for shorter ones\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, dict) tuples of (start, end, data)\n",
      "     |  \n",
      "     |  load_configs(self, args)\n",
      "     |      Load the configuraiton\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  map_tasks_by_rank(self, function, inputs, allgather=False)\n",
      "     |      Run a function over a series of inputs, in parallel\n",
      "     |      \n",
      "     |      This mirrors the map function, and returns the equivalent of\n",
      "     |      [function(input) for input in inputs], but executes in parallel.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      function: Callable\n",
      "     |          Function to be run on each item in inputs\n",
      "     |      \n",
      "     |      inputs: Iterable\n",
      "     |          Any sequence of inputs, which should be the same\n",
      "     |          on all processes. Or at least the same length:\n",
      "     |          inputs not assigned to this process are ignored so\n",
      "     |          you could get away with a dummy input for them.\n",
      "     |      \n",
      "     |      allgather: bool\n",
      "     |          Whether to give all ranks the results (True) or just the\n",
      "     |          root process (False). Default = False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results: list\n",
      "     |          A list of the results of calling the function on each input,\n",
      "     |          in the same order as the input tasks\n",
      "     |  \n",
      "     |  open_input(self, tag, wrapper=False, **kwargs)\n",
      "     |      Find and open an input file with the given tag, in read-only mode.\n",
      "     |      \n",
      "     |      For general files this will simply return a standard\n",
      "     |      python file object.\n",
      "     |      \n",
      "     |      For specialized file types like FITS or HDF5 it will return\n",
      "     |      a more specific object - see the types.py file for more info.\n",
      "     |  \n",
      "     |  open_output(self, tag, wrapper=False, final_name=False, **kwargs)\n",
      "     |      Find and open an output file with the given tag, in write mode.\n",
      "     |      \n",
      "     |      If final_name is True then they will be opened using their final\n",
      "     |      target output name.  Otherwise we will prepend \"inprogress_\" to their\n",
      "     |      file name. This means we know that if the final file exists then it\n",
      "     |      is completed.\n",
      "     |      \n",
      "     |      If wrapper is True this will return an instance of the class\n",
      "     |      of the file as specified in the cls.outputs.  Otherwise it will\n",
      "     |      return an open file object (standard python one or something more\n",
      "     |      specialized).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      tag: str\n",
      "     |          Tag as listed in self.outputs\n",
      "     |      \n",
      "     |      wrapper: bool\n",
      "     |          Default=False.  Whether to return a wrapped file\n",
      "     |      \n",
      "     |      final_name: bool\n",
      "     |          Default=False. Whether to save to\n",
      "     |      \n",
      "     |      **kwargs:\n",
      "     |          Extra args are passed on to the file's class constructor.\n",
      "     |  \n",
      "     |  print_io(self, stream=<ipykernel.iostream.OutStream object at 0x1045ebe20>)\n",
      "     |      Print out the tags, paths and types for all the inputs and outputs of this stage\n",
      "     |  \n",
      "     |  read_config(self, args)\n",
      "     |      This function looks for the arguments of the pipeline stage using a\n",
      "     |      combination of default values, command line options and separate\n",
      "     |      configuration file.\n",
      "     |      \n",
      "     |      The order for resolving config options is first looking for a default\n",
      "     |      value, then looking for a\n",
      "     |      \n",
      "     |      In case a mandatory argument (argument with no default) is missing,\n",
      "     |      an exception is raised.\n",
      "     |      \n",
      "     |      Note that we recognize arguments with no default as the ones where\n",
      "     |      self.config_options holds a type instead of a value.\n",
      "     |  \n",
      "     |  setup_mpi(self, comm=None)\n",
      "     |      Setup the MPI interface\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      comm: MPI communicator\n",
      "     |          (default is None) An MPI comm object to use in preference to COMM_WORLD\n",
      "     |  \n",
      "     |  should_skip(self, run_config)\n",
      "     |      Return true if we should skip a stage b/c it's outputs already exist and we are in resume mode\n",
      "     |  \n",
      "     |  split_tasks_by_rank(self, tasks)\n",
      "     |      Iterate through a list of items, yielding ones this process is responsible for/\n",
      "     |      \n",
      "     |      Tasks are allocated in a round-robin way.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tasks: iterable\n",
      "     |          Tasks to split up\n",
      "     |  \n",
      "     |  start_dask(self)\n",
      "     |      Prepare dask to run under MPI. After calling this method\n",
      "     |      only a single process, MPI rank 1 will continue to exeute code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Python 3.6+ provides a facility to automatically\n",
      "     |      call a method (this one) whenever a new subclass\n",
      "     |      is defined.  In this case we use that feature to keep\n",
      "     |      track of all available pipeline stages, each of which is\n",
      "     |      defined by a class.\n",
      "     |  \n",
      "     |  execute(args, comm=None) from builtins.type\n",
      "     |      Create an instance of this stage and run it\n",
      "     |      with the specified inputs and outputs.\n",
      "     |      \n",
      "     |      This is calld by the main method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: namespace\n",
      "     |          The argparse namespace for this subclass.\n",
      "     |  \n",
      "     |  generate_command(inputs, config, outputs, aliases=None, instance_name=None) from builtins.type\n",
      "     |      Generate a command line that will run the stage\n",
      "     |  \n",
      "     |  generate_cwl(log_dir=None) from builtins.type\n",
      "     |      Produces a CWL App object which can then be exported to yaml\n",
      "     |  \n",
      "     |  get_module() from builtins.type\n",
      "     |      Return the path to the python package containing the current sub-class\n",
      "     |      \n",
      "     |      If we have a PipelineStage subclass defined in a module called \"bar\", in\n",
      "     |      a package called \"foo\" e.g.:\n",
      "     |      /path/to/foo/bar.py  <--   contains subclass \"Baz\"\n",
      "     |      \n",
      "     |      Then calling Baz.get_module() will return \"foo.bar\".\n",
      "     |      \n",
      "     |      We use this later to construct command lines like \"python -m foo Baz\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      module: str\n",
      "     |          The module containing this class.\n",
      "     |  \n",
      "     |  get_stage(name, module_name=None) from builtins.type\n",
      "     |      Return the PipelineStage subclass with the given name.\n",
      "     |      \n",
      "     |      This is used so that we do not need a new entry point __main__ function\n",
      "     |      for each new stage - instead we can just use a single one which can query\n",
      "     |      which class it should be using based on the name.\n",
      "     |      \n",
      "     |      If module_name is provided, this will import that module\n",
      "     |      in order to load the required class.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cls: class\n",
      "     |          The corresponding subclass\n",
      "     |  \n",
      "     |  input_tags() from builtins.type\n",
      "     |      Return the list of input tags required by this stage\n",
      "     |  \n",
      "     |  inputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  main() from builtins.type\n",
      "     |      Create an instance of this stage and execute it with\n",
      "     |      inputs and outputs taken from the command line\n",
      "     |  \n",
      "     |  make_stage(**kwargs) from builtins.type\n",
      "     |      Make a stage of a particular type\n",
      "     |  \n",
      "     |  output_tags() from builtins.type\n",
      "     |      Return the list of output tags required by this stage\n",
      "     |  \n",
      "     |  outputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  parse_command_line(cmd=None) from builtins.type\n",
      "     |      Set up and argument parser and parse the command line\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cmd : str or None\n",
      "     |          The command line to part (if None this will use the system arguments)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      args : Namespace\n",
      "     |          The resulting Mapping of arguement to values\n",
      "     |  \n",
      "     |  usage() from builtins.type\n",
      "     |      Print a usage message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  stop_dask()\n",
      "     |      End the dask event loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  comm\n",
      "     |      The MPI communicator object (None if not running under MPI)\n",
      "     |  \n",
      "     |  config\n",
      "     |      Returns the configuration dictionary for this stage, aggregating command\n",
      "     |      line options and optional configuration file.\n",
      "     |  \n",
      "     |  instance_name\n",
      "     |      Return the name associated to this particular instance of this stage\n",
      "     |  \n",
      "     |  rank\n",
      "     |      The rank of this process under MPI (0 if not running under MPI)\n",
      "     |  \n",
      "     |  size\n",
      "     |      The number or processes under MPI (1 if not running under MPI)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  allow_reload = False\n",
      "     |  \n",
      "     |  dask_parallel = False\n",
      "     |  \n",
      "     |  doc = ''\n",
      "     |  \n",
      "     |  incomplete_pipeline_stages = {'CatInformer': (<class 'rail.estimation....\n",
      "     |  \n",
      "     |  parallel = True\n",
      "     |  \n",
      "     |  pipeline_stages = {'CMNNPDF': (<class 'rail.estimation.algos.cmnn.CMNN...\n",
      "\n",
      "DATA\n",
      "    MISSING = <dataclasses._MISSING_TYPE object>\n",
      "\n",
      "FILE\n",
      "    /Users/alicec03/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/creation/degradation/lsst_error_model.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rail.creation.degradation.lsst_error_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Quantity Cuts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a dictionary with the different bands and magnitudes you want\n",
    "\n",
    "def quantCuts(band, mag):\n",
    "    quantity_cut = QuantityCut.make_stage(\n",
    "        name='quantity_cut',    \n",
    "        cuts={'mag_i_lsst': 25.0},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcuts_dict = {'mag_u_lsst': [...], \n",
    "              'mag_g_lsst': [...], \n",
    "              'mag_r_lsst': [...], \n",
    "              'mag_i_lsst': [...], \n",
    "              'mag_z_lsst': [...], \n",
    "              'mag_y_lsst': [...] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Survey-Based Degraders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.creation.degradation.spectroscopic_selections import *\n",
    "\n",
    "def specSelectBOSS(ntrain):\n",
    "    degr = SpecSelection_BOSS.make_stage(\n",
    "        name = 'specselection_boss',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectDEEP2(ntrain):\n",
    "    degr = SpecSelection_DEEP2.make_stage(\n",
    "        name = 'specselection_deep2',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectGAMA(ntrain):\n",
    "    degr = SpecSelection_GAMA.make_stage(\n",
    "        name = 'specselection_gama',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectHSC(ntrain):\n",
    "    degr = SpecSelection_HSC.make_stage(\n",
    "        name = 'specselection_HSC',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectVVDSf02(ntrain):\n",
    "    degr = SpecSelection_VVDSf02.make_stage(\n",
    "        name = 'specselection_VVDSf02',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr \n",
    "\n",
    "def specSelectzCOSMOS(ntrain):\n",
    "    degr = SpecSelection_zCOSMOS.make_stage(\n",
    "        name = 'specselection_zCOSMOS',\n",
    "        N_tot = ntrain\n",
    "    )\n",
    "    return degr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(data, model, grid):\n",
    "    posts = FlowPosterior.make_stage(\n",
    "        name='get_posts'+str(data), \n",
    "        column='redshift',\n",
    "        grid = grid,\n",
    "        model = model,\n",
    "        data = data\n",
    "    )\n",
    "    return posts #posts.get_posterior(data, column = 'redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(zmin, zmax, nbins):\n",
    "    import numpy as np\n",
    "    grid = np.linspace(zmin, zmax, nbins + 1)\n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = makeGrid(0, 2.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_train_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_train = FlowPosterior.make_stage(name='orig_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_train)\n",
    "\n",
    "# orig_train_pdfs = flow_post_orig_train.get_posterior(orig_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_train_posts ** rerun this cell!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_train = FlowPosterior.make_stage(name='deg_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              err_samples = 0,\n",
    "#                                              data = deg_train)\n",
    "\n",
    "\n",
    "\n",
    "# deg_train_pdfs = flow_post_deg_train.get_posterior(deg_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_test = FlowPosterior.make_stage(name='orig_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_test)\n",
    "\n",
    "# orig_test_pdfs = flow_post_orig_test.get_posterior(orig_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_test = FlowPosterior.make_stage(name='deg_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = deg_test)\n",
    "\n",
    "# deg_test_pdfs = flow_post_deg_test.get_posterior(deg_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "def colRemapper(dict):\n",
    "    col_remap = ColumnMapper.make_stage(\n",
    "    name='col_remapper', \n",
    "    columns=dict,\n",
    "    )\n",
    "    return col_remap\n",
    "\n",
    "def tableConverter():\n",
    "    table_conv = TableConverter.make_stage(\n",
    "    name='table_conv', \n",
    "    output_format='numpyDict',\n",
    "    )\n",
    "    return table_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_remap = colRemapper(band_dict_err)\n",
    "table_conv = tableConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inform & Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informTrainZ():\n",
    "    inf = TrainZInformer.make_stage(\n",
    "    name = 'inform_TrainZ',\n",
    "    model = 'trainz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateTrainZ(info):\n",
    "    est = TrainZEstimator.make_stage(\n",
    "    name = 'estimate_TrainZ',\n",
    "    model = 'trainz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module rail.estimation.algos.cmnn in rail.estimation.algos:\n",
      "\n",
      "NAME\n",
      "    rail.estimation.algos.cmnn\n",
      "\n",
      "DESCRIPTION\n",
      "    Implementation of the color-matched nearest neighbor (CMNN) algorithm\n",
      "    See https://ui.adsabs.harvard.edu/abs/2018AJ....155....1G/abstract\n",
      "    for more details\n",
      "\n",
      "CLASSES\n",
      "    rail.estimation.estimator.CatEstimator(rail.core.stage.RailStage)\n",
      "        CMNNPDF\n",
      "    rail.estimation.informer.CatInformer(rail.core.stage.RailStage)\n",
      "        Inform_CMNNPDF\n",
      "    \n",
      "    class CMNNPDF(rail.estimation.estimator.CatEstimator)\n",
      "     |  CMNNPDF(args, comm=None)\n",
      "     |  \n",
      "     |  Color Matched Nearest Neighbor Estimator\n",
      "     |  Note that there are several modifications from the original CMNN, mainly that\n",
      "     |  the original estimator dropped non-detections from the Mahalnobis distance\n",
      "     |  calculation. However, there is information in a non-detection, so instead here\n",
      "     |  I've replaced the non-detections with 1 sigma limit and a magnitude\n",
      "     |  uncertainty of 1.0 and fixed the degrees of freedom to be the number of\n",
      "     |  magnitude bands minus one.\n",
      "     |  \n",
      "     |  Current implementation returns a single Gaussian for each galaxy with a width\n",
      "     |  determined by the std deviation of all galaxies within the range set by the\n",
      "     |  ppf value.\n",
      "     |  \n",
      "     |  There are three options for how to choose the central value of the Gaussian\n",
      "     |  and that option is set using the `selection_mode` config parameter (integer):\n",
      "     |  option 0: randomly choose one of the neighbors within the PPF cutoff\n",
      "     |  option 1: choose the value with the smallest Mahalnobis distance\n",
      "     |  option 2: random choice as in option 0, but weighted by distance\n",
      "     |  \n",
      "     |  If a test galaxy does not have enough training galaxies it is\n",
      "     |  assigned a redshift `bad_redshift_val` and a width `bad_redshift_err`, both\n",
      "     |  of which are config parameters that can be set by the user.  Note that this\n",
      "     |  should only happen if the number of training galaxies is smaller than\n",
      "     |  min_n, which is unlikely, but is included here for completeness.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CMNNPDF\n",
      "     |      rail.estimation.estimator.CatEstimator\n",
      "     |      rail.core.stage.RailStage\n",
      "     |      ceci.stage.PipelineStage\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, args, comm=None)\n",
      "     |      Constructor:\n",
      "     |      Do Estimator specific initialization\n",
      "     |  \n",
      "     |  open_model(self, **kwargs)\n",
      "     |      Load the mode and/or attach it to this Estimator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      model : `object`, `str` or `ModelHandle`\n",
      "     |          Either an object with a trained model,\n",
      "     |          a path pointing to a file that can be read to obtain the trained model,\n",
      "     |          or a `ModelHandle` providing access to the trained model.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self.model : `object`\n",
      "     |          The object encapsulating the trained model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  config_options = {'bad_redshift_err': <ceci.config.StageParameter obje...\n",
      "     |  \n",
      "     |  name = 'CMNNPDF'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.estimation.estimator.CatEstimator:\n",
      "     |  \n",
      "     |  estimate(self, input_data)\n",
      "     |      The main interface method for the photo-z estimation\n",
      "     |      \n",
      "     |      This will attach the input_data to this `Estimator`\n",
      "     |      (for introspection and provenance tracking).\n",
      "     |      \n",
      "     |      Then it will call the run() and finalize() methods, which need to\n",
      "     |      be implemented by the sub-classes.\n",
      "     |      \n",
      "     |      The run() method will need to register the data that it creates to this Estimator\n",
      "     |      by using `self.add_data('output', output_data)`.\n",
      "     |      \n",
      "     |      Finally, this will return a QPHandle providing access to that output data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_data : `dict` or `ModelHandle`\n",
      "     |          Either a dictionary of all input data or a `ModelHandle` providing access to the same\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      output: `QPHandle`\n",
      "     |          Handle providing access to QP ensemble with output data\n",
      "     |  \n",
      "     |  run(self)\n",
      "     |      Run the stage and return the execution status\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.estimation.estimator.CatEstimator:\n",
      "     |  \n",
      "     |  inputs = [('model', <class 'rail.core.data.ModelHandle'>), ('input', <...\n",
      "     |  \n",
      "     |  outputs = [('output', <class 'rail.core.data.QPHandle'>)]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  add_data(self, tag, data=None)\n",
      "     |      Adds a handle to the DataStore associated to a particular tag and\n",
      "     |      attaches data to it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  add_handle(self, tag, data=None, path=None)\n",
      "     |      Adds a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any or None\n",
      "     |          If not None these data will be associated to the handle\n",
      "     |      path : str or None\n",
      "     |          If not None, this will be the path used to read the data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that gives access to the associated data\n",
      "     |  \n",
      "     |  connect_input(self, other, inputTag=None, outputTag=None)\n",
      "     |      Connect another stage to this stage as an input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : RailStage\n",
      "     |           The stage whose output is being connected\n",
      "     |      inputTag : str\n",
      "     |           Which input tag of this stage to connect to.  None -> self.inputs[0]\n",
      "     |      outputTag : str\n",
      "     |           Which output tag of the other stage to connect to.  None -> other.outputs[0]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : The input handle for this stage\n",
      "     |  \n",
      "     |  get_data(self, tag, allow_missing=True)\n",
      "     |      Gets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. This gets the data via the DataHandle, and can and will read the data\n",
      "     |      from disk if needed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  get_handle(self, tag, path=None, allow_missing=False)\n",
      "     |      Gets a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      path : str or None\n",
      "     |          The path to the data, only needed if we might need to read the data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that give access to the associated data\n",
      "     |  \n",
      "     |  input_iterator(self, tag, **kwargs)\n",
      "     |      Iterate the input assocated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      \n",
      "     |      kwargs : dict[str, Any]\n",
      "     |          These will be passed to the Handle's iterator method\n",
      "     |  \n",
      "     |  set_data(self, tag, data, path=None, do_read=True)\n",
      "     |      Sets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. If data is a DataHandle and tag is one of the input tags,\n",
      "     |      then this will add an alias between the two, i.e., it will\n",
      "     |      set `self.config.alias[tag] = data.tag`.  This allows the user to\n",
      "     |      make connections between stages simply by passing DataHandles between\n",
      "     |      them.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |          The data being set,\n",
      "     |      path : str or None\n",
      "     |          Can be used to set the path for the data\n",
      "     |      do_read : bool\n",
      "     |          If True, will read the data if it is not set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  build(**kwargs) from builtins.type\n",
      "     |      Return an object that can be used to build a stage\n",
      "     |  \n",
      "     |  make_and_connect(**kwargs) from builtins.type\n",
      "     |      Make a stage and connects it to other stages\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      kwargs are used to set stage configuration,\n",
      "     |      the should be key, value pairs, where the key\n",
      "     |      is the parameter name and the value is value we want to assign\n",
      "     |      \n",
      "     |      The 'connections' keyword is special, it is a dict[str, DataHandle]\n",
      "     |      and should define the Input connections for this stage\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A stage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  data_store = DataStore\n",
      "     |  {  model:<class 'rail.tools.flow_handl...e.data...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  already_finished(self)\n",
      "     |      Print a warning that a stage is being skipped\n",
      "     |  \n",
      "     |  check_io(self, args=None)\n",
      "     |      Check the inputs and outputs.\n",
      "     |      This function is seperate so that when Stages are configured interactively after\n",
      "     |      construction then can invove this\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  data_ranges_by_rank(self, n_rows, chunk_rows, parallel=True)\n",
      "     |      Split a number of rows by process.\n",
      "     |      \n",
      "     |      Given a total number of rows to read and a chunk size, yield\n",
      "     |      the ranges within them that this process should handle.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_rows: int\n",
      "     |          Total number of rows to split up\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Size of each chunk to be read.\n",
      "     |      \n",
      "     |      Parallel: bool\n",
      "     |          Whether to split data by rank or just give all procs all data.\n",
      "     |          Default=True\n",
      "     |  \n",
      "     |  finalize(self)\n",
      "     |      Finalize the stage, moving all its outputs to their final locations.\n",
      "     |  \n",
      "     |  find_inputs(self, pipeline_files)\n",
      "     |      Find and retrun all the inputs associated to this stage in the FileManager\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  find_outputs(self, outdir)\n",
      "     |      Find and retrun all the outputs associated to this stage\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  get_aliased_tag(self, tag)\n",
      "     |      Returns the possibly remapped value for an input or output tag\n",
      "     |      \n",
      "     |      Parameter\n",
      "     |      ---------\n",
      "     |      tag : `str`\n",
      "     |          The input or output tag we are checking\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aliased_tag : `str`\n",
      "     |          The aliases version of the tag\n",
      "     |  \n",
      "     |  get_aliases(self)\n",
      "     |      Returns the dictionary of aliases used to remap inputs and outputs\n",
      "     |      in the case that we want to have multiple instance of this class in the pipeline\n",
      "     |  \n",
      "     |  get_config_dict(self, ignore=None, reduce_config=False)\n",
      "     |      Write the current configuration to a dict\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ignore : dict or None\n",
      "     |          Global parameters not to write\n",
      "     |      reduce_config : bool\n",
      "     |          If true, reduce the configuration by parsing out the inputs, outputs and global params\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out_dict : dict\n",
      "     |          The configuration\n",
      "     |  \n",
      "     |  get_input(self, tag)\n",
      "     |      Return the path of an input file with the given tag,\n",
      "     |      which can be aliased.\n",
      "     |  \n",
      "     |  get_input_type(self, tag)\n",
      "     |      Return the file type class of an input file with the given tag.\n",
      "     |  \n",
      "     |  get_output(self, tag, final_name=False)\n",
      "     |      Return the path of an output file with the given tag,\n",
      "     |      which can be aliased already.\n",
      "     |      \n",
      "     |      If final_name is False then use a temporary name - file will\n",
      "     |      be moved to its final name at the end\n",
      "     |  \n",
      "     |  get_output_type(self, tag)\n",
      "     |      Return the file type class of an output file with the given tag.\n",
      "     |  \n",
      "     |  is_dask(self)\n",
      "     |      Returns True if the stage is being run in parallel with Dask.\n",
      "     |  \n",
      "     |  is_mpi(self)\n",
      "     |      Returns True if the stage is being run under MPI.\n",
      "     |  \n",
      "     |  is_parallel(self)\n",
      "     |      Returns True if the code is being run in parallel.\n",
      "     |      Right now is_parallel() will return the same value as is_mpi(),\n",
      "     |      but that may change in future if we implement other forms of\n",
      "     |      parallelization.\n",
      "     |  \n",
      "     |  iterate_fits(self, tag, hdunum, cols, chunk_rows, parallel=True)\n",
      "     |      Loop through chunks of the input data from a FITS file with the given tag\n",
      "     |      \n",
      "     |      TODO: add ceci tests of this functions\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      hdunum: int\n",
      "     |          The extension number to read\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, array) tuples of (start, end, data)\n",
      "     |          data is a structured array.\n",
      "     |  \n",
      "     |  iterate_hdf(self, tag, group_name, cols, chunk_rows, parallel=True, longest=False)\n",
      "     |      Loop through chunks of the input data from an HDF5 file with the given tag.\n",
      "     |      \n",
      "     |      All the selected columns must have the same length.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      group: str\n",
      "     |          The group within the HDF5 file to use, looked up as\n",
      "     |          file[group]\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      longest: bool\n",
      "     |          Whether to allow mixed length arrays and keep going until the longest\n",
      "     |          array is completed, returning empty arrays for shorter ones\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, dict) tuples of (start, end, data)\n",
      "     |  \n",
      "     |  load_configs(self, args)\n",
      "     |      Load the configuraiton\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  map_tasks_by_rank(self, function, inputs, allgather=False)\n",
      "     |      Run a function over a series of inputs, in parallel\n",
      "     |      \n",
      "     |      This mirrors the map function, and returns the equivalent of\n",
      "     |      [function(input) for input in inputs], but executes in parallel.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      function: Callable\n",
      "     |          Function to be run on each item in inputs\n",
      "     |      \n",
      "     |      inputs: Iterable\n",
      "     |          Any sequence of inputs, which should be the same\n",
      "     |          on all processes. Or at least the same length:\n",
      "     |          inputs not assigned to this process are ignored so\n",
      "     |          you could get away with a dummy input for them.\n",
      "     |      \n",
      "     |      allgather: bool\n",
      "     |          Whether to give all ranks the results (True) or just the\n",
      "     |          root process (False). Default = False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results: list\n",
      "     |          A list of the results of calling the function on each input,\n",
      "     |          in the same order as the input tasks\n",
      "     |  \n",
      "     |  open_input(self, tag, wrapper=False, **kwargs)\n",
      "     |      Find and open an input file with the given tag, in read-only mode.\n",
      "     |      \n",
      "     |      For general files this will simply return a standard\n",
      "     |      python file object.\n",
      "     |      \n",
      "     |      For specialized file types like FITS or HDF5 it will return\n",
      "     |      a more specific object - see the types.py file for more info.\n",
      "     |  \n",
      "     |  open_output(self, tag, wrapper=False, final_name=False, **kwargs)\n",
      "     |      Find and open an output file with the given tag, in write mode.\n",
      "     |      \n",
      "     |      If final_name is True then they will be opened using their final\n",
      "     |      target output name.  Otherwise we will prepend \"inprogress_\" to their\n",
      "     |      file name. This means we know that if the final file exists then it\n",
      "     |      is completed.\n",
      "     |      \n",
      "     |      If wrapper is True this will return an instance of the class\n",
      "     |      of the file as specified in the cls.outputs.  Otherwise it will\n",
      "     |      return an open file object (standard python one or something more\n",
      "     |      specialized).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      tag: str\n",
      "     |          Tag as listed in self.outputs\n",
      "     |      \n",
      "     |      wrapper: bool\n",
      "     |          Default=False.  Whether to return a wrapped file\n",
      "     |      \n",
      "     |      final_name: bool\n",
      "     |          Default=False. Whether to save to\n",
      "     |      \n",
      "     |      **kwargs:\n",
      "     |          Extra args are passed on to the file's class constructor.\n",
      "     |  \n",
      "     |  print_io(self, stream=<ipykernel.iostream.OutStream object at 0x1045ebe20>)\n",
      "     |      Print out the tags, paths and types for all the inputs and outputs of this stage\n",
      "     |  \n",
      "     |  read_config(self, args)\n",
      "     |      This function looks for the arguments of the pipeline stage using a\n",
      "     |      combination of default values, command line options and separate\n",
      "     |      configuration file.\n",
      "     |      \n",
      "     |      The order for resolving config options is first looking for a default\n",
      "     |      value, then looking for a\n",
      "     |      \n",
      "     |      In case a mandatory argument (argument with no default) is missing,\n",
      "     |      an exception is raised.\n",
      "     |      \n",
      "     |      Note that we recognize arguments with no default as the ones where\n",
      "     |      self.config_options holds a type instead of a value.\n",
      "     |  \n",
      "     |  setup_mpi(self, comm=None)\n",
      "     |      Setup the MPI interface\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      comm: MPI communicator\n",
      "     |          (default is None) An MPI comm object to use in preference to COMM_WORLD\n",
      "     |  \n",
      "     |  should_skip(self, run_config)\n",
      "     |      Return true if we should skip a stage b/c it's outputs already exist and we are in resume mode\n",
      "     |  \n",
      "     |  split_tasks_by_rank(self, tasks)\n",
      "     |      Iterate through a list of items, yielding ones this process is responsible for/\n",
      "     |      \n",
      "     |      Tasks are allocated in a round-robin way.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tasks: iterable\n",
      "     |          Tasks to split up\n",
      "     |  \n",
      "     |  start_dask(self)\n",
      "     |      Prepare dask to run under MPI. After calling this method\n",
      "     |      only a single process, MPI rank 1 will continue to exeute code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Python 3.6+ provides a facility to automatically\n",
      "     |      call a method (this one) whenever a new subclass\n",
      "     |      is defined.  In this case we use that feature to keep\n",
      "     |      track of all available pipeline stages, each of which is\n",
      "     |      defined by a class.\n",
      "     |  \n",
      "     |  execute(args, comm=None) from builtins.type\n",
      "     |      Create an instance of this stage and run it\n",
      "     |      with the specified inputs and outputs.\n",
      "     |      \n",
      "     |      This is calld by the main method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: namespace\n",
      "     |          The argparse namespace for this subclass.\n",
      "     |  \n",
      "     |  generate_command(inputs, config, outputs, aliases=None, instance_name=None) from builtins.type\n",
      "     |      Generate a command line that will run the stage\n",
      "     |  \n",
      "     |  generate_cwl(log_dir=None) from builtins.type\n",
      "     |      Produces a CWL App object which can then be exported to yaml\n",
      "     |  \n",
      "     |  get_module() from builtins.type\n",
      "     |      Return the path to the python package containing the current sub-class\n",
      "     |      \n",
      "     |      If we have a PipelineStage subclass defined in a module called \"bar\", in\n",
      "     |      a package called \"foo\" e.g.:\n",
      "     |      /path/to/foo/bar.py  <--   contains subclass \"Baz\"\n",
      "     |      \n",
      "     |      Then calling Baz.get_module() will return \"foo.bar\".\n",
      "     |      \n",
      "     |      We use this later to construct command lines like \"python -m foo Baz\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      module: str\n",
      "     |          The module containing this class.\n",
      "     |  \n",
      "     |  get_stage(name, module_name=None) from builtins.type\n",
      "     |      Return the PipelineStage subclass with the given name.\n",
      "     |      \n",
      "     |      This is used so that we do not need a new entry point __main__ function\n",
      "     |      for each new stage - instead we can just use a single one which can query\n",
      "     |      which class it should be using based on the name.\n",
      "     |      \n",
      "     |      If module_name is provided, this will import that module\n",
      "     |      in order to load the required class.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cls: class\n",
      "     |          The corresponding subclass\n",
      "     |  \n",
      "     |  input_tags() from builtins.type\n",
      "     |      Return the list of input tags required by this stage\n",
      "     |  \n",
      "     |  inputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  main() from builtins.type\n",
      "     |      Create an instance of this stage and execute it with\n",
      "     |      inputs and outputs taken from the command line\n",
      "     |  \n",
      "     |  make_stage(**kwargs) from builtins.type\n",
      "     |      Make a stage of a particular type\n",
      "     |  \n",
      "     |  output_tags() from builtins.type\n",
      "     |      Return the list of output tags required by this stage\n",
      "     |  \n",
      "     |  outputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  parse_command_line(cmd=None) from builtins.type\n",
      "     |      Set up and argument parser and parse the command line\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cmd : str or None\n",
      "     |          The command line to part (if None this will use the system arguments)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      args : Namespace\n",
      "     |          The resulting Mapping of arguement to values\n",
      "     |  \n",
      "     |  usage() from builtins.type\n",
      "     |      Print a usage message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  stop_dask()\n",
      "     |      End the dask event loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  comm\n",
      "     |      The MPI communicator object (None if not running under MPI)\n",
      "     |  \n",
      "     |  config\n",
      "     |      Returns the configuration dictionary for this stage, aggregating command\n",
      "     |      line options and optional configuration file.\n",
      "     |  \n",
      "     |  instance_name\n",
      "     |      Return the name associated to this particular instance of this stage\n",
      "     |  \n",
      "     |  rank\n",
      "     |      The rank of this process under MPI (0 if not running under MPI)\n",
      "     |  \n",
      "     |  size\n",
      "     |      The number or processes under MPI (1 if not running under MPI)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  allow_reload = False\n",
      "     |  \n",
      "     |  dask_parallel = False\n",
      "     |  \n",
      "     |  doc = ''\n",
      "     |  \n",
      "     |  incomplete_pipeline_stages = {'CatInformer': (<class 'rail.estimation....\n",
      "     |  \n",
      "     |  parallel = True\n",
      "     |  \n",
      "     |  pipeline_stages = {'CMNNPDF': (<class 'rail.estimation.algos.cmnn.CMNN...\n",
      "    \n",
      "    class Inform_CMNNPDF(rail.estimation.informer.CatInformer)\n",
      "     |  Inform_CMNNPDF(args, comm=None)\n",
      "     |  \n",
      "     |  compute colors and color errors for CMNN training set and\n",
      "     |  store in a model file that will be used by the CMNNPDF stage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Inform_CMNNPDF\n",
      "     |      rail.estimation.informer.CatInformer\n",
      "     |      rail.core.stage.RailStage\n",
      "     |      ceci.stage.PipelineStage\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, args, comm=None)\n",
      "     |      Constructor\n",
      "     |      Do CatInformer specific initialization, then check on bands\n",
      "     |  \n",
      "     |  run(self)\n",
      "     |      Run the stage and return the execution status\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  config_options = {'bands': StageConfig{hdf5_groupname:photometry,zmin:...\n",
      "     |  \n",
      "     |  name = 'Inform_CMNNPDF'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.estimation.informer.CatInformer:\n",
      "     |  \n",
      "     |  inform(self, training_data)\n",
      "     |      The main interface method for Informers\n",
      "     |      \n",
      "     |      This will attach the input_data to this `Informer`\n",
      "     |      (for introspection and provenance tracking).\n",
      "     |      \n",
      "     |      Then it will call the run() and finalize() methods, which need to\n",
      "     |      be implemented by the sub-classes.\n",
      "     |      \n",
      "     |      The run() method will need to register the model that it creates to this Estimator\n",
      "     |      by using `self.add_data('model', model)`.\n",
      "     |      \n",
      "     |      Finally, this will return a ModelHandle providing access to the trained model.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_data : `dict` or `TableHandle`\n",
      "     |          dictionary of all input data, or a `TableHandle` providing access to it\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      model : ModelHandle\n",
      "     |          Handle providing access to trained model\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.estimation.informer.CatInformer:\n",
      "     |  \n",
      "     |  inputs = [('input', <class 'rail.core.data.TableHandle'>)]\n",
      "     |  \n",
      "     |  outputs = [('model', <class 'rail.core.data.ModelHandle'>)]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  add_data(self, tag, data=None)\n",
      "     |      Adds a handle to the DataStore associated to a particular tag and\n",
      "     |      attaches data to it.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  add_handle(self, tag, data=None, path=None)\n",
      "     |      Adds a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any or None\n",
      "     |          If not None these data will be associated to the handle\n",
      "     |      path : str or None\n",
      "     |          If not None, this will be the path used to read the data\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that gives access to the associated data\n",
      "     |  \n",
      "     |  connect_input(self, other, inputTag=None, outputTag=None)\n",
      "     |      Connect another stage to this stage as an input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : RailStage\n",
      "     |           The stage whose output is being connected\n",
      "     |      inputTag : str\n",
      "     |           Which input tag of this stage to connect to.  None -> self.inputs[0]\n",
      "     |      outputTag : str\n",
      "     |           Which output tag of the other stage to connect to.  None -> other.outputs[0]\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : The input handle for this stage\n",
      "     |  \n",
      "     |  get_data(self, tag, allow_missing=True)\n",
      "     |      Gets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. This gets the data via the DataHandle, and can and will read the data\n",
      "     |      from disk if needed.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  get_handle(self, tag, path=None, allow_missing=False)\n",
      "     |      Gets a DataHandle associated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      path : str or None\n",
      "     |          The path to the data, only needed if we might need to read the data\n",
      "     |      allow_missing : bool\n",
      "     |          If False this will raise a key error if the tag is not in the DataStore\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      handle : DataHandle\n",
      "     |          The handle that give access to the associated data\n",
      "     |  \n",
      "     |  input_iterator(self, tag, **kwargs)\n",
      "     |      Iterate the input assocated to a particular tag\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      \n",
      "     |      kwargs : dict[str, Any]\n",
      "     |          These will be passed to the Handle's iterator method\n",
      "     |  \n",
      "     |  set_data(self, tag, data, path=None, do_read=True)\n",
      "     |      Sets the data associated to a particular tag\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      1. If data is a DataHandle and tag is one of the input tags,\n",
      "     |      then this will add an alias between the two, i.e., it will\n",
      "     |      set `self.config.alias[tag] = data.tag`.  This allows the user to\n",
      "     |      make connections between stages simply by passing DataHandles between\n",
      "     |      them.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag : str\n",
      "     |          The tag (from cls.inputs or cls.outputs) for this data\n",
      "     |      data : any\n",
      "     |          The data being set,\n",
      "     |      path : str or None\n",
      "     |          Can be used to set the path for the data\n",
      "     |      do_read : bool\n",
      "     |          If True, will read the data if it is not set\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      data : any\n",
      "     |          The data accesed by the handle assocated to the tag\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  build(**kwargs) from builtins.type\n",
      "     |      Return an object that can be used to build a stage\n",
      "     |  \n",
      "     |  make_and_connect(**kwargs) from builtins.type\n",
      "     |      Make a stage and connects it to other stages\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      kwargs are used to set stage configuration,\n",
      "     |      the should be key, value pairs, where the key\n",
      "     |      is the parameter name and the value is value we want to assign\n",
      "     |      \n",
      "     |      The 'connections' keyword is special, it is a dict[str, DataHandle]\n",
      "     |      and should define the Input connections for this stage\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A stage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from rail.core.stage.RailStage:\n",
      "     |  \n",
      "     |  data_store = DataStore\n",
      "     |  {  model:<class 'rail.tools.flow_handl...e.data...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  already_finished(self)\n",
      "     |      Print a warning that a stage is being skipped\n",
      "     |  \n",
      "     |  check_io(self, args=None)\n",
      "     |      Check the inputs and outputs.\n",
      "     |      This function is seperate so that when Stages are configured interactively after\n",
      "     |      construction then can invove this\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  data_ranges_by_rank(self, n_rows, chunk_rows, parallel=True)\n",
      "     |      Split a number of rows by process.\n",
      "     |      \n",
      "     |      Given a total number of rows to read and a chunk size, yield\n",
      "     |      the ranges within them that this process should handle.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_rows: int\n",
      "     |          Total number of rows to split up\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Size of each chunk to be read.\n",
      "     |      \n",
      "     |      Parallel: bool\n",
      "     |          Whether to split data by rank or just give all procs all data.\n",
      "     |          Default=True\n",
      "     |  \n",
      "     |  finalize(self)\n",
      "     |      Finalize the stage, moving all its outputs to their final locations.\n",
      "     |  \n",
      "     |  find_inputs(self, pipeline_files)\n",
      "     |      Find and retrun all the inputs associated to this stage in the FileManager\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  find_outputs(self, outdir)\n",
      "     |      Find and retrun all the outputs associated to this stage\n",
      "     |      \n",
      "     |      These are returned as a dictionary of tag : path pairs\n",
      "     |  \n",
      "     |  get_aliased_tag(self, tag)\n",
      "     |      Returns the possibly remapped value for an input or output tag\n",
      "     |      \n",
      "     |      Parameter\n",
      "     |      ---------\n",
      "     |      tag : `str`\n",
      "     |          The input or output tag we are checking\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      aliased_tag : `str`\n",
      "     |          The aliases version of the tag\n",
      "     |  \n",
      "     |  get_aliases(self)\n",
      "     |      Returns the dictionary of aliases used to remap inputs and outputs\n",
      "     |      in the case that we want to have multiple instance of this class in the pipeline\n",
      "     |  \n",
      "     |  get_config_dict(self, ignore=None, reduce_config=False)\n",
      "     |      Write the current configuration to a dict\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ignore : dict or None\n",
      "     |          Global parameters not to write\n",
      "     |      reduce_config : bool\n",
      "     |          If true, reduce the configuration by parsing out the inputs, outputs and global params\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out_dict : dict\n",
      "     |          The configuration\n",
      "     |  \n",
      "     |  get_input(self, tag)\n",
      "     |      Return the path of an input file with the given tag,\n",
      "     |      which can be aliased.\n",
      "     |  \n",
      "     |  get_input_type(self, tag)\n",
      "     |      Return the file type class of an input file with the given tag.\n",
      "     |  \n",
      "     |  get_output(self, tag, final_name=False)\n",
      "     |      Return the path of an output file with the given tag,\n",
      "     |      which can be aliased already.\n",
      "     |      \n",
      "     |      If final_name is False then use a temporary name - file will\n",
      "     |      be moved to its final name at the end\n",
      "     |  \n",
      "     |  get_output_type(self, tag)\n",
      "     |      Return the file type class of an output file with the given tag.\n",
      "     |  \n",
      "     |  is_dask(self)\n",
      "     |      Returns True if the stage is being run in parallel with Dask.\n",
      "     |  \n",
      "     |  is_mpi(self)\n",
      "     |      Returns True if the stage is being run under MPI.\n",
      "     |  \n",
      "     |  is_parallel(self)\n",
      "     |      Returns True if the code is being run in parallel.\n",
      "     |      Right now is_parallel() will return the same value as is_mpi(),\n",
      "     |      but that may change in future if we implement other forms of\n",
      "     |      parallelization.\n",
      "     |  \n",
      "     |  iterate_fits(self, tag, hdunum, cols, chunk_rows, parallel=True)\n",
      "     |      Loop through chunks of the input data from a FITS file with the given tag\n",
      "     |      \n",
      "     |      TODO: add ceci tests of this functions\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      hdunum: int\n",
      "     |          The extension number to read\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, array) tuples of (start, end, data)\n",
      "     |          data is a structured array.\n",
      "     |  \n",
      "     |  iterate_hdf(self, tag, group_name, cols, chunk_rows, parallel=True, longest=False)\n",
      "     |      Loop through chunks of the input data from an HDF5 file with the given tag.\n",
      "     |      \n",
      "     |      All the selected columns must have the same length.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tag: str\n",
      "     |          The tag from the inputs list to use\n",
      "     |      \n",
      "     |      group: str\n",
      "     |          The group within the HDF5 file to use, looked up as\n",
      "     |          file[group]\n",
      "     |      \n",
      "     |      cols: list\n",
      "     |          The columns to read\n",
      "     |      \n",
      "     |      chunk_rows: int\n",
      "     |          Number of columns to read and return at once\n",
      "     |      \n",
      "     |      parallel: bool\n",
      "     |          Whether to split up data among processes (parallel=True) or give\n",
      "     |          all processes all data (parallel=False).  Default = True.\n",
      "     |      \n",
      "     |      longest: bool\n",
      "     |          Whether to allow mixed length arrays and keep going until the longest\n",
      "     |          array is completed, returning empty arrays for shorter ones\n",
      "     |      \n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      it: iterator\n",
      "     |          Iterator yielding (int, int, dict) tuples of (start, end, data)\n",
      "     |  \n",
      "     |  load_configs(self, args)\n",
      "     |      Load the configuraiton\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: dict or namespace\n",
      "     |          Specification of input and output paths and any missing config options\n",
      "     |  \n",
      "     |  map_tasks_by_rank(self, function, inputs, allgather=False)\n",
      "     |      Run a function over a series of inputs, in parallel\n",
      "     |      \n",
      "     |      This mirrors the map function, and returns the equivalent of\n",
      "     |      [function(input) for input in inputs], but executes in parallel.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      function: Callable\n",
      "     |          Function to be run on each item in inputs\n",
      "     |      \n",
      "     |      inputs: Iterable\n",
      "     |          Any sequence of inputs, which should be the same\n",
      "     |          on all processes. Or at least the same length:\n",
      "     |          inputs not assigned to this process are ignored so\n",
      "     |          you could get away with a dummy input for them.\n",
      "     |      \n",
      "     |      allgather: bool\n",
      "     |          Whether to give all ranks the results (True) or just the\n",
      "     |          root process (False). Default = False.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      results: list\n",
      "     |          A list of the results of calling the function on each input,\n",
      "     |          in the same order as the input tasks\n",
      "     |  \n",
      "     |  open_input(self, tag, wrapper=False, **kwargs)\n",
      "     |      Find and open an input file with the given tag, in read-only mode.\n",
      "     |      \n",
      "     |      For general files this will simply return a standard\n",
      "     |      python file object.\n",
      "     |      \n",
      "     |      For specialized file types like FITS or HDF5 it will return\n",
      "     |      a more specific object - see the types.py file for more info.\n",
      "     |  \n",
      "     |  open_output(self, tag, wrapper=False, final_name=False, **kwargs)\n",
      "     |      Find and open an output file with the given tag, in write mode.\n",
      "     |      \n",
      "     |      If final_name is True then they will be opened using their final\n",
      "     |      target output name.  Otherwise we will prepend \"inprogress_\" to their\n",
      "     |      file name. This means we know that if the final file exists then it\n",
      "     |      is completed.\n",
      "     |      \n",
      "     |      If wrapper is True this will return an instance of the class\n",
      "     |      of the file as specified in the cls.outputs.  Otherwise it will\n",
      "     |      return an open file object (standard python one or something more\n",
      "     |      specialized).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      tag: str\n",
      "     |          Tag as listed in self.outputs\n",
      "     |      \n",
      "     |      wrapper: bool\n",
      "     |          Default=False.  Whether to return a wrapped file\n",
      "     |      \n",
      "     |      final_name: bool\n",
      "     |          Default=False. Whether to save to\n",
      "     |      \n",
      "     |      **kwargs:\n",
      "     |          Extra args are passed on to the file's class constructor.\n",
      "     |  \n",
      "     |  print_io(self, stream=<ipykernel.iostream.OutStream object at 0x1045ebe20>)\n",
      "     |      Print out the tags, paths and types for all the inputs and outputs of this stage\n",
      "     |  \n",
      "     |  read_config(self, args)\n",
      "     |      This function looks for the arguments of the pipeline stage using a\n",
      "     |      combination of default values, command line options and separate\n",
      "     |      configuration file.\n",
      "     |      \n",
      "     |      The order for resolving config options is first looking for a default\n",
      "     |      value, then looking for a\n",
      "     |      \n",
      "     |      In case a mandatory argument (argument with no default) is missing,\n",
      "     |      an exception is raised.\n",
      "     |      \n",
      "     |      Note that we recognize arguments with no default as the ones where\n",
      "     |      self.config_options holds a type instead of a value.\n",
      "     |  \n",
      "     |  setup_mpi(self, comm=None)\n",
      "     |      Setup the MPI interface\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      comm: MPI communicator\n",
      "     |          (default is None) An MPI comm object to use in preference to COMM_WORLD\n",
      "     |  \n",
      "     |  should_skip(self, run_config)\n",
      "     |      Return true if we should skip a stage b/c it's outputs already exist and we are in resume mode\n",
      "     |  \n",
      "     |  split_tasks_by_rank(self, tasks)\n",
      "     |      Iterate through a list of items, yielding ones this process is responsible for/\n",
      "     |      \n",
      "     |      Tasks are allocated in a round-robin way.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      tasks: iterable\n",
      "     |          Tasks to split up\n",
      "     |  \n",
      "     |  start_dask(self)\n",
      "     |      Prepare dask to run under MPI. After calling this method\n",
      "     |      only a single process, MPI rank 1 will continue to exeute code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Python 3.6+ provides a facility to automatically\n",
      "     |      call a method (this one) whenever a new subclass\n",
      "     |      is defined.  In this case we use that feature to keep\n",
      "     |      track of all available pipeline stages, each of which is\n",
      "     |      defined by a class.\n",
      "     |  \n",
      "     |  execute(args, comm=None) from builtins.type\n",
      "     |      Create an instance of this stage and run it\n",
      "     |      with the specified inputs and outputs.\n",
      "     |      \n",
      "     |      This is calld by the main method.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: namespace\n",
      "     |          The argparse namespace for this subclass.\n",
      "     |  \n",
      "     |  generate_command(inputs, config, outputs, aliases=None, instance_name=None) from builtins.type\n",
      "     |      Generate a command line that will run the stage\n",
      "     |  \n",
      "     |  generate_cwl(log_dir=None) from builtins.type\n",
      "     |      Produces a CWL App object which can then be exported to yaml\n",
      "     |  \n",
      "     |  get_module() from builtins.type\n",
      "     |      Return the path to the python package containing the current sub-class\n",
      "     |      \n",
      "     |      If we have a PipelineStage subclass defined in a module called \"bar\", in\n",
      "     |      a package called \"foo\" e.g.:\n",
      "     |      /path/to/foo/bar.py  <--   contains subclass \"Baz\"\n",
      "     |      \n",
      "     |      Then calling Baz.get_module() will return \"foo.bar\".\n",
      "     |      \n",
      "     |      We use this later to construct command lines like \"python -m foo Baz\"\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      module: str\n",
      "     |          The module containing this class.\n",
      "     |  \n",
      "     |  get_stage(name, module_name=None) from builtins.type\n",
      "     |      Return the PipelineStage subclass with the given name.\n",
      "     |      \n",
      "     |      This is used so that we do not need a new entry point __main__ function\n",
      "     |      for each new stage - instead we can just use a single one which can query\n",
      "     |      which class it should be using based on the name.\n",
      "     |      \n",
      "     |      If module_name is provided, this will import that module\n",
      "     |      in order to load the required class.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cls: class\n",
      "     |          The corresponding subclass\n",
      "     |  \n",
      "     |  input_tags() from builtins.type\n",
      "     |      Return the list of input tags required by this stage\n",
      "     |  \n",
      "     |  inputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  main() from builtins.type\n",
      "     |      Create an instance of this stage and execute it with\n",
      "     |      inputs and outputs taken from the command line\n",
      "     |  \n",
      "     |  make_stage(**kwargs) from builtins.type\n",
      "     |      Make a stage of a particular type\n",
      "     |  \n",
      "     |  output_tags() from builtins.type\n",
      "     |      Return the list of output tags required by this stage\n",
      "     |  \n",
      "     |  outputs_() from builtins.type\n",
      "     |      Return the dict of inputs\n",
      "     |  \n",
      "     |  parse_command_line(cmd=None) from builtins.type\n",
      "     |      Set up and argument parser and parse the command line\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      cmd : str or None\n",
      "     |          The command line to part (if None this will use the system arguments)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      args : Namespace\n",
      "     |          The resulting Mapping of arguement to values\n",
      "     |  \n",
      "     |  usage() from builtins.type\n",
      "     |      Print a usage message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  stop_dask()\n",
      "     |      End the dask event loop\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  comm\n",
      "     |      The MPI communicator object (None if not running under MPI)\n",
      "     |  \n",
      "     |  config\n",
      "     |      Returns the configuration dictionary for this stage, aggregating command\n",
      "     |      line options and optional configuration file.\n",
      "     |  \n",
      "     |  instance_name\n",
      "     |      Return the name associated to this particular instance of this stage\n",
      "     |  \n",
      "     |  rank\n",
      "     |      The rank of this process under MPI (0 if not running under MPI)\n",
      "     |  \n",
      "     |  size\n",
      "     |      The number or processes under MPI (1 if not running under MPI)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from ceci.stage.PipelineStage:\n",
      "     |  \n",
      "     |  allow_reload = False\n",
      "     |  \n",
      "     |  dask_parallel = False\n",
      "     |  \n",
      "     |  doc = ''\n",
      "     |  \n",
      "     |  incomplete_pipeline_stages = {'CatInformer': (<class 'rail.estimation....\n",
      "     |  \n",
      "     |  parallel = True\n",
      "     |  \n",
      "     |  pipeline_stages = {'CMNNPDF': (<class 'rail.estimation.algos.cmnn.CMNN...\n",
      "\n",
      "DATA\n",
      "    SHARED_PARAMS = StageConfig{hdf5_groupname:photometry,zmin:0.0,z...hif...\n",
      "    chi2 = <scipy.stats._continuous_distns.chi2_gen object>\n",
      "        A chi-squared continuous random variable.\n",
      "        \n",
      "        For the noncentral chi-square distribution, see `ncx2`.\n",
      "        \n",
      "        As an instance of the `rv_continuous` class, `chi2` object inherits from it\n",
      "        a collection of generic methods (see below for the full list),\n",
      "        and completes them with details specific for this particular distribution.\n",
      "        \n",
      "        Methods\n",
      "        -------\n",
      "        rvs(df, loc=0, scale=1, size=1, random_state=None)\n",
      "            Random variates.\n",
      "        pdf(x, df, loc=0, scale=1)\n",
      "            Probability density function.\n",
      "        logpdf(x, df, loc=0, scale=1)\n",
      "            Log of the probability density function.\n",
      "        cdf(x, df, loc=0, scale=1)\n",
      "            Cumulative distribution function.\n",
      "        logcdf(x, df, loc=0, scale=1)\n",
      "            Log of the cumulative distribution function.\n",
      "        sf(x, df, loc=0, scale=1)\n",
      "            Survival function  (also defined as ``1 - cdf``, but `sf` is sometimes more accurate).\n",
      "        logsf(x, df, loc=0, scale=1)\n",
      "            Log of the survival function.\n",
      "        ppf(q, df, loc=0, scale=1)\n",
      "            Percent point function (inverse of ``cdf`` --- percentiles).\n",
      "        isf(q, df, loc=0, scale=1)\n",
      "            Inverse survival function (inverse of ``sf``).\n",
      "        moment(order, df, loc=0, scale=1)\n",
      "            Non-central moment of the specified order.\n",
      "        stats(df, loc=0, scale=1, moments='mv')\n",
      "            Mean('m'), variance('v'), skew('s'), and/or kurtosis('k').\n",
      "        entropy(df, loc=0, scale=1)\n",
      "            (Differential) entropy of the RV.\n",
      "        fit(data)\n",
      "            Parameter estimates for generic data.\n",
      "            See `scipy.stats.rv_continuous.fit <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.fit.html#scipy.stats.rv_continuous.fit>`__ for detailed documentation of the\n",
      "            keyword arguments.\n",
      "        expect(func, args=(df,), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "            Expected value of a function (of one argument) with respect to the distribution.\n",
      "        median(df, loc=0, scale=1)\n",
      "            Median of the distribution.\n",
      "        mean(df, loc=0, scale=1)\n",
      "            Mean of the distribution.\n",
      "        var(df, loc=0, scale=1)\n",
      "            Variance of the distribution.\n",
      "        std(df, loc=0, scale=1)\n",
      "            Standard deviation of the distribution.\n",
      "        interval(confidence, df, loc=0, scale=1)\n",
      "            Confidence interval with equal areas around the median.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ncx2\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for `chi2` is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            f(x, k) = \\frac{1}{2^{k/2} \\Gamma \\left( k/2 \\right)}\n",
      "                       x^{k/2-1} \\exp \\left( -x/2 \\right)\n",
      "        \n",
      "        for :math:`x > 0`  and :math:`k > 0` (degrees of freedom, denoted ``df``\n",
      "        in the implementation).\n",
      "        \n",
      "        `chi2` takes ``df`` as a shape parameter.\n",
      "        \n",
      "        The chi-squared distribution is a special case of the gamma\n",
      "        distribution, with gamma parameters ``a = df/2``, ``loc = 0`` and\n",
      "        ``scale = 2``.\n",
      "        \n",
      "        The probability density above is defined in the \"standardized\" form. To shift\n",
      "        and/or scale the distribution use the ``loc`` and ``scale`` parameters.\n",
      "        Specifically, ``chi2.pdf(x, df, loc, scale)`` is identically\n",
      "        equivalent to ``chi2.pdf(y, df) / scale`` with\n",
      "        ``y = (x - loc) / scale``. Note that shifting the location of a distribution\n",
      "        does not make it a \"noncentral\" distribution; noncentral generalizations of\n",
      "        some distributions are available in separate classes.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from scipy.stats import chi2\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> fig, ax = plt.subplots(1, 1)\n",
      "        \n",
      "        Calculate the first four moments:\n",
      "        \n",
      "        >>> df = 55\n",
      "        >>> mean, var, skew, kurt = chi2.stats(df, moments='mvsk')\n",
      "        \n",
      "        Display the probability density function (``pdf``):\n",
      "        \n",
      "        >>> x = np.linspace(chi2.ppf(0.01, df),\n",
      "        ...                 chi2.ppf(0.99, df), 100)\n",
      "        >>> ax.plot(x, chi2.pdf(x, df),\n",
      "        ...        'r-', lw=5, alpha=0.6, label='chi2 pdf')\n",
      "        \n",
      "        Alternatively, the distribution object can be called (as a function)\n",
      "        to fix the shape, location and scale parameters. This returns a \"frozen\"\n",
      "        RV object holding the given parameters fixed.\n",
      "        \n",
      "        Freeze the distribution and display the frozen ``pdf``:\n",
      "        \n",
      "        >>> rv = chi2(df)\n",
      "        >>> ax.plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf')\n",
      "        \n",
      "        Check accuracy of ``cdf`` and ``ppf``:\n",
      "        \n",
      "        >>> vals = chi2.ppf([0.001, 0.5, 0.999], df)\n",
      "        >>> np.allclose([0.001, 0.5, 0.999], chi2.cdf(vals, df))\n",
      "        True\n",
      "        \n",
      "        Generate random numbers:\n",
      "        \n",
      "        >>> r = chi2.rvs(df, size=1000)\n",
      "        \n",
      "        And compare the histogram:\n",
      "        \n",
      "        >>> ax.hist(r, density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n",
      "        >>> ax.set_xlim([x[0], x[-1]])\n",
      "        >>> ax.legend(loc='best', frameon=False)\n",
      "        >>> plt.show()\n",
      "\n",
      "FILE\n",
      "    /Users/alicec03/miniforge3/envs/rail---new/lib/python3.11/site-packages/rail/estimation/algos/cmnn.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rail.estimation.algos.cmnn)#Inform_CMNNPDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informCMNN():\n",
    "    inf = Inform_CMNNPDF.make_stage(\n",
    "    name = 'inform_CMNN',\n",
    "    model = 'cmnn.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    # config_options = {'err_bands': ['mag_err_u_lsst', \n",
    "    #                                 'mag_err_g_lsst'\n",
    "    #                                 'mag_err_r_lsst'\n",
    "    #                                 'mag_err_i_lsst'\n",
    "    #                                 'mag_err_z_lsst'\n",
    "    #                                 'mag_err_y_lsst'] }\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateCMNN(info):\n",
    "    est = CMNNPDF.make_stage(\n",
    "    name = 'estimate_CMNN',\n",
    "    model = 'cmnn.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informGPz():\n",
    "    inf = GPzInformer.make_stage(\n",
    "    name = 'inform_GPz',\n",
    "    model = 'gpz.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    # config_options = {'err_bands': ['mag_err_u_lsst', \n",
    "    #                                 'mag_err_g_lsst'\n",
    "    #                                 'mag_err_r_lsst'\n",
    "    #                                 'mag_err_i_lsst'\n",
    "    #                                 'mag_err_z_lsst'\n",
    "    #                                 'mag_err_y_lsst'] }\n",
    "\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimateGPz(info):\n",
    "    est = GPzEstimator.make_stage(\n",
    "    name = 'estimate_GPz',\n",
    "    model = 'gpz.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def informPZFlow():\n",
    "    inf = PZFlowInformer.make_stage(\n",
    "    name = 'inform_PZFlow',\n",
    "    model = 'pzflow.pkl',\n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return inf\n",
    "\n",
    "def estimatePZFlow(info):\n",
    "    est = PZFlowEstimator.make_stage(\n",
    "    name = 'estimate_PZFlow',\n",
    "    model = 'pzflow.pkl', \n",
    "    hdf5_groupname=\"\"\n",
    "    )\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informFZBoost():\n",
    "    info = FlexZBoostInformer.make_stage(\n",
    "    name ='inform_FZBoost', \n",
    "    model ='fzboost.pkl', \n",
    "    hdf5_groupname='',\n",
    "    )\n",
    "    return info\n",
    "\n",
    "def estimateFZBoost(info):\n",
    "    est = FlexZBoostEstimator.make_stage(\n",
    "    name='est_FZBoost', \n",
    "    nondetect_val=np.nan,\n",
    "    model= info,\n",
    "    hdf5_groupname='',\n",
    "    aliases=dict(input='test_data', output='fzboost_estim'),\n",
    "    nzbins = 100 \n",
    "    )\n",
    "    return est "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'invz': invRedshift,\n",
    "\n",
    "spec_dict = {'BOSS': specSelectBOSS, \n",
    "             'DEEP2': specSelectDEEP2, \n",
    "             'GAMA': specSelectGAMA,\n",
    "             'HSC': specSelectHSC, \n",
    "             'VVDSf02': specSelectVVDSf02, \n",
    "             'zCOSMOS': specSelectzCOSMOS } \n",
    "\n",
    "inf_est_dict = {'TrainZ': [informTrainZ, estimateTrainZ],\n",
    "               'CMNN': [informCMNN, estimateCMNN], \n",
    "               'GPz': [informGPz, estimateGPz], \n",
    "               'PZFlow': [informPZFlow, estimatePZFlow], \n",
    "               'FZBoost': [informFZBoost, estimateFZBoost] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ceci \n",
    "\n",
    "# pr = ceci.Pipeline.read(path_lst_1[0])#parent_dir+directory+\"/invz=0.33672517538070684_lsstErr_pzflow.yml\")\n",
    "# pr.run()\n",
    "\n",
    "# ## 1) terminal: go to path up to invz_lsstErr_pzflow, then run these 2 lines \n",
    "# ## 2)  make list/txt file with list of paths to files made by big F\n",
    "\n",
    "# ## do 1) \n",
    "# ## open virtual env\n",
    "# ## python \n",
    "# ## import ceci \n",
    "# ## run the 2 lines of code above \n",
    "\n",
    "\n",
    "# ### at the end we can put this into a .py file that we can run at the command line \n",
    "\n",
    "# ## %cd ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## more config parameters/better config parameters\n",
    "## have to give path above to estimator model instead of get_handle('model')\n",
    "## fix truncated parameter printing in help(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Big F's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure to change the first argument of testSet\n",
    "# # testData = testSet(ntest, seed2)\n",
    "\n",
    "# testData = testSet(100, 39)\n",
    "# testData.run()\n",
    "\n",
    "# test_data = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_test_set.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lsstErr = lsstError(band_dict, seed3)\n",
    "\n",
    "# bands = ['u','g','r','i','z','y']\n",
    "# band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "# band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "# lsstErr = lsstError(band_dict, 172)\n",
    "# lsstErr.connect_input(test_data) ## might be wrong; passing in a file not a stage \n",
    "# lsstErr.run()\n",
    "\n",
    "# lsst_Err = DS.read_file(\"test_Data\", TableHandle, \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/output_lsst_error.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for inverse redshift incompleteness:\n",
    "\n",
    "pivot_ls = [1.0, 1.4] \n",
    "\n",
    "name_ls = ['BOSS', 'DEEP2', 'GAMA', 'HSC', 'VVDSf02', 'zCOSMOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF0(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins, invzparam):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "\n",
    "    if degrader == invRedshift:\n",
    "       deg = degrader(invzparam)\n",
    "    else:\n",
    "        deg = degrader(ntrain) \n",
    "\n",
    "    print('degrader is: '+str(deg))\n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infTrainZ = informTrainZ()\n",
    "    estTrainZ = estimateTrainZ(infTrainZ)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infTrainZ, \n",
    "        estTrainZ]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infTrainZ.connect_input(deg) \n",
    "    estTrainZ.connect_input(infTrainZ, inputTag = 'model')\n",
    "    estTrainZ.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_pzflow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_0 = []\n",
    "directory_0 = \"specSelection_lsstErr_TrainZ\"\n",
    "parent_dir_0 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0 = os.path.join(parent_dir_0, directory_0)\n",
    "os.makedirs(path_0, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrader is: Applying the BOSS selection.\n",
      "degrader is: Applying the DEEP2 selection.\n",
      "degrader is: Applying the GAMA selection.\n",
      "degrader is: Applying the HSC selection.\n",
      "degrader is: Applying the VVDSf02 selection.\n",
      "degrader is: Applying the zCOSMOS selection.\n"
     ]
    }
   ],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_0.append(bigF0(spec_dict[key], key, path_0, 1000000, 10000, 17, 39, 172, 10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_boss.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/BOSS_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_deep2\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_deep2   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --output=./output_specselection_deep2.pq \n",
      "Output writing to ./specselection_deep2.out\n",
      "\n",
      "Job specselection_deep2 has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_deep2.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/DEEP2_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_gama\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_gama   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --output=./output_specselection_gama.pq \n",
      "Output writing to ./specselection_gama.out\n",
      "\n",
      "Job specselection_gama has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_gama.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/GAMA_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_HSC\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_HSC   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --output=./output_specselection_HSC.pq \n",
      "Output writing to ./specselection_HSC.out\n",
      "\n",
      "Job specselection_HSC has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_HSC.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/HSC_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_VVDSf02\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_VVDSf02   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --output=./output_specselection_VVDSf02.pq \n",
      "Output writing to ./specselection_VVDSf02.out\n",
      "\n",
      "Job specselection_VVDSf02 has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_VVDSf02.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/VVDSf02_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_zCOSMOS\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_zCOSMOS   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --output=./output_specselection_zCOSMOS.pq \n",
      "Output writing to ./specselection_zCOSMOS.out\n",
      "\n",
      "Job specselection_zCOSMOS has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_specselection_zCOSMOS.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/zCOSMOS_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n"
     ]
    }
   ],
   "source": [
    "out_dir_0 = \"outputs\"\n",
    "out_parent_dir_0 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ\"\n",
    "path_outs_0 = os.path.join(out_parent_dir_0, out_dir_0)\n",
    "os.makedirs(path_outs_0, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_0:\n",
    "    if ind <= 5:\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs\")\n",
    "        dir_0 = name_ls[ind]\n",
    "        parent_0 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs\"\n",
    "        outpath_0 = os.path.join(parent_0, dir_0)\n",
    "        os.makedirs(outpath_0, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/\"+dir_0)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# df2 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_specselection_boss.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "52105\n",
      "4567\n",
      "23902\n",
      "137241\n",
      "57704\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_BOSS = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/BOSS/output_specselection_boss.pq\")\n",
    "df_DEEP2 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/DEEP2/output_specselection_deep2.pq\")\n",
    "df_GAMA = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/GAMA/output_specselection_gama.pq\")\n",
    "df_HSC = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/HSC/output_specselection_hsc.pq\")\n",
    "df_VVDSf02 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/VVDSf02/output_specselection_VVDSf02.pq\")\n",
    "df_zCOSMOS = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_TrainZ/outputs/zCOSMOS/output_specselection_zCOSMOS.pq\")\n",
    "\n",
    "print(len(df_BOSS))\n",
    "print(len(df_DEEP2))\n",
    "print(len(df_GAMA))\n",
    "print(len(df_HSC))\n",
    "print(len(df_VVDSf02))\n",
    "print(len(df_zCOSMOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_0_invz = []\n",
    "directory_0_invz = \"invz_lsstErr_TrainZ\"\n",
    "parent_dir_0_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_0_invz = os.path.join(parent_dir_0_invz, directory_0_invz)\n",
    "os.makedirs(path_0_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degrader is: <rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness object at 0x286f23ad0>\n",
      "Inserting handle into data store.  output_inv_redshift: inprogress_output_inv_redshift.pq, inv_redshift\n",
      "degrader is: <rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness object at 0x286f21990>\n"
     ]
    }
   ],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_0_invz.append(bigF0(invRedshift, 'invz='+str(i), path_0_invz, 1000, 100, 17, 39, 172, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing inv_redshift\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness   --input=./output_train_set.pq   --name=inv_redshift   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --output=./output_inv_redshift.pq \n",
      "Output writing to ./inv_redshift.out\n",
      "\n",
      "Job inv_redshift has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_inv_redshift.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.0_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing inv_redshift\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness   --input=./output_train_set.pq   --name=inv_redshift   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --output=./output_inv_redshift.pq \n",
      "Output writing to ./inv_redshift.out\n",
      "\n",
      "Job inv_redshift has completed successfully!\n",
      "\n",
      "Executing inform_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZInformer   --input=./output_inv_redshift.pq   --name=inform_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --model=./trainz.pkl \n",
      "Output writing to ./inform_TrainZ.out\n",
      "\n",
      "Job inform_TrainZ has completed successfully!\n",
      "\n",
      "Executing estimate_TrainZ\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.train_z.TrainZEstimator   --model=./trainz.pkl   --input=./output_lsst_error.pq   --name=estimate_TrainZ   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/invz=1.4_lsstErr_pzflow_config.yml   --output=./output_estimate_TrainZ.hdf5 \n",
      "Output writing to ./estimate_TrainZ.out\n",
      "\n",
      "Job estimate_TrainZ has completed successfully!\n"
     ]
    }
   ],
   "source": [
    "out_dir_0_invz = \"outputs\"\n",
    "out_parent_dir_0_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ\"\n",
    "path_outs_0_invz = os.path.join(out_parent_dir_0_invz, out_dir_0_invz)\n",
    "os.makedirs(path_outs_0_invz, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_0_invz:\n",
    "    if ind < len(pivot_ls):\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/outputs\")\n",
    "        dir_0_invz = str(pivot_ls[ind])\n",
    "        parent_0_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/outputs\"\n",
    "        outpath_0_invz = os.path.join(parent_0_invz, dir_0_invz)\n",
    "        os.makedirs(outpath_0_invz, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_TrainZ/outputs/\"+dir_0_invz)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins, invzparam):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "\n",
    "    if degrader == invRedshift:\n",
    "       deg = degrader(invzparam)\n",
    "    else:\n",
    "        deg = degrader(ntrain)  \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    remapper = colRemapper(band_dict_err)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infCMNN = informCMNN()\n",
    "    estCMNN = estimateCMNN(infCMNN)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        remapper,\n",
    "        testData, \n",
    "        lsstErr, \n",
    "        infCMNN, \n",
    "        estCMNN]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    remapper.connect_input(deg)\n",
    "    infCMNN.connect_input(remapper)\n",
    "\n",
    "    lsstErr.connect_input(testData)\n",
    "    remapper.connect_input(lsstErr)\n",
    "    estCMNN.connect_input(infCMNN, inputTag = 'model')\n",
    "    estCMNN.connect_input(remapper, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_CMNN.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1 = []\n",
    "directory_1 = \"specSelection_lsstErr_CMNN\"\n",
    "parent_dir_1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1 = os.path.join(parent_dir_1, directory_1)\n",
    "os.makedirs(path_1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_1.append(bigF1(spec_dict[key], key, path_1, 1000000, 100, 17, 39, 172, 10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/BOSS_lsstErr_CMNN_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_deep2\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_deep2   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/DEEP2_lsstErr_CMNN_config.yml   --output=./output_specselection_deep2.pq \n",
      "Output writing to ./specselection_deep2.out\n",
      "\n",
      "Job specselection_deep2 has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_gama\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_gama   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/GAMA_lsstErr_CMNN_config.yml   --output=./output_specselection_gama.pq \n",
      "Output writing to ./specselection_gama.out\n",
      "\n",
      "Job specselection_gama has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_HSC\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_HSC   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/HSC_lsstErr_CMNN_config.yml   --output=./output_specselection_HSC.pq \n",
      "Output writing to ./specselection_HSC.out\n",
      "\n",
      "Job specselection_HSC has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_VVDSf02\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_VVDSf02   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/VVDSf02_lsstErr_CMNN_config.yml   --output=./output_specselection_VVDSf02.pq \n",
      "Output writing to ./specselection_VVDSf02.out\n",
      "\n",
      "Job specselection_VVDSf02 has completed successfully!\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing col_remapper\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.core.utilStages.ColumnMapper   --input=./output_lsst_error.pq   --name=col_remapper   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_col_remapper.pq \n",
      "Output writing to ./col_remapper.out\n",
      "\n",
      "Job col_remapper has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_col_remapper.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has completed successfully!\n",
      "\n",
      "Executing estimate_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.CMNNPDF   --model=./cmnn.pkl   --input=./output_col_remapper.pq   --name=estimate_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_estimate_CMNN.hdf5 \n",
      "Output writing to ./estimate_CMNN.out\n",
      "\n",
      "Job estimate_CMNN has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_zCOSMOS\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_zCOSMOS   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/zCOSMOS_lsstErr_CMNN_config.yml   --output=./output_specselection_zCOSMOS.pq \n",
      "Output writing to ./specselection_zCOSMOS.out\n",
      "\n",
      "Job specselection_zCOSMOS has completed successfully!\n"
     ]
    }
   ],
   "source": [
    "out_dir_1 = \"outputs\"\n",
    "out_parent_dir_1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN\"\n",
    "path_outs_1 = os.path.join(out_parent_dir_1, out_dir_1)\n",
    "os.makedirs(path_outs_1, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_1:\n",
    "    if ind <= 5:\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/outputs\")\n",
    "        dir_1 = name_ls[ind]\n",
    "        parent_1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/outputs\"\n",
    "        outpath_1 = os.path.join(parent_1, dir_1)\n",
    "        os.makedirs(outpath_1, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_CMNN/outputs/\"+dir_1)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_1_invz = []\n",
    "directory = \"invz_lsstErr_CMNN\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_1_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_1_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_1_invz.append(bigF1(invRedshift, 'invz='+str(i), path_1_invz, 1000000, 100, 17, 39, 172, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.0_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.0_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.0_lsstErr_CMNN_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing inv_redshift\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness   --input=./output_train_set.pq   --name=inv_redshift   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.0_lsstErr_CMNN_config.yml   --output=./output_inv_redshift.pq \n",
      "Output writing to ./inv_redshift.out\n",
      "\n",
      "Job inv_redshift has completed successfully!\n",
      "\n",
      "Executing inform_CMNN\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.cmnn.Inform_CMNNPDF   --input=./output_inv_redshift.pq   --name=inform_CMNN   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.0_lsstErr_CMNN_config.yml   --model=./cmnn.pkl \n",
      "Output writing to ./inform_CMNN.out\n",
      "\n",
      "Job inform_CMNN has failed with status 1\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.4_lsstErr_CMNN_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************************************\n",
      "Error running pipeline stage inform_CMNN.\n",
      "\n",
      "Standard output and error streams in ./inform_CMNN.out\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/invz=1.4_lsstErr_CMNN_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 74\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/outputs/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdir_1_invz)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     pr \u001b[39m=\u001b[39m ceci\u001b[39m.\u001b[39mPipeline\u001b[39m.\u001b[39mread(i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     pr\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     ind \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y231sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:830\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    829\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the pipeline are return the execution status\"\"\"\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_jobs()\n\u001b[1;32m    831\u001b[0m     \u001b[39m# When the\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_all_outputs()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:1300\u001b[0m, in \u001b[0;36mMiniPipeline.run_jobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         interval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlauncher_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minterval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m   1299\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1300\u001b[0m             runner\u001b[39m.\u001b[39;49mrun(interval)\n\u001b[1;32m   1301\u001b[0m         \u001b[39mexcept\u001b[39;00m minirunner\u001b[39m.\u001b[39mFailedJob \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m   1302\u001b[0m             sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m   1303\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m \u001b[39m*************************************************\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1310\u001b[0m             )\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/minirunner.py:229\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, interval, timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39m==\u001b[39m WAITING:\n\u001b[1;32m    228\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msleep(interval)\n\u001b[1;32m    230\u001b[0m     t \u001b[39m=\u001b[39m default_timer() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m>\u001b[39m timeout:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out_dir_1_invz = \"outputs\"\n",
    "out_parent_dir_1_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN\"\n",
    "path_outs_1_invz = os.path.join(out_parent_dir_1_invz, out_dir_1_invz)\n",
    "os.makedirs(path_outs_1_invz, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_1_invz:\n",
    "    if ind < len(pivot_ls):\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/outputs\")\n",
    "        dir_1_invz = str(pivot_ls[ind])\n",
    "        parent_1_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/outputs\"\n",
    "        outpath_1_invz = os.path.join(parent_1_invz, dir_1_invz)\n",
    "        os.makedirs(outpath_1_invz, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_CMNN/outputs/\"+dir_1_invz)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins, invzparam):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "\n",
    "    if degrader == invRedshift:\n",
    "       deg = degrader(invzparam)\n",
    "    else:\n",
    "        deg = degrader(ntrain)  \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    remapper = colRemapper(band_dict_err)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infGPz = informGPz()\n",
    "    estGPz = estimateGPz(infGPz)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        remapper,\n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infGPz, \n",
    "        estGPz]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    remapper.connect_inpus(deg)\n",
    "    infGPz.connect_input(remapper) \n",
    "\n",
    "    lsstErr.connect_input(testData)\n",
    "    remapper.connect_input(lsstErr) \n",
    "    estGPz.connect_input(infGPz, inputTag = 'model')\n",
    "    estGPz.connect_input(remapper, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_GPz.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2 = []\n",
    "directory = \"specSelection_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_2.append(bigF2(spec_dict[key], key, path_2, 1000000, 100, 17, 39, 172, 10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/BOSS_lsstErr_GPz_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/BOSS_lsstErr_GPz_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/BOSS_lsstErr_GPz_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/BOSS_lsstErr_GPz_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_GPz\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.gpz.GPzInformer   --input=./output_specselection_boss.pq   --name=inform_GPz   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/BOSS_lsstErr_GPz_config.yml   --model=./gpz.pkl \n",
      "Output writing to ./inform_GPz.out\n",
      "\n",
      "Job inform_GPz has failed with status 1\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/DEEP2_lsstErr_GPz_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************************************\n",
      "Error running pipeline stage inform_GPz.\n",
      "\n",
      "Standard output and error streams in ./inform_GPz.out\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/DEEP2_lsstErr_GPz_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/DEEP2_lsstErr_GPz_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_deep2\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_deep2   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/DEEP2_lsstErr_GPz_config.yml   --output=./output_specselection_deep2.pq \n",
      "Output writing to ./specselection_deep2.out\n",
      "\n",
      "Job specselection_deep2 has completed successfully!\n",
      "\n",
      "Executing inform_GPz\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.gpz.GPzInformer   --input=./output_specselection_deep2.pq   --name=inform_GPz   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/DEEP2_lsstErr_GPz_config.yml   --model=./gpz.pkl \n",
      "Output writing to ./inform_GPz.out\n",
      "\n",
      "Job inform_GPz has failed with status 1\n",
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/GAMA_lsstErr_GPz_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************************************\n",
      "Error running pipeline stage inform_GPz.\n",
      "\n",
      "Standard output and error streams in ./inform_GPz.out\n",
      "*************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/GAMA_lsstErr_GPz_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/GAMA_lsstErr_GPz_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 80\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y241sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/outputs/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mdir_2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y241sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     pr \u001b[39m=\u001b[39m ceci\u001b[39m.\u001b[39mPipeline\u001b[39m.\u001b[39mread(i)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y241sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     pr\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y241sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     ind \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y241sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39melse\u001b[39;00m: \n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:830\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    829\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the pipeline are return the execution status\"\"\"\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_jobs()\n\u001b[1;32m    831\u001b[0m     \u001b[39m# When the\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_all_outputs()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:1300\u001b[0m, in \u001b[0;36mMiniPipeline.run_jobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         interval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlauncher_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minterval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m   1299\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1300\u001b[0m             runner\u001b[39m.\u001b[39;49mrun(interval)\n\u001b[1;32m   1301\u001b[0m         \u001b[39mexcept\u001b[39;00m minirunner\u001b[39m.\u001b[39mFailedJob \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m   1302\u001b[0m             sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m   1303\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m \u001b[39m*************************************************\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1310\u001b[0m             )\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/minirunner.py:229\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, interval, timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39m==\u001b[39m WAITING:\n\u001b[1;32m    228\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msleep(interval)\n\u001b[1;32m    230\u001b[0m     t \u001b[39m=\u001b[39m default_timer() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m>\u001b[39m timeout:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out_dir_2 = \"outputs\"\n",
    "out_parent_dir_2 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz\"\n",
    "path_outs_2 = os.path.join(out_parent_dir_2, out_dir_2)\n",
    "os.makedirs(path_outs_2, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_2:\n",
    "    if ind <= 5:\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/outputs\")\n",
    "        dir_2 = name_ls[ind]\n",
    "        parent_2 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/outputs\"\n",
    "        outpath_2 = os.path.join(parent_2, dir_2)\n",
    "        os.makedirs(outpath_2, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_GPz/outputs/\"+dir_2)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_2_invz = []\n",
    "directory = \"invz_lsstErr_GPz\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_2_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_2_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_2_invz.append(bigF2(invRedshift, 'invz='+str(i), path_1_invz, 1000000, 100, 17, 39, 172, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_2_invz = \"outputs\"\n",
    "out_parent_dir_2_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_GPz\"\n",
    "path_outs_2_invz = os.path.join(out_parent_dir_2_invz, out_dir_2_invz)\n",
    "os.makedirs(path_outs_2_invz, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_GPz/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_2_invz:\n",
    "    if ind < len(pivot_ls):\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_GPz/outputs\")\n",
    "        dir_2_invz = str(pivot_ls[ind])\n",
    "        parent_2_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_GPz/outputs\"\n",
    "        outpath_2_invz = os.path.join(parent_2_invz, dir_2_invz)\n",
    "        os.makedirs(outpath_2_invz, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_GPz/outputs/\"+dir_2_invz)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PZFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bigF3(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins, invzparam):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "\n",
    "    if degrader == invRedshift:\n",
    "       deg = degrader(invzparam)\n",
    "    else:\n",
    "        deg = degrader(ntrain)  \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_PZFlow.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(rail.creation.degradation.spectroscopic_selections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##run \n",
    "\n",
    "path_lst_3 = []\n",
    "directory = \"specSelection_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_3.append(bigF3(spec_dict[key], key, path_3, 1000000, 100, 17, 39, 172, 10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_3 = \"outputs\"\n",
    "out_parent_dir_3 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_PZFlow\"\n",
    "path_outs_3 = os.path.join(out_parent_dir_3, out_dir_3)\n",
    "os.makedirs(path_outs_3, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_PZFlow/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_3:\n",
    "    if ind <= 5:\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_PZFlow/outputs\")\n",
    "        dir_3 = name_ls[ind]\n",
    "        parent_3 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_PZFlow/outputs\"\n",
    "        outpath_3 = os.path.join(parent_3, dir_3)\n",
    "        os.makedirs(outpath_3, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_lsstErr_PZFlow/outputs/\"+dir_3)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_3_invz = []\n",
    "directory = \"invz_lsstErr_PZFlow\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_3_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_3_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_3_invz.append(bigF3(invRedshift, 'invz='+str(i), path_3_invz, 1000000, 100, 17, 39, 172, 10, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_3_invz = \"outputs\"\n",
    "out_parent_dir_3_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_PZFlow\"\n",
    "path_outs_3_invz = os.path.join(out_parent_dir_3_invz, out_dir_3_invz)\n",
    "os.makedirs(path_outs_3_invz, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_PZFlow/outputs\")\n",
    "\n",
    "ind = 0\n",
    "for i in path_lst_3_invz:\n",
    "    if ind < len(pivot_ls):\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_PZFlow/outputs\")\n",
    "        dir_3_invz = str(pivot_ls[ind])\n",
    "        parent_3_invz = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_PZFlow/outputs\"\n",
    "        outpath_3_invz = os.path.join(parent_3_invz, dir_3_invz)\n",
    "        os.makedirs(outpath_3_invz, exist_ok=True)\n",
    "        os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/invz_lsstErr_PZFlow/outputs/\"+dir_3_invz)\n",
    "        pr = ceci.Pipeline.read(i)\n",
    "        pr.run()\n",
    "        ind += 1\n",
    "    else: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlexZBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF4(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins, invzparam):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "\n",
    "    if degrader == invRedshift:\n",
    "       deg = degrader(invzparam)\n",
    "    else:\n",
    "        deg = degrader(ntrain)  \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infFZBoost = informFZBoost()\n",
    "    estFZBoost = estimateFZBoost(infFZBoost)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infFZBoost, \n",
    "        estFZBoost]\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infFZBoost.connect_input(deg) \n",
    "    estFZBoost.connect_input(infFZBoost, inputTag = 'model')\n",
    "    estFZBoost.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :(\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_lsstErr_FZBoost.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4 = []\n",
    "directory = \"specSelection_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model_inform_FZBoost: inprogress_fzboost.pkl, inform_FZBoost\n"
     ]
    }
   ],
   "source": [
    "for key in spec_dict:\n",
    "    path_lst_4.append(bigF4(spec_dict[key], key, path_4, 1000, 100, 17, 39, 172, 10, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_4_invz = []\n",
    "directory = \"invz_lsstErr_FZBoost\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_4_invz = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_4_invz, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot_ls:\n",
    "    path_lst_4_invz.append(bigF4(invRedshift, 'invz='+str(i), path_1_invz, 1000, 100, 17, 39, 172, 10, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function makedirs in module os:\n",
      "\n",
      "makedirs(name, mode=511, exist_ok=False)\n",
      "    makedirs(name [, mode=0o777][, exist_ok=False])\n",
      "    \n",
      "    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n",
      "    mkdir, except that any intermediate path segment (not just the rightmost)\n",
      "    will be created if it does not exist. If the target directory already\n",
      "    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n",
      "    raised.  This is recursive.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(os.makedirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST1(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]  \n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST1.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model_inform_PZFlow: inprogress_pzflow.pkl, inform_PZFlow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_lst_TEST1 = []\n",
    "directory = \"specSelection_TEST1\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST1 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST1, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST1.append(bigF_TEST1(spec_dict[key], key, path_TEST1, 1000, 1000, 104, 12, 327, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF_TEST2(degrader, name, pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "    #grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    deg = degrader(ntrain) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "    infPZFlow = informPZFlow()\n",
    "    estPZFlow = estimatePZFlow(infPZFlow)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        deg, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        infPZFlow, \n",
    "        estPZFlow]\n",
    "\n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    deg.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    infPZFlow.connect_input(deg) \n",
    "    estPZFlow.connect_input(infPZFlow, inputTag = 'model')\n",
    "    estPZFlow.connect_input(lsstErr, inputTag = 'input') ## trucated out of docs :( \n",
    "    #estPZFlow.connect_input(lsst_Err, inputTag = 'input') ## might be wrong, passing in file instead of stage, need to debug w alex\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST2.yml\" % name)\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_lst_TEST2 = []\n",
    "directory = \"specSelection_TEST2\"\n",
    "parent_dir = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST2 = os.path.join(parent_dir, directory)\n",
    "os.makedirs(path_TEST2, exist_ok=True)\n",
    "\n",
    "\n",
    "for key in spec_dict:\n",
    "    path_lst_TEST2.append(bigF_TEST2(spec_dict[key], key, path_TEST2, 10000, 10000, 104, 12, 327, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir1 = \"outputs\"\n",
    "out_parent_dir1 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1\"\n",
    "path_outs1 = os.path.join(out_parent_dir1, out_dir1)\n",
    "os.makedirs(path_outs1, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1\n"
     ]
    }
   ],
   "source": [
    "print(path_TEST1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/BOSS_TEST1_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 104\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y163sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y163sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pr \u001b[39m=\u001b[39m ceci\u001b[39m.\u001b[39mPipeline\u001b[39m.\u001b[39mread(path_TEST1\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/BOSS_TEST1.yml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y163sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pr\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:830\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    829\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the pipeline are return the execution status\"\"\"\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_jobs()\n\u001b[1;32m    831\u001b[0m     \u001b[39m# When the\u001b[39;00m\n\u001b[1;32m    832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_all_outputs()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:1300\u001b[0m, in \u001b[0;36mMiniPipeline.run_jobs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         interval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlauncher_config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minterval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m   1299\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1300\u001b[0m             runner\u001b[39m.\u001b[39;49mrun(interval)\n\u001b[1;32m   1301\u001b[0m         \u001b[39mexcept\u001b[39;00m minirunner\u001b[39m.\u001b[39mFailedJob \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m   1302\u001b[0m             sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m   1303\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m \u001b[39m*************************************************\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m   1310\u001b[0m             )\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/minirunner.py:229\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, interval, timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39m==\u001b[39m WAITING:\n\u001b[1;32m    228\u001b[0m     status \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update()\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(interval)\n\u001b[1;32m    230\u001b[0m     t \u001b[39m=\u001b[39m default_timer() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m t \u001b[39m>\u001b[39m timeout:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST1+\"/BOSS_TEST1.yml\")\n",
    "pr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453446</td>\n",
       "      <td>26.440466</td>\n",
       "      <td>25.532093</td>\n",
       "      <td>24.414080</td>\n",
       "      <td>24.132780</td>\n",
       "      <td>23.951639</td>\n",
       "      <td>23.614315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.614395</td>\n",
       "      <td>26.199156</td>\n",
       "      <td>25.898083</td>\n",
       "      <td>25.544622</td>\n",
       "      <td>25.158127</td>\n",
       "      <td>24.919113</td>\n",
       "      <td>24.583817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.532331</td>\n",
       "      <td>27.018871</td>\n",
       "      <td>26.491842</td>\n",
       "      <td>26.029282</td>\n",
       "      <td>25.345669</td>\n",
       "      <td>24.971943</td>\n",
       "      <td>24.457464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695185</td>\n",
       "      <td>25.286282</td>\n",
       "      <td>24.142662</td>\n",
       "      <td>22.950605</td>\n",
       "      <td>21.883846</td>\n",
       "      <td>21.517628</td>\n",
       "      <td>21.255428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697118</td>\n",
       "      <td>27.651823</td>\n",
       "      <td>27.095114</td>\n",
       "      <td>26.331165</td>\n",
       "      <td>25.550674</td>\n",
       "      <td>25.334547</td>\n",
       "      <td>25.198923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.731998</td>\n",
       "      <td>29.733955</td>\n",
       "      <td>29.171751</td>\n",
       "      <td>28.277988</td>\n",
       "      <td>27.197586</td>\n",
       "      <td>26.220169</td>\n",
       "      <td>25.771671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.822214</td>\n",
       "      <td>26.690687</td>\n",
       "      <td>26.424179</td>\n",
       "      <td>25.911663</td>\n",
       "      <td>25.186234</td>\n",
       "      <td>24.857292</td>\n",
       "      <td>24.752474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.904075</td>\n",
       "      <td>27.091158</td>\n",
       "      <td>26.829113</td>\n",
       "      <td>26.207962</td>\n",
       "      <td>25.369640</td>\n",
       "      <td>24.944141</td>\n",
       "      <td>24.778233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.430669</td>\n",
       "      <td>28.732162</td>\n",
       "      <td>27.865288</td>\n",
       "      <td>27.377495</td>\n",
       "      <td>26.528309</td>\n",
       "      <td>26.075668</td>\n",
       "      <td>25.367645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.824988</td>\n",
       "      <td>28.784861</td>\n",
       "      <td>27.667164</td>\n",
       "      <td>26.037912</td>\n",
       "      <td>24.842108</td>\n",
       "      <td>24.219093</td>\n",
       "      <td>23.972706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "0    0.453446   26.440466   25.532093   24.414080   24.132780   23.951639   \n",
       "1    1.614395   26.199156   25.898083   25.544622   25.158127   24.919113   \n",
       "2    1.532331   27.018871   26.491842   26.029282   25.345669   24.971943   \n",
       "3    0.695185   25.286282   24.142662   22.950605   21.883846   21.517628   \n",
       "4    0.697118   27.651823   27.095114   26.331165   25.550674   25.334547   \n",
       "..        ...         ...         ...         ...         ...         ...   \n",
       "995  1.731998   29.733955   29.171751   28.277988   27.197586   26.220169   \n",
       "996  0.822214   26.690687   26.424179   25.911663   25.186234   24.857292   \n",
       "997  0.904075   27.091158   26.829113   26.207962   25.369640   24.944141   \n",
       "998  1.430669   28.732162   27.865288   27.377495   26.528309   26.075668   \n",
       "999  0.824988   28.784861   27.667164   26.037912   24.842108   24.219093   \n",
       "\n",
       "     mag_y_lsst  \n",
       "0     23.614315  \n",
       "1     24.583817  \n",
       "2     24.457464  \n",
       "3     21.255428  \n",
       "4     25.198923  \n",
       "..          ...  \n",
       "995   25.771671  \n",
       "996   24.752474  \n",
       "997   24.778233  \n",
       "998   25.367645  \n",
       "999   23.972706  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1train = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs/output_train_set.pq\")\n",
    "\n",
    "df1train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.332584</td>\n",
       "      <td>22.746304</td>\n",
       "      <td>20.570354</td>\n",
       "      <td>19.191704</td>\n",
       "      <td>18.38974</td>\n",
       "      <td>18.079622</td>\n",
       "      <td>17.820402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "291  0.332584   22.746304   20.570354   19.191704    18.38974   18.079622   \n",
       "\n",
       "     mag_y_lsst  \n",
       "291   17.820402  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST1/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.342823</td>\n",
       "      <td>25.937267</td>\n",
       "      <td>25.592773</td>\n",
       "      <td>25.302280</td>\n",
       "      <td>24.184923</td>\n",
       "      <td>23.383533</td>\n",
       "      <td>22.579002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191652</td>\n",
       "      <td>28.780466</td>\n",
       "      <td>28.075939</td>\n",
       "      <td>27.267124</td>\n",
       "      <td>26.668451</td>\n",
       "      <td>25.890570</td>\n",
       "      <td>25.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.751760</td>\n",
       "      <td>26.832052</td>\n",
       "      <td>26.458172</td>\n",
       "      <td>26.087759</td>\n",
       "      <td>25.595860</td>\n",
       "      <td>24.988527</td>\n",
       "      <td>24.666149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.620976</td>\n",
       "      <td>22.530554</td>\n",
       "      <td>22.241764</td>\n",
       "      <td>21.103287</td>\n",
       "      <td>20.136244</td>\n",
       "      <td>19.746765</td>\n",
       "      <td>19.453854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.793243</td>\n",
       "      <td>27.564707</td>\n",
       "      <td>26.932222</td>\n",
       "      <td>26.285490</td>\n",
       "      <td>25.502998</td>\n",
       "      <td>25.277523</td>\n",
       "      <td>25.163303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.981384</td>\n",
       "      <td>27.963957</td>\n",
       "      <td>27.702507</td>\n",
       "      <td>27.336897</td>\n",
       "      <td>27.156370</td>\n",
       "      <td>26.714178</td>\n",
       "      <td>26.362583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744960</td>\n",
       "      <td>27.017117</td>\n",
       "      <td>26.490191</td>\n",
       "      <td>25.695547</td>\n",
       "      <td>24.839457</td>\n",
       "      <td>24.637497</td>\n",
       "      <td>24.520649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.101568</td>\n",
       "      <td>27.205582</td>\n",
       "      <td>26.924608</td>\n",
       "      <td>26.450403</td>\n",
       "      <td>26.079315</td>\n",
       "      <td>25.530327</td>\n",
       "      <td>25.305614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.928054</td>\n",
       "      <td>28.203192</td>\n",
       "      <td>27.457575</td>\n",
       "      <td>26.576130</td>\n",
       "      <td>25.856819</td>\n",
       "      <td>25.445122</td>\n",
       "      <td>25.309990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.202691</td>\n",
       "      <td>28.391132</td>\n",
       "      <td>27.409241</td>\n",
       "      <td>26.832666</td>\n",
       "      <td>26.587118</td>\n",
       "      <td>26.461618</td>\n",
       "      <td>26.408859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "0     1.342823   25.937267   25.592773   25.302280   24.184923   23.383533   \n",
       "1     1.191652   28.780466   28.075939   27.267124   26.668451   25.890570   \n",
       "2     1.751760   26.832052   26.458172   26.087759   25.595860   24.988527   \n",
       "3     0.620976   22.530554   22.241764   21.103287   20.136244   19.746765   \n",
       "4     0.793243   27.564707   26.932222   26.285490   25.502998   25.277523   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "9995  1.981384   27.963957   27.702507   27.336897   27.156370   26.714178   \n",
       "9996  0.744960   27.017117   26.490191   25.695547   24.839457   24.637497   \n",
       "9997  1.101568   27.205582   26.924608   26.450403   26.079315   25.530327   \n",
       "9998  0.928054   28.203192   27.457575   26.576130   25.856819   25.445122   \n",
       "9999  0.202691   28.391132   27.409241   26.832666   26.587118   26.461618   \n",
       "\n",
       "      mag_y_lsst  \n",
       "0      22.579002  \n",
       "1      25.420044  \n",
       "2      24.666149  \n",
       "3      19.453854  \n",
       "4      25.163303  \n",
       "...          ...  \n",
       "9995   26.362583  \n",
       "9996   24.520649  \n",
       "9997   25.305614  \n",
       "9998   25.309990  \n",
       "9999   26.408859  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2train = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_train_set.pq\")\n",
    "\n",
    "df2train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing specselection_boss\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_selections.specselection_boss   --input=./output_train_set.pq   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_specselection_boss.pq \n",
      "Output writing to ./specselection_boss.out\n",
      "\n",
      "Job specselection_boss has completed successfully!\n",
      "\n",
      "Executing inform_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.Inform_PZFlowPdf   --input=./output_specselection_boss.pq   --name=inform_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --model=./pzflow.pkl \n",
      "Output writing to ./inform_PZFlow.out\n",
      "\n",
      "Job inform_PZFlow has completed successfully!\n",
      "\n",
      "Executing estimate_PZFlow\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.estimation.algos.pzflow_nf.PZFlowEstimator   --model=./pzflow.pkl   --input=./output_lsst_error.pq   --name=estimate_PZFlow   --config=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/BOSS_TEST2_config.yml   --output=./output_estimate_PZFlow.hdf5 \n",
      "Output writing to ./estimate_PZFlow.out\n",
      "\n",
      "Job estimate_PZFlow has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0.591147</td>\n",
       "      <td>22.445744</td>\n",
       "      <td>20.724831</td>\n",
       "      <td>19.164146</td>\n",
       "      <td>18.284557</td>\n",
       "      <td>17.949516</td>\n",
       "      <td>17.694904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>0.498089</td>\n",
       "      <td>25.742825</td>\n",
       "      <td>22.528442</td>\n",
       "      <td>20.879122</td>\n",
       "      <td>19.909256</td>\n",
       "      <td>19.455730</td>\n",
       "      <td>19.245495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>0.441687</td>\n",
       "      <td>23.170385</td>\n",
       "      <td>20.473461</td>\n",
       "      <td>18.878864</td>\n",
       "      <td>18.125809</td>\n",
       "      <td>17.771408</td>\n",
       "      <td>17.569096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>0.299266</td>\n",
       "      <td>24.022921</td>\n",
       "      <td>21.591301</td>\n",
       "      <td>20.290333</td>\n",
       "      <td>19.444916</td>\n",
       "      <td>19.087450</td>\n",
       "      <td>18.843006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>0.535850</td>\n",
       "      <td>25.292589</td>\n",
       "      <td>22.514803</td>\n",
       "      <td>20.829006</td>\n",
       "      <td>19.857273</td>\n",
       "      <td>19.471964</td>\n",
       "      <td>19.235981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7243</th>\n",
       "      <td>0.508251</td>\n",
       "      <td>24.524036</td>\n",
       "      <td>22.378204</td>\n",
       "      <td>20.889675</td>\n",
       "      <td>19.961979</td>\n",
       "      <td>19.593729</td>\n",
       "      <td>19.318655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9625</th>\n",
       "      <td>0.569059</td>\n",
       "      <td>23.863209</td>\n",
       "      <td>22.356947</td>\n",
       "      <td>20.861506</td>\n",
       "      <td>19.825939</td>\n",
       "      <td>19.414465</td>\n",
       "      <td>19.127625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9705</th>\n",
       "      <td>0.568569</td>\n",
       "      <td>23.138166</td>\n",
       "      <td>21.716282</td>\n",
       "      <td>20.204254</td>\n",
       "      <td>19.358370</td>\n",
       "      <td>19.036844</td>\n",
       "      <td>18.774906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      redshift  mag_u_lsst  mag_g_lsst  mag_r_lsst  mag_i_lsst  mag_z_lsst  \\\n",
       "1286  0.591147   22.445744   20.724831   19.164146   18.284557   17.949516   \n",
       "4494  0.498089   25.742825   22.528442   20.879122   19.909256   19.455730   \n",
       "4836  0.441687   23.170385   20.473461   18.878864   18.125809   17.771408   \n",
       "5332  0.299266   24.022921   21.591301   20.290333   19.444916   19.087450   \n",
       "6753  0.535850   25.292589   22.514803   20.829006   19.857273   19.471964   \n",
       "7243  0.508251   24.524036   22.378204   20.889675   19.961979   19.593729   \n",
       "9625  0.569059   23.863209   22.356947   20.861506   19.825939   19.414465   \n",
       "9705  0.568569   23.138166   21.716282   20.204254   19.358370   19.036844   \n",
       "\n",
       "      mag_y_lsst  \n",
       "1286   17.694904  \n",
       "4494   19.245495  \n",
       "4836   17.569096  \n",
       "5332   18.843006  \n",
       "6753   19.235981  \n",
       "7243   19.318655  \n",
       "9625   19.127625  \n",
       "9705   18.774906  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir2 = \"outputs\"\n",
    "out_parent_dir2 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2\"\n",
    "path_outs2 = os.path.join(out_parent_dir2, out_dir2)\n",
    "os.makedirs(path_outs2, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST2+\"/BOSS_TEST2.yml\")\n",
    "pr.run()\n",
    "\n",
    "import pandas as pd\n",
    "df2 = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST2/outputs/output_specselection_boss.pq\")\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FTEST(pathname, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    \n",
    "    ##things you need\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    #deg = lsstError(band_dict, seed3) \n",
    "    \n",
    "    testData = testSet(ntest, seed2)\n",
    "\n",
    "    # lsstErr = lsstError(band_dict, seed3)\n",
    "    infFZBoost = informFZBoost()\n",
    "    estFZBoost = estimateFZBoost(infFZBoost)\n",
    "\n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        #deg, \n",
    "        testData, \n",
    "        #lsstErr,  \n",
    "        infFZBoost, \n",
    "        estFZBoost]  \n",
    "\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "\n",
    "    # deg.connect_input(trainData)\n",
    "    #lsstErr.connect_input(testData)\n",
    "\n",
    "    infFZBoost.connect_input(trainData) \n",
    "    estFZBoost.connect_input(infFZBoost, inputTag = 'model')\n",
    "    estFZBoost.connect_input(testData, inputTag = 'input') ## trucated out of docs :( \n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    outpath = os.path.join(pathname, \"% s_TEST.yml\" % \"no_degrader\")\n",
    "    pipe.save(outpath)\n",
    "    return outpath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst_TEST3 = []\n",
    "directory_TEST3 = \"specSelection_TEST3\"\n",
    "parent_dir_TEST3 = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/\"\n",
    "path_TEST3 = os.path.join(parent_dir_TEST3, directory_TEST3)\n",
    "os.makedirs(path_TEST3, exist_ok=True)\n",
    "\n",
    "\n",
    "# for key in spec_dict:\n",
    "#     path_lst_TEST3.append(FTEST(spec_dict[key], key, path_TEST1, 1000, 1000, 104, 12, 327, 10))\n",
    "\n",
    "path_lst_TEST3.append(FTEST(path_TEST3, 10000, 100, 104, 12, 327, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_TEST = \"outputs_FZBoost\"\n",
    "out_parent_dir_TEST = \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3\"\n",
    "path_outs_TEST = os.path.join(out_parent_dir_TEST, out_dir_TEST)\n",
    "os.makedirs(path_outs_TEST, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConstructorError",
     "evalue": "could not determine a constructor for the tag 'tag:yaml.org,2002:python/object:rail.estimation.algos.flexzboost.FlexZBoostInformer'\n  in \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3/no_degrader_TEST_config.yml\", line 32, column 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConstructorError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb Cell 120\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y252sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(\u001b[39m\"\u001b[39m\u001b[39m/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3/outputs_FZBoost\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y252sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pr \u001b[39m=\u001b[39m ceci\u001b[39m.\u001b[39;49mPipeline\u001b[39m.\u001b[39;49mread(path_TEST3\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/no_degrader_TEST.yml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/Test_Pipeline.ipynb#Y252sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pr\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:488\u001b[0m, in \u001b[0;36mPipeline.read\u001b[0;34m(cls, pipeline_config_filename, extra_config, dry_run)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m    487\u001b[0m         \u001b[39m__import__\u001b[39m(module)\n\u001b[0;32m--> 488\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(pipe_config)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:386\u001b[0m, in \u001b[0;36mPipeline.create\u001b[0;34m(pipe_config)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    380\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown pipeline launcher \u001b[39m\u001b[39m{\u001b[39;00mlauncher_name\u001b[39m}\u001b[39;00m\u001b[39m, options are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(launcher_dict\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mmsg\u001b[39;00m\n\u001b[1;32m    383\u001b[0m p \u001b[39m=\u001b[39m pipeline_class(\n\u001b[1;32m    384\u001b[0m     stages, launcher_config, overall_inputs\u001b[39m=\u001b[39minputs, modules\u001b[39m=\u001b[39mmodules\n\u001b[1;32m    385\u001b[0m )\n\u001b[0;32m--> 386\u001b[0m p\u001b[39m.\u001b[39;49minitialize(inputs, run_config, stages_config)\n\u001b[1;32m    387\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/ceci/pipeline.py:790\u001b[0m, in \u001b[0;36mPipeline.initialize\u001b[0;34m(self, overall_inputs, run_config, stages_config)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages_config) \u001b[39mas\u001b[39;00m stage_config_file:\n\u001b[0;32m--> 790\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage_config_data \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39;49msafe_load(stage_config_file)\n\u001b[1;32m    791\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    792\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstage_config_data \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/__init__.py:125\u001b[0m, in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msafe_load\u001b[39m(stream):\n\u001b[1;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[39m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m    to be safe for untrusted input.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m load(stream, SafeLoader)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/__init__.py:81\u001b[0m, in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     79\u001b[0m loader \u001b[39m=\u001b[39m Loader(stream)\n\u001b[1;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m loader\u001b[39m.\u001b[39;49mget_single_data()\n\u001b[1;32m     82\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     loader\u001b[39m.\u001b[39mdispose()\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:51\u001b[0m, in \u001b[0;36mBaseConstructor.get_single_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_single_node()\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m node \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct_document(node)\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:60\u001b[0m, in \u001b[0;36mBaseConstructor.construct_document\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_generators \u001b[39m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m     \u001b[39mfor\u001b[39;00m generator \u001b[39min\u001b[39;00m state_generators:\n\u001b[0;32m---> 60\u001b[0m         \u001b[39mfor\u001b[39;00m dummy \u001b[39min\u001b[39;00m generator:\n\u001b[1;32m     61\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstructed_objects \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:413\u001b[0m, in \u001b[0;36mSafeConstructor.construct_yaml_map\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    411\u001b[0m data \u001b[39m=\u001b[39m {}\n\u001b[1;32m    412\u001b[0m \u001b[39myield\u001b[39;00m data\n\u001b[0;32m--> 413\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct_mapping(node)\n\u001b[1;32m    414\u001b[0m data\u001b[39m.\u001b[39mupdate(value)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:218\u001b[0m, in \u001b[0;36mSafeConstructor.construct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(node, MappingNode):\n\u001b[1;32m    217\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten_mapping(node)\n\u001b[0;32m--> 218\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mconstruct_mapping(node, deep\u001b[39m=\u001b[39;49mdeep)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:143\u001b[0m, in \u001b[0;36mBaseConstructor.construct_mapping\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(key, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mHashable):\n\u001b[1;32m    141\u001b[0m         \u001b[39mraise\u001b[39;00m ConstructorError(\u001b[39m\"\u001b[39m\u001b[39mwhile constructing a mapping\u001b[39m\u001b[39m\"\u001b[39m, node\u001b[39m.\u001b[39mstart_mark,\n\u001b[1;32m    142\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfound unhashable key\u001b[39m\u001b[39m\"\u001b[39m, key_node\u001b[39m.\u001b[39mstart_mark)\n\u001b[0;32m--> 143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct_object(value_node, deep\u001b[39m=\u001b[39;49mdeep)\n\u001b[1;32m    144\u001b[0m     mapping[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m mapping\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:100\u001b[0m, in \u001b[0;36mBaseConstructor.construct_object\u001b[0;34m(self, node, deep)\u001b[0m\n\u001b[1;32m     98\u001b[0m             constructor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mconstruct_mapping\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m tag_suffix \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     data \u001b[39m=\u001b[39m constructor(\u001b[39mself\u001b[39;49m, node)\n\u001b[1;32m    101\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     data \u001b[39m=\u001b[39m constructor(\u001b[39mself\u001b[39m, tag_suffix, node)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail---new/lib/python3.11/site-packages/yaml/constructor.py:427\u001b[0m, in \u001b[0;36mSafeConstructor.construct_undefined\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstruct_undefined\u001b[39m(\u001b[39mself\u001b[39m, node):\n\u001b[0;32m--> 427\u001b[0m     \u001b[39mraise\u001b[39;00m ConstructorError(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    428\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcould not determine a constructor for the tag \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m node\u001b[39m.\u001b[39mtag,\n\u001b[1;32m    429\u001b[0m             node\u001b[39m.\u001b[39mstart_mark)\n",
      "\u001b[0;31mConstructorError\u001b[0m: could not determine a constructor for the tag 'tag:yaml.org,2002:python/object:rail.estimation.algos.flexzboost.FlexZBoostInformer'\n  in \"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3/no_degrader_TEST_config.yml\", line 32, column 10"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3/outputs_FZBoost\")\n",
    "\n",
    "pr = ceci.Pipeline.read(path_TEST3+\"/no_degrader_TEST.yml\")\n",
    "pr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>redshift</th>\n",
       "      <th>mag_g_lsst</th>\n",
       "      <th>mag_g_lsst_err</th>\n",
       "      <th>mag_i_lsst</th>\n",
       "      <th>mag_i_lsst_err</th>\n",
       "      <th>mag_r_lsst</th>\n",
       "      <th>mag_r_lsst_err</th>\n",
       "      <th>mag_u_lsst</th>\n",
       "      <th>mag_u_lsst_err</th>\n",
       "      <th>mag_y_lsst</th>\n",
       "      <th>mag_y_lsst_err</th>\n",
       "      <th>mag_z_lsst</th>\n",
       "      <th>mag_z_lsst_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.965879</td>\n",
       "      <td>25.879404</td>\n",
       "      <td>0.057823</td>\n",
       "      <td>24.656401</td>\n",
       "      <td>0.028527</td>\n",
       "      <td>25.367927</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>26.197949</td>\n",
       "      <td>0.226304</td>\n",
       "      <td>23.746738</td>\n",
       "      <td>0.051104</td>\n",
       "      <td>24.103603</td>\n",
       "      <td>0.030794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112687</td>\n",
       "      <td>26.847807</td>\n",
       "      <td>0.135247</td>\n",
       "      <td>26.121641</td>\n",
       "      <td>0.104139</td>\n",
       "      <td>26.529480</td>\n",
       "      <td>0.100909</td>\n",
       "      <td>27.294345</td>\n",
       "      <td>0.533706</td>\n",
       "      <td>25.402500</td>\n",
       "      <td>0.215698</td>\n",
       "      <td>26.351736</td>\n",
       "      <td>0.219303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.704666</td>\n",
       "      <td>27.559750</td>\n",
       "      <td>0.246778</td>\n",
       "      <td>25.592196</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>26.581457</td>\n",
       "      <td>0.105604</td>\n",
       "      <td>28.976660</td>\n",
       "      <td>1.501604</td>\n",
       "      <td>25.789174</td>\n",
       "      <td>0.296218</td>\n",
       "      <td>25.392386</td>\n",
       "      <td>0.096273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793990</td>\n",
       "      <td>26.650420</td>\n",
       "      <td>0.113975</td>\n",
       "      <td>25.222062</td>\n",
       "      <td>0.047021</td>\n",
       "      <td>25.966401</td>\n",
       "      <td>0.061397</td>\n",
       "      <td>26.901584</td>\n",
       "      <td>0.397699</td>\n",
       "      <td>24.729052</td>\n",
       "      <td>0.121445</td>\n",
       "      <td>25.014646</td>\n",
       "      <td>0.069001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.546315</td>\n",
       "      <td>24.110855</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>22.613920</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>23.241883</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>24.459181</td>\n",
       "      <td>0.050363</td>\n",
       "      <td>22.060726</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>22.297977</td>\n",
       "      <td>0.007802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.339472</td>\n",
       "      <td>27.394182</td>\n",
       "      <td>0.215147</td>\n",
       "      <td>25.858046</td>\n",
       "      <td>0.082613</td>\n",
       "      <td>26.823286</td>\n",
       "      <td>0.130335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.499371</td>\n",
       "      <td>0.099389</td>\n",
       "      <td>25.131967</td>\n",
       "      <td>0.076545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.262786</td>\n",
       "      <td>25.282655</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>23.820874</td>\n",
       "      <td>0.014115</td>\n",
       "      <td>24.422184</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>25.878391</td>\n",
       "      <td>0.173117</td>\n",
       "      <td>22.580313</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>23.134816</td>\n",
       "      <td>0.013621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.511737</td>\n",
       "      <td>24.683479</td>\n",
       "      <td>0.020304</td>\n",
       "      <td>22.474778</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>23.168497</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>27.234214</td>\n",
       "      <td>0.510776</td>\n",
       "      <td>21.834788</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>22.022427</td>\n",
       "      <td>0.006859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.312853</td>\n",
       "      <td>24.656233</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>23.954590</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>24.076688</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>25.410581</td>\n",
       "      <td>0.115890</td>\n",
       "      <td>23.788194</td>\n",
       "      <td>0.053020</td>\n",
       "      <td>23.778379</td>\n",
       "      <td>0.023198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.847027</td>\n",
       "      <td>27.460548</td>\n",
       "      <td>0.227359</td>\n",
       "      <td>25.708277</td>\n",
       "      <td>0.072376</td>\n",
       "      <td>26.547836</td>\n",
       "      <td>0.102543</td>\n",
       "      <td>28.661756</td>\n",
       "      <td>1.274727</td>\n",
       "      <td>25.182394</td>\n",
       "      <td>0.179247</td>\n",
       "      <td>25.370383</td>\n",
       "      <td>0.094431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      redshift  mag_g_lsst  mag_g_lsst_err  mag_i_lsst  mag_i_lsst_err  \\\n",
       "0     0.965879   25.879404        0.057823   24.656401        0.028527   \n",
       "1     0.112687   26.847807        0.135247   26.121641        0.104139   \n",
       "2     0.704666   27.559750        0.246778   25.592196        0.065307   \n",
       "3     0.793990   26.650420        0.113975   25.222062        0.047021   \n",
       "4     0.546315   24.110855        0.012791   22.613920        0.006719   \n",
       "...        ...         ...             ...         ...             ...   \n",
       "9995  1.339472   27.394182        0.215147   25.858046        0.082613   \n",
       "9996  1.262786   25.282655        0.034108   23.820874        0.014115   \n",
       "9997  0.511737   24.683479        0.020304   22.474778        0.006385   \n",
       "9998  0.312853   24.656233        0.019842   23.954590        0.015711   \n",
       "9999  0.847027   27.460548        0.227359   25.708277        0.072376   \n",
       "\n",
       "      mag_r_lsst  mag_r_lsst_err  mag_u_lsst  mag_u_lsst_err  mag_y_lsst  \\\n",
       "0      25.367927        0.036107   26.197949        0.226304   23.746738   \n",
       "1      26.529480        0.100909   27.294345        0.533706   25.402500   \n",
       "2      26.581457        0.105604   28.976660        1.501604   25.789174   \n",
       "3      25.966401        0.061397   26.901584        0.397699   24.729052   \n",
       "4      23.241883        0.007272   24.459181        0.050363   22.060726   \n",
       "...          ...             ...         ...             ...         ...   \n",
       "9995   26.823286        0.130335         NaN             NaN   24.499371   \n",
       "9996   24.422184        0.016017   25.878391        0.173117   22.580313   \n",
       "9997   23.168497        0.007034   27.234214        0.510776   21.834788   \n",
       "9998   24.076688        0.012212   25.410581        0.115890   23.788194   \n",
       "9999   26.547836        0.102543   28.661756        1.274727   25.182394   \n",
       "\n",
       "      mag_y_lsst_err  mag_z_lsst  mag_z_lsst_err  \n",
       "0           0.051104   24.103603        0.030794  \n",
       "1           0.215698   26.351736        0.219303  \n",
       "2           0.296218   25.392386        0.096273  \n",
       "3           0.121445   25.014646        0.069001  \n",
       "4           0.012195   22.297977        0.007802  \n",
       "...              ...         ...             ...  \n",
       "9995        0.099389   25.131967        0.076545  \n",
       "9996        0.018460   23.134816        0.013621  \n",
       "9997        0.010365   22.022427        0.006859  \n",
       "9998        0.053020   23.778379        0.023198  \n",
       "9999        0.179247   25.370383        0.094431  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.read_parquet(\"/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/specSelection_TEST3/outputs_GPz/output_lsst_error.pq\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail--new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
