{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential Imports: \n",
    "import os\n",
    "import numpy as np\n",
    "import qp\n",
    "import tables_io\n",
    "from pathlib import Path \n",
    "from pzflow.examples import get_galaxy_data\n",
    "import ceci\n",
    "\n",
    "## RAIL-Specific Imports: \n",
    "import rail\n",
    "from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness\n",
    "from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "\n",
    "## Data Storage: \n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    #path to access the data \n",
    "    DATA_DIR = Path().resolve() / \"data\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    catalog_file = DATA_DIR / \"base_catalog.pq\"\n",
    "\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    \n",
    "    #array of galaxies w/ 7 attributes for each: redshift & ugrizy\n",
    "    catalog = get_galaxy_data().rename(band_dict, axis=1) \n",
    "\n",
    "    #turns array into a table \n",
    "    tables_io.write(catalog, str(catalog_file.with_suffix(\"\")), catalog_file.suffix[1:])\n",
    "\n",
    "    catalog_file = str(catalog_file)\n",
    "    flow_file = str(DATA_DIR / \"trained_flow.pkl\")\n",
    "\n",
    "    #we set up the stage \n",
    "    flow_modeler_params = {\n",
    "        \"name\": \"flow_modeler\",\n",
    "        \"input\": catalog_file,\n",
    "        \"model\": flow_file,\n",
    "        \"seed\": 0,\n",
    "        \"phys_cols\": {\"redshift\": [0, 3]},\n",
    "        \"phot_cols\": {\n",
    "            \"mag_u_lsst\": [17, 35],\n",
    "            \"mag_g_lsst\": [16, 32],\n",
    "            \"mag_r_lsst\": [15, 30],\n",
    "            \"mag_i_lsst\": [15, 30],\n",
    "            \"mag_z_lsst\": [14, 29],\n",
    "            \"mag_y_lsst\": [14, 28],\n",
    "        },\n",
    "        \"calc_colors\": {\"ref_column_name\": \"mag_i_lsst\"},\n",
    "    }\n",
    "    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)\n",
    "    flow_modeler.fit_model()\n",
    "    return flow_modeler.get_handle(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  input: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/base_catalog.pq, flow_modeler\n",
      "Training 30 epochs \n",
      "Loss:\n",
      "(0) 21.3266\n",
      "(1) 6.7267\n",
      "(2) 2.0761\n",
      "(3) 2.6037\n",
      "(4) -0.0680\n",
      "(5) 0.4129\n",
      "(6) 0.2506\n",
      "(7) 0.1637\n",
      "(8) -1.3346\n",
      "(9) -1.7669\n",
      "(10) -1.1823\n",
      "(11) -1.6267\n",
      "(12) 3402823273761818485311871060541440.0000\n",
      "(13) 3402823273761818485311871060541440.0000\n",
      "(14) -1.0711\n",
      "(15) -0.6228\n",
      "(16) 3402823273761818485311871060541440.0000\n",
      "(17) 3402823273761818485311871060541440.0000\n",
      "(18) -2.8045\n",
      "(19) -3.3746\n",
      "(20) 3402823273761818485311871060541440.0000\n",
      "(21) -2.4881\n",
      "(22) -3.2147\n",
      "(23) -3.7188\n",
      "(24) -3.4398\n",
      "(25) -3.7955\n",
      "(26) -3.3772\n",
      "(27) 3402823273761818485311871060541440.0000\n",
      "(28) -3.5247\n",
      "(29) -4.1677\n",
      "(30) -3.4874\n",
      "Inserting handle into data store.  model_flow_modeler: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/inprogress_trained_flow.pkl, flow_modeler\n"
     ]
    }
   ],
   "source": [
    "modelData = makeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSet(model, ntrain, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'stuff',\n",
    "            model = model,\n",
    "            n_samples = ntrain,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data.sample(ntrain, seed)\n",
    "\n",
    "def invRedshift(data, pivot = 1.0):\n",
    "    deg = InvRedshiftIncompleteness.make_stage(\n",
    "        name = 'stuff',\n",
    "        pivot_redshift = pivot\n",
    "    )\n",
    "    return deg(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n"
     ]
    }
   ],
   "source": [
    "origTrainData = trainSet(modelData, 10000, 372)\n",
    "\n",
    "degTrainData = invRedshift(trainSet(modelData, 10000, 372), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(data, model, grid):\n",
    "    posts = FlowPosterior.make_stage(\n",
    "        name='stuff', \n",
    "        column='redshift',\n",
    "        grid = grid,\n",
    "        model = model,\n",
    "        data = data\n",
    "    )\n",
    "    return posts.get_posterior(data, column = 'redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(zmin, zmax, nbins):\n",
    "    import numpy as np\n",
    "    grid = np.linspace(zmin, zmax, nbins + 1)\n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = makeGrid(0, 2.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.hdf5, stuff\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Ensemble' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m origTrainPosts \u001b[39m=\u001b[39m getPosts(origTrainData, modelData, grid)\n\u001b[0;32m----> 2\u001b[0m degTrainPosts \u001b[39m=\u001b[39m getPosts(degTrainData, modelData, grid)\n",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mgetPosts\u001b[0;34m(data, model, grid)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetPosts\u001b[39m(data, model, grid):\n\u001b[1;32m      2\u001b[0m     posts \u001b[39m=\u001b[39m FlowPosterior\u001b[39m.\u001b[39mmake_stage(\n\u001b[1;32m      3\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      4\u001b[0m         column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mredshift\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         data \u001b[39m=\u001b[39m data\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m posts\u001b[39m.\u001b[39;49mget_posterior(data, column \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mredshift\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/rail/creation/engine.py:203\u001b[0m, in \u001b[0;36mPosteriorCalculator.get_posterior\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_data(\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m, input_data)\n\u001b[1;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mupdate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 203\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalize()\n\u001b[1;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_handle(\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/rail/creation/engines/flowEngine.py:294\u001b[0m, in \u001b[0;36mFlowPosterior.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m     marg_rules \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmarg_rules\n\u001b[1;32m    293\u001b[0m \u001b[39m# use the PZFlow normalizing flow to calculate posteriors\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m pdfs \u001b[39m=\u001b[39m flow\u001b[39m.\u001b[39;49mposterior(\n\u001b[1;32m    295\u001b[0m     inputs\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    296\u001b[0m     column\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mcolumn,\n\u001b[1;32m    297\u001b[0m     grid\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mgrid),\n\u001b[1;32m    298\u001b[0m     err_samples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49merr_samples,\n\u001b[1;32m    299\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m    300\u001b[0m     marg_rules\u001b[39m=\u001b[39;49mmarg_rules,\n\u001b[1;32m    301\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    302\u001b[0m     nan_to_zero\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnan_to_zero,\n\u001b[1;32m    303\u001b[0m )\n\u001b[1;32m    305\u001b[0m \u001b[39m# save the posteriors in a qp ensemble\u001b[39;00m\n\u001b[1;32m    306\u001b[0m ensemble \u001b[39m=\u001b[39m qp\u001b[39m.\u001b[39mEnsemble(\n\u001b[1;32m    307\u001b[0m     qp\u001b[39m.\u001b[39minterp, data\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mxvals\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mgrid, \u001b[39m\"\u001b[39m\u001b[39myvals\u001b[39m\u001b[39m\"\u001b[39m: pdfs}\n\u001b[1;32m    308\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/pzflow/flow.py:542\u001b[0m, in \u001b[0;36mFlow.posterior\u001b[0;34m(self, inputs, column, grid, marg_rules, normalize, err_samples, seed, batch_size, nan_to_zero)\u001b[0m\n\u001b[1;32m    539\u001b[0m batch_size \u001b[39m=\u001b[39m nrows \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m batch_size\n\u001b[1;32m    541\u001b[0m \u001b[39m# make sure indices run 0 -> nrows\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    544\u001b[0m \u001b[39mif\u001b[39;00m err_samples \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     \u001b[39m# validate nsamples\u001b[39;00m\n\u001b[1;32m    546\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    547\u001b[0m         err_samples, \u001b[39mint\u001b[39m\n\u001b[1;32m    548\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39merr_samples must be a positive integer.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Ensemble' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "origTrainPosts = getPosts(origTrainData, modelData, grid)\n",
    "degTrainPosts = getPosts(degTrainData, modelData, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_train_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_train = FlowPosterior.make_stage(name='orig_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_train)\n",
    "\n",
    "# orig_train_pdfs = flow_post_orig_train.get_posterior(orig_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_train_posts ** rerun this cell!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_train = FlowPosterior.make_stage(name='deg_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              err_samples = 0,\n",
    "#                                              data = deg_train)\n",
    "\n",
    "\n",
    "\n",
    "# deg_train_pdfs = flow_post_deg_train.get_posterior(deg_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSet(model, ntest, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'stuff',\n",
    "            model = model,\n",
    "            n_samples = ntest,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data.sample(ntest, seed)\n",
    "\n",
    "\n",
    "## you need to ask alex about where you can find the defaults for these params \n",
    "def lsstError(data, seed, tvis = 1, nYrObs = 1, airmass = 1, extendedSource = 1, sigmaSys = 1, magLim = 1, ndFlag = 1, A_min = 1, A_max = 1):\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    deg = LSSTErrorModel.make_stage(\n",
    "        name='stuff',\n",
    "        bandNames=band_dict, \n",
    "        seed=seed,\n",
    "    )\n",
    "    return deg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testData = lsstError(testSet(100000, 1078), 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPosts = getPosts(testData, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_test = FlowPosterior.make_stage(name='orig_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_test)\n",
    "\n",
    "# orig_test_pdfs = flow_post_orig_test.get_posterior(orig_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_test = FlowPosterior.make_stage(name='deg_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = deg_test)\n",
    "\n",
    "# deg_test_pdfs = flow_post_deg_test.get_posterior(deg_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTable(datafile):\n",
    "    \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    rename_dict = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    col_remapper = ColumnMapper.make_stage(\n",
    "    name='col_remapper', \n",
    "    columns=rename_dict,\n",
    "    )\n",
    "    table_conv = TableConverter.make_stage(\n",
    "    name='table_conv', \n",
    "    output_format='numpyDict',\n",
    "    )\n",
    "    pq = col_remapper(datafile)\n",
    "    tabledata = table_conv(pq)\n",
    "    table = tables_io.convertObj(tabledata.data, tables_io.types.PD_DATAFRAME)\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainTable = makeTable(trainData)\n",
    "# testTable = makeTable(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informFZBoost(data):\n",
    "    info = Inform_FZBoost.make_stage(\n",
    "    name ='informFZBoost', \n",
    "    model ='fzboost.pkl', \n",
    "    hdf5_groupname='',\n",
    "    )\n",
    "    info.inform(data)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informedEst = informFZBoost(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateFZBoost(data, info, nbins):\n",
    "    est = FZBoost.make_stage(\n",
    "    name='estFZBoost', \n",
    "    nondetect_val=np.nan,\n",
    "    model= info.get_handle('model'), \n",
    "    hdf5_groupname='',\n",
    "    aliases=dict(input='test_data', output='fzboost_estim'),\n",
    "    nzbins = nbins ,\n",
    "    zmax = zmax\n",
    "    )\n",
    "    return est.estimate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 30 epochs \n",
      "Loss:\n",
      "(0) 21.3266\n",
      "(1) 6.7267\n",
      "(2) 2.0761\n",
      "(3) 2.6037\n",
      "(4) -0.0680\n",
      "(5) 0.4129\n",
      "(6) 0.2506\n",
      "(7) 0.1637\n",
      "(8) -1.3346\n",
      "(9) -1.7669\n",
      "(10) -1.1823\n",
      "(11) -1.6267\n",
      "(12) 3402823273761818485311871060541440.0000\n",
      "(13) 3402823273761818485311871060541440.0000\n",
      "(14) -1.0711\n",
      "(15) -0.6228\n",
      "(16) 3402823273761818485311871060541440.0000\n",
      "(17) 3402823273761818485311871060541440.0000\n",
      "(18) -2.8045\n",
      "(19) -3.3746\n",
      "(20) 3402823273761818485311871060541440.0000\n",
      "(21) -2.4881\n",
      "(22) -3.2147\n",
      "(23) -3.7188\n",
      "(24) -3.4398\n",
      "(25) -3.7955\n",
      "(26) -3.3772\n",
      "(27) 3402823273761818485311871060541440.0000\n",
      "(28) -3.5247\n",
      "(29) -4.1677\n",
      "(30) -3.4874\n",
      "Inserting handle into data store.  model_flow_modeler: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/inprogress_trained_flow.pkl, flow_modeler\n"
     ]
    }
   ],
   "source": [
    "# estData = estimateFZBoost(testData, informedEst, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF():\n",
    "    grid = makeGrid(0, 2.5, 100) \n",
    "    #modelData = makeModel()\n",
    "    trainData = invRedshift(trainSet(modelData, 10, 372), 1.0)\n",
    "    trainPosts = getPosts(trainData, modelData, grid)\n",
    "    testData = lsstError(testSet(modelData, 100, 1078), 39)\n",
    "    testPosts = getPosts(testData, modelData, grid)\n",
    "    trainTable = makeTable(trainData)\n",
    "    testTable = makeTable(testData)\n",
    "    informedEst = informFZBoost(trainData)\n",
    "    estData = estimateFZBoost(testData, informedEst)\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [modelData, trainData, trainPosts, testData, testPosts, trainTable, testTable, informedEst, estData]\n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.hdf5, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.pq, stuff\n",
      "Inserting handle into data store.  output_stuff: inprogress_output_stuff.hdf5, stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/miniforge3/envs/rail/lib/python3.10/site-packages/qp/interp_pdf.py:83: RuntimeWarning: invalid value encountered in divide\n",
      "  self._ycumul = (self._ycumul.T / self._ycumul[:,-1]).T\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Ensemble' object has no attribute 'rename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bigF()\n",
      "Cell \u001b[0;32mIn[121], line 8\u001b[0m, in \u001b[0;36mbigF\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m testData \u001b[39m=\u001b[39m lsstError(testSet(modelData, \u001b[39m100\u001b[39m, \u001b[39m1078\u001b[39m), \u001b[39m39\u001b[39m)\n\u001b[1;32m      7\u001b[0m testPosts \u001b[39m=\u001b[39m getPosts(testData, modelData, grid)\n\u001b[0;32m----> 8\u001b[0m trainTable \u001b[39m=\u001b[39m makeTable(trainData)\n\u001b[1;32m      9\u001b[0m testTable \u001b[39m=\u001b[39m makeTable(testData)\n\u001b[1;32m     10\u001b[0m informedEst \u001b[39m=\u001b[39m informFZBoost(trainData)\n",
      "Cell \u001b[0;32mIn[98], line 15\u001b[0m, in \u001b[0;36mmakeTable\u001b[0;34m(datafile)\u001b[0m\n\u001b[1;32m      7\u001b[0m col_remapper \u001b[39m=\u001b[39m ColumnMapper\u001b[39m.\u001b[39mmake_stage(\n\u001b[1;32m      8\u001b[0m name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcol_remapper\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m columns\u001b[39m=\u001b[39mrename_dict,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m table_conv \u001b[39m=\u001b[39m TableConverter\u001b[39m.\u001b[39mmake_stage(\n\u001b[1;32m     12\u001b[0m name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtable_conv\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m output_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumpyDict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m pq \u001b[39m=\u001b[39m col_remapper(datafile)\n\u001b[1;32m     16\u001b[0m tabledata \u001b[39m=\u001b[39m table_conv(pq)\n\u001b[1;32m     17\u001b[0m table \u001b[39m=\u001b[39m tables_io\u001b[39m.\u001b[39mconvertObj(tabledata\u001b[39m.\u001b[39mdata, tables_io\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mPD_DATAFRAME)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/rail/core/utilStages.py:63\u001b[0m, in \u001b[0;36mColumnMapper.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return a table with the columns names changed\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39m    The degraded sample\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_data(\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m, data)\n\u001b[0;32m---> 63\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_handle(\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/rail/core/utilStages.py:39\u001b[0m, in \u001b[0;36mColumnMapper.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     38\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_data(\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m, allow_missing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 39\u001b[0m     out_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mrename(columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mcolumns, inplace\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39minplace)\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39minplace:  \u001b[39m#pragma: no cover\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         out_data \u001b[39m=\u001b[39m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Ensemble' object has no attribute 'rename'"
     ]
    }
   ],
   "source": [
    "bigF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rail.core.data.PqHandle"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
