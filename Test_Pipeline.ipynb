{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Essential Imports: \n",
    "import os\n",
    "import numpy as np\n",
    "import qp\n",
    "import tables_io\n",
    "from pathlib import Path \n",
    "from pzflow.examples import get_galaxy_data\n",
    "import ceci\n",
    "\n",
    "## RAIL-Specific Imports: \n",
    "import rail\n",
    "from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness\n",
    "from rail.creation.engines.flowEngine import FlowModeler, FlowCreator, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "from rail.estimation.algos.flexzboost import Inform_FZBoost, FZBoost\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "\n",
    "## Data Storage: \n",
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    #path to access the data \n",
    "    DATA_DIR = Path().resolve() / \"data\"\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    catalog_file = DATA_DIR / \"base_catalog.pq\"\n",
    "\n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "    \n",
    "    #array of galaxies w/ 7 attributes for each: redshift & ugrizy\n",
    "    catalog = get_galaxy_data().rename(band_dict, axis=1) \n",
    "\n",
    "    #turns array into a table \n",
    "    tables_io.write(catalog, str(catalog_file.with_suffix(\"\")), catalog_file.suffix[1:])\n",
    "\n",
    "    catalog_file = str(catalog_file)\n",
    "    flow_file = str(DATA_DIR / \"trained_flow.pkl\")\n",
    "\n",
    "    print(flow_file)\n",
    "\n",
    "    #we set up the stage \n",
    "    flow_modeler_params = {\n",
    "        \"name\": \"flow_modeler\",\n",
    "        \"input\": catalog_file,\n",
    "        \"model\": flow_file,\n",
    "        \"seed\": 0,\n",
    "        \"phys_cols\": {\"redshift\": [0, 3]},\n",
    "        \"phot_cols\": {\n",
    "            \"mag_u_lsst\": [17, 35],\n",
    "            \"mag_g_lsst\": [16, 32],\n",
    "            \"mag_r_lsst\": [15, 30],\n",
    "            \"mag_i_lsst\": [15, 30],\n",
    "            \"mag_z_lsst\": [14, 29],\n",
    "            \"mag_y_lsst\": [14, 28],\n",
    "        },\n",
    "        \"calc_colors\": {\"ref_column_name\": \"mag_i_lsst\"},\n",
    "    }\n",
    "    flow_modeler = FlowModeler.make_stage(**flow_modeler_params)\n",
    "    # flow_modeler.fit_model()\n",
    "    return flow_modeler, flow_file ##.get_handle(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl\n"
     ]
    }
   ],
   "source": [
    "modelData, flow_file = makeModel() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSet(ntrain, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'train_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntrain,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data #.sample(ntrain, seed)\n",
    "\n",
    "def invRedshift(pivot = 1.0):\n",
    "    degr = InvRedshiftIncompleteness.make_stage(\n",
    "        name = 'inv_redshift',\n",
    "        pivot_redshift = pivot\n",
    "    )\n",
    "    return degr #(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting handle into data store.  model: /Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl, train_set\n"
     ]
    }
   ],
   "source": [
    "# data = FlowCreator.make_stage(\n",
    "#             name = 'train_set',\n",
    "#             model = flow_file,\n",
    "#             n_samples = 2,\n",
    "#             seed = 78 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origTrainData = trainSet(modelData, 100, 372)\n",
    "# bubble = origTrainData.sample(100, 372)\n",
    "\n",
    "# degTrainData = invRedshift(1.0)\n",
    "# dot = degTrainData(bubble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degTrainData.get_handle('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPosts(data, model, grid):\n",
    "    posts = FlowPosterior.make_stage(\n",
    "        name='get_posts'+str(data), \n",
    "        column='redshift',\n",
    "        grid = grid,\n",
    "        model = model,\n",
    "        data = data\n",
    "    )\n",
    "    return posts #posts.get_posterior(data, column = 'redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGrid(zmin, zmax, nbins):\n",
    "    import numpy as np\n",
    "    grid = np.linspace(zmin, zmax, nbins + 1)\n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = makeGrid(0, 2.5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origTrainPosts = getPosts(origTrainData, modelData, grid)\n",
    "# degTrainPosts = getPosts(degTrainData, modelData, grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_train_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_train = FlowPosterior.make_stage(name='orig_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_train)\n",
    "\n",
    "# orig_train_pdfs = flow_post_orig_train.get_posterior(orig_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_train_posts ** rerun this cell!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_train = FlowPosterior.make_stage(name='deg_train_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              err_samples = 0,\n",
    "#                                              data = deg_train)\n",
    "\n",
    "\n",
    "\n",
    "# deg_train_pdfs = flow_post_deg_train.get_posterior(deg_train, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSet(ntest, seed):\n",
    "    data = FlowCreator.make_stage(\n",
    "            name = 'test_set',\n",
    "            model = flow_file,\n",
    "            n_samples = ntest,\n",
    "            seed = seed \n",
    "    )\n",
    "    return data #.sample(ntest, seed)\n",
    "\n",
    "\n",
    "## you need to ask alex about where you can find the defaults for these params \n",
    "\n",
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "\n",
    "def lsstError(dict, seed): #tvis = 1, nYrObs = 1, airmass = 1, extendedSource = 1, sigmaSys = 1, magLim = 1, ndFlag = 1, A_min = 1, A_max = 1):\n",
    "    deg = LSSTErrorModel.make_stage(\n",
    "        name='lsst_error',\n",
    "        renameDict= dict, \n",
    "        ndFlag=np.nan,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return deg #(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testSetMaker = testSet(modelData, 100, 17)\n",
    "# testData = testSetMaker.sample(100, 17)\n",
    "# degTestData = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_orig_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_orig_test = FlowPosterior.make_stage(name='orig_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = orig_test)\n",
    "\n",
    "# orig_test_pdfs = flow_post_orig_test.get_posterior(orig_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run if you need output_deg_test_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_post_deg_test = FlowPosterior.make_stage(name='deg_test_posts', \n",
    "#                                              column='redshift',\n",
    "#                                              grid = np.linspace(0, 2.5, 101),\n",
    "#                                              model=flow_file,\n",
    "#                                              data = deg_test)\n",
    "\n",
    "# deg_test_pdfs = flow_post_deg_test.get_posterior(deg_test, column='redshift')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def makeTable(datafile):\n",
    "    \n",
    "#     bands = ['u','g','r','i','z','y']\n",
    "#     rename_dict = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "#     col_remapper = ColumnMapper.make_stage(\n",
    "#     name='col_remapper', \n",
    "#     columns=rename_dict,\n",
    "#     )\n",
    "#     table_conv = TableConverter.make_stage(\n",
    "#     name='table_conv', \n",
    "#     output_format='numpyDict',\n",
    "#     )\n",
    "#     pq = col_remapper(datafile)\n",
    "#     tabledata = table_conv(pq)\n",
    "#     table = tables_io.convertObj(tabledata.data, tables_io.types.PD_DATAFRAME)\n",
    "#     return table\n",
    "\n",
    "\n",
    "# ## make two separate functions for each stage, make bands, rename_dict inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "def colRemapper(dict):\n",
    "    col_remapper = ColumnMapper.make_stage(\n",
    "    name='col_remapper', \n",
    "    columns=dict,\n",
    "    )\n",
    "    return col_remapper\n",
    "\n",
    "def tableConverter():\n",
    "    table_conv = TableConverter.make_stage(\n",
    "    name='table_conv', \n",
    "    output_format='numpyDict',\n",
    "    )\n",
    "    return table_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "squiggle = colRemapper(band_dict_err)\n",
    "noodle = tableConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainTable = makeTable(trainData)\n",
    "# testTable = makeTable(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inform & Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def informFZBoost():\n",
    "    info = Inform_FZBoost.make_stage(\n",
    "    name ='inform_FZBoost', \n",
    "    model ='fzboost.pkl', \n",
    "    hdf5_groupname='',\n",
    "    )\n",
    "    # info.inform(data)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# informedEst = informFZBoost()\n",
    "# informedEst.inform(degTrainData.get_handle('output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateFZBoost(info, nbins):\n",
    "    est = FZBoost.make_stage(\n",
    "    name='est_FZBoost', \n",
    "    nondetect_val=np.nan,\n",
    "    model= info, #.get_handle('model'), \n",
    "    hdf5_groupname='',\n",
    "    aliases=dict(input='test_data', output='fzboost_estim'),\n",
    "    nzbins = nbins \n",
    "    )\n",
    "    return est #.estimate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estData = estimateFZBoost(informedEst, 100)\n",
    "\n",
    "# estData.estimate(testSetMaker.get_handle('output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function connect_input in module rail.core.stage:\n",
      "\n",
      "connect_input(self, other, inputTag=None, outputTag=None)\n",
      "    Connect another stage to this stage as an input\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : RailStage\n",
      "         The stage whose output is being connected\n",
      "    inputTag : str\n",
      "         Which input tag of this stage to connect to.  None -> self.inputs[0]\n",
      "    outputTag : str\n",
      "         Which output tag of the other stage to connect to.  None -> other.outputs[0]\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    handle : The input handle for this stage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RailStage.connect_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigF(pivotz, ntrain, ntest, seed1, seed2, seed3, nbins):\n",
    "    ##things you need\n",
    "    grid = makeGrid(0, 2.5, nbins) \n",
    "    bands = ['u','g','r','i','z','y']\n",
    "    band_dict = {band: f\"mag_{band}_lsst\" for band in bands}\n",
    "    band_dict_err = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}\n",
    "\n",
    "    # modelData = makeModel()\n",
    "    \n",
    "    ##stages \n",
    "    trainData = trainSet(ntrain, seed1)\n",
    "    invRed = invRedshift(pivotz)\n",
    "\n",
    "    # origTrainPosts = getPosts(output_train_set.pq (???), modelData, grid)\n",
    "    # degTrainPosts = getPosts(###)\n",
    "\n",
    "    testData = testSet(ntest, seed2)\n",
    "    lsstErr = lsstError(band_dict, seed3)\n",
    "\n",
    "    # origTestPosts = getPosts(###)\n",
    "    # degTestPosts = getPosts(###)\n",
    "        \n",
    "    ## maybe do table things? later tho \n",
    "\n",
    "    informFZB = informFZBoost()\n",
    "    estFZB = estimateFZBoost(informFZB, nbins)\n",
    "\n",
    "    \n",
    "    ##pipeline and yml\n",
    "    pipe = ceci.Pipeline.interactive()\n",
    "    stages = [\n",
    "        trainData, \n",
    "        invRed, \n",
    "        testData, \n",
    "        lsstErr,  \n",
    "        informFZB, \n",
    "        estFZB]\n",
    "    \n",
    "    for stage in stages:\n",
    "        pipe.add_stage(stage)\n",
    "        \n",
    "\n",
    "    invRed.connect_input(trainData)\n",
    "    lsstErr.connect_input(testData)\n",
    "\n",
    "    informFZB.connect_input(invRed)\n",
    "    estFZB.connect_input(lsstErr)#testData)#informFZB, testData) #lsstErr)\n",
    "\n",
    "    pipe.initialize(\n",
    "    dict(model=flow_file), dict(output_dir=\".\", log_dir=\".\", resume=False), None) \n",
    "\n",
    "    pipe.save(\"test_pipeline_est.yml\") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage est_FZBoost is missing input(s): test_data\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bigF(\u001b[39m1.0\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m17\u001b[39;49m, \u001b[39m39\u001b[39;49m, \u001b[39m172\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[99], line 49\u001b[0m, in \u001b[0;36mbigF\u001b[0;34m(pivotz, ntrain, ntest, seed1, seed2, seed3, nbins)\u001b[0m\n\u001b[1;32m     46\u001b[0m informFZB\u001b[39m.\u001b[39mconnect_input(invRed)\n\u001b[1;32m     47\u001b[0m estFZB\u001b[39m.\u001b[39mconnect_input(lsstErr)\u001b[39m#testData)#informFZB, testData) #lsstErr)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m pipe\u001b[39m.\u001b[39;49minitialize(\n\u001b[1;32m     50\u001b[0m \u001b[39mdict\u001b[39;49m(model\u001b[39m=\u001b[39;49mflow_file), \u001b[39mdict\u001b[39;49m(output_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, log_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m, resume\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), \u001b[39mNone\u001b[39;49;00m) \n\u001b[1;32m     52\u001b[0m pipe\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mtest_pipeline_est.yml\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/ceci/pipeline.py:798\u001b[0m, in \u001b[0;36mPipeline.initialize\u001b[0;34m(self, overall_inputs, run_config, stages_config)\u001b[0m\n\u001b[1;32m    795\u001b[0m     v\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_config)\n\u001b[1;32m    797\u001b[0m \u001b[39m# Get the stages in the order we need.\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mordered_stages(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moverall_inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstages_config)\n\u001b[1;32m    800\u001b[0m \u001b[39m# Initiate the run.\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# This is an implementation detail for the different subclasses to store\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# necessary information about the run if necessary.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# Usually, the arguments are ignored, but they are provided in case a class needs to\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m# do something special with any of them.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitiate_run(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/rail/lib/python3.10/site-packages/ceci/pipeline.py:753\u001b[0m, in \u001b[0;36mPipeline.ordered_stages\u001b[0;34m(self, overall_inputs, stages_config)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 msg1\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStage \u001b[39m\u001b[39m{\u001b[39;00mstage_name\u001b[39m}\u001b[39;00m\u001b[39m is missing input(s): \u001b[39m\u001b[39m{\u001b[39;00mmissing_inputs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    752\u001b[0m             msg1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(msg1)\n\u001b[0;32m--> 753\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    755\u001b[0m \u001b[39mSome required inputs to the pipeline could not be found,\u001b[39m\n\u001b[1;32m    756\u001b[0m \u001b[39m(or possibly your pipeline is cyclic):\u001b[39m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[39m{\u001b[39;00mmsg1\u001b[39m}\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    760\u001b[0m             )\n\u001b[1;32m    762\u001b[0m         \u001b[39mreturn\u001b[39;00m ordered_stages\n",
      "\u001b[0;31mValueError\u001b[0m: \nSome required inputs to the pipeline could not be found,\n(or possibly your pipeline is cyclic):\n\nStage est_FZBoost is missing input(s): test_data\n"
     ]
    }
   ],
   "source": [
    "bigF(1.0, 100, 100, 17, 39, 172, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing test_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=test_set   --config=test_pipeline_config.yml   --output=./output_test_set.pq \n",
      "Output writing to ./test_set.out\n",
      "\n",
      "Job test_set has completed successfully!\n",
      "\n",
      "Executing lsst_error\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.lsst_error_model.LSSTErrorModel   --input=./output_test_set.pq   --name=lsst_error   --config=test_pipeline_config.yml   --output=./output_lsst_error.pq \n",
      "Output writing to ./lsst_error.out\n",
      "\n",
      "Job lsst_error has completed successfully!\n",
      "\n",
      "Executing train_set\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.engines.flowEngine.FlowCreator   --model=/Users/alicec03/Desktop/Summer_Research/Photo-z-Stress-Test/Photo-z-Stress-Test/data/trained_flow.pkl   --name=train_set   --config=test_pipeline_config.yml   --output=./output_train_set.pq \n",
      "Output writing to ./train_set.out\n",
      "\n",
      "Job train_set has completed successfully!\n",
      "\n",
      "Executing inv_redshift\n",
      "Command is:\n",
      "OMP_NUM_THREADS=1   python3 -m ceci rail.creation.degradation.spectroscopic_degraders.InvRedshiftIncompleteness   --input=./output_train_set.pq   --name=inv_redshift   --config=test_pipeline_config.yml   --output=./output_inv_redshift.pq \n",
      "Output writing to ./inv_redshift.out\n",
      "\n",
      "Job inv_redshift has completed successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = ceci.Pipeline.read(\"test_pipeline_est.yml\")\n",
    "pr.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
